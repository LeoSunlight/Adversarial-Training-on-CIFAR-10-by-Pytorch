{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f33ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch as ch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "from models import ResNet18\n",
    "from advertorch.attacks import L2PGDAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c632f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "file_name = 'basic_training_robust_dataset'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, *tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im, targ = tuple(tensor[index] for tensor in self.tensors)\n",
    "        if self.transform:\n",
    "            real_transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                self.transform\n",
    "            ])\n",
    "            im = real_transform(im)\n",
    "        return im, targ\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)\n",
    "\n",
    "data_path = \"d_robust_CIFAR/\"\n",
    "train_data = ch.cat(ch.load(os.path.join(data_path, f\"CIFAR_ims\")))\n",
    "train_labels = ch.cat(ch.load(os.path.join(data_path, f\"CIFAR_lab\")))\n",
    "train_dataset = TensorDataset(train_data, train_labels, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6326d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "adversary = L2PGDAttack(net, loss_fn=nn.CrossEntropyLoss(), eps=0.25, nb_iter=100, eps_iter=0.01, rand_init=True, clip_min=0.0, clip_max=1.0, targeted=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3aff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
    "    print('Total benign train loss:', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68376ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    benign_loss = 0\n",
    "    adv_loss = 0\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        benign_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        benign_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign test loss:', loss.item())\n",
    "\n",
    "        adv = adversary.perturb(inputs, targets)\n",
    "        adv_outputs = net(adv)\n",
    "        loss = criterion(adv_outputs, targets)\n",
    "        adv_loss += loss.item()\n",
    "\n",
    "        _, predicted = adv_outputs.max(1)\n",
    "        adv_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Current adversarial test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current adversarial test loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign test accuarcy:', 100. * benign_correct / total)\n",
    "    print('Total adversarial test Accuarcy:', 100. * adv_correct / total)\n",
    "    print('Total benign test loss:', benign_loss)\n",
    "    print('Total adversarial test loss:', adv_loss)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6345f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 2.3160736560821533\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 5.190974235534668\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 3.223655939102173\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 2.56705379486084\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 2.2814841270446777\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 2.382124900817871\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 2.2685041427612305\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 2.354434013366699\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 2.1287925243377686\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 2.2841408252716064\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 2.1224727630615234\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 2.111345052719116\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 2.0045416355133057\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 2.0473756790161133\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 2.1519837379455566\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 2.006269931793213\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.8722373247146606\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.9158884286880493\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.9834343194961548\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 2.028040647506714\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.9330053329467773\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.9748812913894653\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.84067964553833\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.9248250722885132\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.8145018815994263\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.7839666604995728\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.7103554010391235\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.786760926246643\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.7534459829330444\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.5930432081222534\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.6818950176239014\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.6764380931854248\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.699041724205017\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.5833895206451416\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.5244039297103882\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.7349176406860352\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.3359375\n",
      "Current benign train loss: 1.7214943170547485\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.6661345958709717\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.5731312036514282\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.45\n",
      "Current benign train loss: 1.6589666604995728\n",
      "\n",
      "Total benign train accuarcy: 27.034\n",
      "Total benign train loss: 833.3112045526505\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.6094779968261719\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.7792613506317139\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.8116835355758667\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.4226136207580566\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.562622308731079\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.5653250217437744\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.5108058452606201\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.4740580320358276\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.679090142250061\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.532849669456482\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.4762080907821655\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.5969563722610474\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.4052549600601196\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.5158132314682007\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.4597481489181519\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.42933988571167\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.5016945600509644\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.1960316896438599\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.5504987239837646\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.4100185632705688\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.57850980758667\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.4512760639190674\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.5677374601364136\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.3889331817626953\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.3764636516571045\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.4124138355255127\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.2004239559173584\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.312437891960144\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.439122200012207\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.3641160726547241\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.2542850971221924\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.3563878536224365\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.253934383392334\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.2914613485336304\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.3870692253112793\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.3794111013412476\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.2322921752929688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.320539116859436\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.2123702764511108\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.525\n",
      "Current benign train loss: 1.4005134105682373\n",
      "\n",
      "Total benign train accuarcy: 47.812\n",
      "Total benign train loss: 562.6526744365692\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.3084170818328857\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.1531381607055664\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.2675633430480957\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.3285236358642578\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.22389554977417\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.1548556089401245\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.2282612323760986\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.1652740240097046\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.2463274002075195\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.2374119758605957\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.2092853784561157\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.23008131980896\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.0611331462860107\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.1491477489471436\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 0.9990296363830566\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.2246383428573608\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.2653892040252686\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.188194751739502\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.130653977394104\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.2334675788879395\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.216793417930603\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9788721203804016\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8147821426391602\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.0604695081710815\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.0093520879745483\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.07911217212677\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.2164554595947266\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.04667329788208\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.0255509614944458\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.845350444316864\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1550770998001099\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.203788161277771\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.1339516639709473\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.9298538565635681\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1121076345443726\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9749553799629211\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.0293067693710327\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.938154399394989\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.0085456371307373\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.675\n",
      "Current benign train loss: 0.8881975412368774\n",
      "\n",
      "Total benign train accuarcy: 59.598\n",
      "Total benign train loss: 438.5258864760399\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.0045832395553589\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8145062327384949\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 0.9238510131835938\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6672775149345398\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.8976604342460632\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 0.8847769498825073\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.96781986951828\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8142220377922058\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.9564411640167236\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.992345929145813\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.9118993878364563\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.9355201125144958\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8677381873130798\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.7999323606491089\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.8478477597236633\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8282347321510315\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8612380027770996\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8261264562606812\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.9501799941062927\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8355775475502014\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7902700901031494\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.933579683303833\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.8767989873886108\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8489358425140381\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8480762243270874\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.7613586187362671\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.1003276109695435\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.6964211463928223\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7351482510566711\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8642136454582214\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8400005102157593\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6881077885627747\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8234076499938965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8059946894645691\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8497375845909119\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.722388744354248\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7444250583648682\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.6802464723587036\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8250921368598938\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7125\n",
      "Current benign train loss: 0.760513186454773\n",
      "\n",
      "Total benign train accuarcy: 68.798\n",
      "Total benign train loss: 341.3352583050728\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6777499914169312\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6553971767425537\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6362960338592529\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.596015989780426\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7955018281936646\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6865713596343994\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6604131460189819\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5575671195983887\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9158030152320862\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7492636442184448\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7684565186500549\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.467305451631546\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.6951193809509277\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7319014072418213\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6309396028518677\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7862520813941956\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5702395439147949\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7421262264251709\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5216252207756042\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6708588600158691\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5856419801712036\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7042090892791748\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7206925749778748\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5545060634613037\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7715102434158325\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4649650752544403\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8516473770141602\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7095828056335449\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5710113048553467\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6525999903678894\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8637341856956482\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6069266200065613\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6032740473747253\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5472228527069092\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6128506660461426\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5597854852676392\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.726676344871521\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 0.8546388149261475\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5360403060913086\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7375\n",
      "Current benign train loss: 0.7047687768936157\n",
      "\n",
      "Total benign train accuarcy: 75.51\n",
      "Total benign train loss: 269.5730604529381\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6440231800079346\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3900795578956604\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.41632622480392456\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.53778076171875\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6553193926811218\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.4546891748905182\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3886741101741791\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.513128399848938\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6123178601264954\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6510051488876343\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.489196240901947\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5735282301902771\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.6012702584266663\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5185313820838928\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.701585054397583\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6904910206794739\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.6023963689804077\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5258879661560059\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7076221108436584\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6590251326560974\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4417405128479004\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5701894760131836\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.49321308732032776\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.5858862996101379\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4064215123653412\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5960986614227295\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5568179488182068\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6957019567489624\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6256722211837769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5545961856842041\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7379340529441833\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5442806482315063\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5808265805244446\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5572057962417603\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6540535092353821\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.43075114488601685\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.4306660294532776\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6184571981430054\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.44469231367111206\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8625\n",
      "Current benign train loss: 0.32730504870414734\n",
      "\n",
      "Total benign train accuarcy: 80.302\n",
      "Total benign train loss: 218.3290899693966\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4473865330219269\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4957037568092346\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3707512617111206\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.29872995615005493\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.36828961968421936\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3934183120727539\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4175623059272766\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3959316909313202\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5299493074417114\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.28116491436958313\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5516601800918579\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3615938127040863\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.365308552980423\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4530952572822571\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3592278063297272\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4696911573410034\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3702167868614197\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5801817178726196\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.38844025135040283\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5390104055404663\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3724643290042877\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.42067718505859375\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.42258986830711365\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3700293004512787\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3728305399417877\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4902937114238739\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.5668252110481262\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4201069176197052\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4339965581893921\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.36451175808906555\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6121181845664978\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5459454655647278\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.6401399374008179\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.42209360003471375\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4086713492870331\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5366241931915283\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.30781370401382446\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5796371102333069\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36684727668762207\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.825\n",
      "Current benign train loss: 0.48094820976257324\n",
      "\n",
      "Total benign train accuarcy: 84.224\n",
      "Total benign train loss: 174.86070573329926\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.25597602128982544\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3041554391384125\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2964474558830261\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3239227533340454\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.27135422825813293\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3072778284549713\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.32685983180999756\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.33907654881477356\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36064961552619934\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.25752753019332886\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.29132428765296936\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3976984918117523\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.33249565958976746\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4043682813644409\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4264598488807678\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3156003952026367\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.45880502462387085\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3690631687641144\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3052891492843628\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4594130516052246\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4016844928264618\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.40576493740081787\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.327653706073761\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.27797913551330566\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.46213507652282715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3723933696746826\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4044782519340515\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.35416489839553833\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.49436140060424805\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28983959555625916\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3020385205745697\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.358335018157959\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.39323320984840393\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2349407821893692\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4049549102783203\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.40698492527008057\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4474422037601471\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3222365975379944\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.38984668254852295\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8625\n",
      "Current benign train loss: 0.3975846767425537\n",
      "\n",
      "Total benign train accuarcy: 87.472\n",
      "Total benign train loss: 139.02836740016937\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22526246309280396\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20492342114448547\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.26438599824905396\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19227063655853271\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2109823077917099\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17426301538944244\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20232677459716797\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.37167975306510925\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.24598418176174164\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.24776318669319153\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14227928221225739\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29623302817344666\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16093547642230988\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.26655977964401245\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.26360517740249634\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.40126335620880127\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3014044463634491\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4258487820625305\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.32883787155151367\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.36352506279945374\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4611857831478119\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28054049611091614\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.22575783729553223\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3199920356273651\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3204239010810852\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2580150067806244\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2891186475753784\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.28842246532440186\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36996588110923767\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3585570454597473\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.31500163674354553\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.3788173198699951\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.37400245666503906\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2732050120830536\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2745112180709839\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3304005563259125\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4060574173927307\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3021974265575409\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2999817728996277\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8875\n",
      "Current benign train loss: 0.3118552565574646\n",
      "\n",
      "Total benign train accuarcy: 89.958\n",
      "Total benign train loss: 110.95808021724224\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.25788596272468567\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1633271425962448\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18612757325172424\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.18992333114147186\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15456318855285645\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1554780900478363\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1519555300474167\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.16117024421691895\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.28207847476005554\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2785918116569519\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16195407509803772\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.15240027010440826\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.22630834579467773\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18407107889652252\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16102294623851776\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16468441486358643\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.30335932970046997\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3089671730995178\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.333255797624588\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21097540855407715\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.16790227591991425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11722704023122787\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3313741087913513\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.24291172623634338\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.331556499004364\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17476634681224823\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2051490843296051\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36836498975753784\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3090769350528717\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1912224441766739\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.21578021347522736\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.19702434539794922\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2386246919631958\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.304155558347702\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3053221106529236\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.34728163480758667\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.34572306275367737\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2973363697528839\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24766553938388824\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8375\n",
      "Current benign train loss: 0.5147086977958679\n",
      "\n",
      "Total benign train accuarcy: 91.96\n",
      "Total benign train loss: 89.69463960826397\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.16272026300430298\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10874176025390625\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1809058040380478\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18799103796482086\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13352029025554657\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17087242007255554\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11544940620660782\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08813762664794922\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11869049072265625\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09416158497333527\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07605771720409393\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13024912774562836\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1063770204782486\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2241220772266388\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17979690432548523\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.21099960803985596\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2118622362613678\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12582381069660187\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2361048460006714\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09766558557748795\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2590166926383972\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2041529417037964\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1966141313314438\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2113783061504364\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20688501000404358\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13786692917346954\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.298109769821167\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22568975389003754\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.24374933540821075\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.28566572070121765\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.35267338156700134\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18969830870628357\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.25510379672050476\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2168666273355484\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2944745719432831\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22079142928123474\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22085273265838623\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18988795578479767\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.24125008285045624\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9\n",
      "Current benign train loss: 0.29707756638526917\n",
      "\n",
      "Total benign train accuarcy: 93.044\n",
      "Total benign train loss: 77.03875754028559\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09974891692399979\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07696207612752914\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12716810405254364\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05857512354850769\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2351912260055542\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08843036741018295\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08396060019731522\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10072518140077591\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10257311165332794\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11167889088392258\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06360801309347153\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16110314428806305\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08911148458719254\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10251946747303009\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11327984929084778\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1804206669330597\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10965842753648758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24526730179786682\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13776895403862\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1431620866060257\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1624004989862442\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10586819797754288\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13604561984539032\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16259527206420898\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1611875742673874\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20468899607658386\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21695002913475037\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2323136329650879\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19363272190093994\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19972193241119385\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2656029462814331\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.23676559329032898\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22974176704883575\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22844922542572021\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2046063095331192\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1794363558292389\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2086637318134308\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24504587054252625\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12580181658267975\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.1200643926858902\n",
      "\n",
      "Total benign train accuarcy: 94.374\n",
      "Total benign train loss: 62.95292567834258\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1659911572933197\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1394103467464447\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11563809961080551\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04059422016143799\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.1907235085964203\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07492159307003021\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10928632318973541\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11824896931648254\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06321856379508972\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16856542229652405\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12928852438926697\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09395001828670502\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08330381661653519\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1085621789097786\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15617264807224274\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10159091651439667\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14475250244140625\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16806970536708832\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11803718656301498\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2725580930709839\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17484097182750702\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12280340492725372\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09039229154586792\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14098919928073883\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17009928822517395\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2704501152038574\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12826406955718994\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20104943215847015\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22380290925502777\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15139509737491608\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08824248611927032\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10738781094551086\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22950588166713715\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1149175688624382\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10753245651721954\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22601309418678284\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14065738022327423\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3606659471988678\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.182774618268013\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9125\n",
      "Current benign train loss: 0.21482577919960022\n",
      "\n",
      "Total benign train accuarcy: 94.916\n",
      "Total benign train loss: 55.97470019757748\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11800412833690643\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08554571121931076\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.055561814457178116\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04685681685805321\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11735749244689941\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0618814155459404\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11821961402893066\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08698272705078125\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.080802321434021\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07658303529024124\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12489515542984009\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03306102380156517\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1511458158493042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04275418817996979\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08318052440881729\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08815289288759232\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.176901713013649\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.17399998009204865\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12699773907661438\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10928905755281448\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09826367348432541\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12942849099636078\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08623838424682617\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12563858926296234\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.14783930778503418\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1962350308895111\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13426461815834045\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09860357642173767\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13582301139831543\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08859389275312424\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15723805129528046\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20118528604507446\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.29878225922584534\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15975140035152435\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2192080169916153\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10947054624557495\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1350989192724228\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1817086935043335\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1446780413389206\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1195271760225296\n",
      "\n",
      "Total benign train accuarcy: 95.826\n",
      "Total benign train loss: 47.480094658210874\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1307770013809204\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05408375710248947\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07008770853281021\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.053113020956516266\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15641896426677704\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09255506098270416\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1746509075164795\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10519247502088547\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05197452753782272\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13018381595611572\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10352015495300293\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12244115024805069\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07119975239038467\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10784474015235901\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10991594195365906\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15230679512023926\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13604803383350372\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11285267770290375\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10488240420818329\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10750912129878998\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.059883829206228256\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12226793169975281\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06612026691436768\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08780087530612946\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1077975407242775\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1106439009308815\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16017992794513702\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16720743477344513\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.191584974527359\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09560301899909973\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.2095002382993698\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10789816826581955\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20605821907520294\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10816746950149536\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24632635712623596\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17026223242282867\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12122015655040741\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16346412897109985\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10629415512084961\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9125\n",
      "Current benign train loss: 0.1967141032218933\n",
      "\n",
      "Total benign train accuarcy: 95.774\n",
      "Total benign train loss: 47.78195529989898\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09435917437076569\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07194356620311737\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09070511907339096\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08785271644592285\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09843514859676361\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.1028807982802391\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1339365690946579\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10079320520162582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.104796402156353\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07844322919845581\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08961756527423859\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08386548608541489\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048423297703266144\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06915376335382462\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09124258905649185\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13577504456043243\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04597577825188637\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08354485034942627\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1180795282125473\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09338197112083435\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05887375771999359\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09843628108501434\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09598278254270554\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.27428656816482544\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11796478927135468\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07965312153100967\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09423980861902237\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1391918808221817\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12782226502895355\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13601838052272797\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17255882918834686\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09315558522939682\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07596200704574585\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.21063897013664246\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19057580828666687\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12151780724525452\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12412849813699722\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10306492447853088\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08606898039579391\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22695736587047577\n",
      "\n",
      "Total benign train accuarcy: 96.256\n",
      "Total benign train loss: 42.357611287385225\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09928854554891586\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07902792096138\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05633687227964401\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13359063863754272\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05181685835123062\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13158400356769562\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.054652124643325806\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10415790975093842\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10196437686681747\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037704143673181534\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07132307440042496\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0937219187617302\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04883730039000511\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08152127265930176\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11076917499303818\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09108243882656097\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2487405389547348\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06490747630596161\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18274833261966705\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05996116250753403\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11787481606006622\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059406083077192307\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0912661999464035\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06696457415819168\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16042540967464447\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08521745353937149\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07210016995668411\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07318530976772308\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17903685569763184\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.16690263152122498\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07412903010845184\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.25850656628608704\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11219028383493423\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20934957265853882\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11731774359941483\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1903631091117859\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1412487030029297\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.25318047404289246\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09613139927387238\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.12465260922908783\n",
      "\n",
      "Total benign train accuarcy: 96.006\n",
      "Total benign train loss: 44.221715876832604\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031063105911016464\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.144608736038208\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08644487708806992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.07057306170463562\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07697802782058716\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08683085441589355\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10612337291240692\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0836845189332962\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09282189607620239\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14680461585521698\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04174146056175232\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06504335254430771\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13820412755012512\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06726162135601044\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05833898484706879\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07434426993131638\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0900692492723465\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08708338439464569\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08697579056024551\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06320566684007645\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04927019774913788\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059967268258333206\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1430577039718628\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08187366276979446\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10750894993543625\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09919000416994095\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07794757187366486\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14362163841724396\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08578052371740341\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07962917536497116\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13815048336982727\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19889791309833527\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1405632048845291\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1274154782295227\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0900735929608345\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08846519142389297\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10970363020896912\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.07301054894924164\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13136042654514313\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.10965421050786972\n",
      "\n",
      "Total benign train accuarcy: 96.588\n",
      "Total benign train loss: 38.32763183861971\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030848031863570213\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06985832750797272\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05436977371573448\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10602112859487534\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0457884781062603\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08259420841932297\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09310011565685272\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.056982629001140594\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08202110230922699\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07323665916919708\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09394603222608566\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03412608802318573\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10110750794410706\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1213655099272728\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06162988021969795\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04370774328708649\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14823344349861145\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.048617709428071976\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07870984822511673\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13487258553504944\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07228688895702362\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09533969312906265\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0714864656329155\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1085972711443901\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1476946473121643\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10863633453845978\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06044790521264076\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.09778974950313568\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15663792192935944\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06427282094955444\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16580109298229218\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10702675580978394\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15572680532932281\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09305489808320999\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10240084677934647\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.14243677258491516\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.078709676861763\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08575791865587234\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18768443167209625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9\n",
      "Current benign train loss: 0.23756404221057892\n",
      "\n",
      "Total benign train accuarcy: 96.512\n",
      "Total benign train loss: 39.00110054202378\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03773192688822746\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0629817396402359\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14950086176395416\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.028716668486595154\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0813896507024765\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06906281411647797\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05343806371092796\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13201172649860382\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08453430980443954\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06466536968946457\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08735401928424835\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07921619713306427\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08038727939128876\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05118010565638542\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11829477548599243\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10803484916687012\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1170128732919693\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06187150254845619\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0679602324962616\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11277373880147934\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13650132715702057\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045428600162267685\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11745459586381912\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07491099834442139\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0869964137673378\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07093805074691772\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12924174964427948\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0810568705201149\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10664943605661392\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05797756090760231\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10345233231782913\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09071548283100128\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06556263566017151\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0803103893995285\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.16667163372039795\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11363595724105835\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13908587396144867\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1609000414609909\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1616571843624115\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14497420191764832\n",
      "\n",
      "Total benign train accuarcy: 96.632\n",
      "Total benign train loss: 37.17382675781846\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02956809289753437\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10866226255893707\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10952939093112946\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13920609652996063\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047611381858587265\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09633670747280121\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07196744531393051\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05549926310777664\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04281005263328552\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0765010342001915\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05926590785384178\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10300672799348831\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.020214898511767387\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03993310406804085\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07858655601739883\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09910905361175537\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14162373542785645\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12232131510972977\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0439910814166069\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08651568740606308\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.060921333730220795\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09318232536315918\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04967804625630379\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11449816077947617\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1725589781999588\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.18628127872943878\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1301315426826477\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048275548964738846\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09261216223239899\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22615842521190643\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15392428636550903\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1024441197514534\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06901156157255173\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1035294309258461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.21164946258068085\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18812380731105804\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11005780845880508\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0992274135351181\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1173606663942337\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.09335646033287048\n",
      "\n",
      "Total benign train accuarcy: 96.516\n",
      "Total benign train loss: 38.57545283995569\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07214739173650742\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11005868017673492\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11474256217479706\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.034819986671209335\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09766113758087158\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10603712499141693\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05413522571325302\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.029034772887825966\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04883522167801857\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11909917742013931\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06361281871795654\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051767874509096146\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06427991390228271\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025563793256878853\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14996691048145294\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06421034038066864\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06032419204711914\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.033716022968292236\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10852132737636566\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11499079316854477\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07799100130796432\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0988880842924118\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.15845239162445068\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0794418528676033\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08411860466003418\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09120245277881622\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10587547719478607\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12933005392551422\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15752848982810974\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21121132373809814\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06095799431204796\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08735478669404984\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06887716799974442\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2131008803844452\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14912238717079163\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06900165230035782\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0773172676563263\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059210579842329025\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13067911565303802\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.20416657626628876\n",
      "\n",
      "Total benign train accuarcy: 96.832\n",
      "Total benign train loss: 36.137764010578394\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10056504607200623\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05784608796238899\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031718842685222626\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05003168806433678\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06976421177387238\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05930526927113533\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09149041771888733\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07567107677459717\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06750811636447906\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06576485186815262\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10461080074310303\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.041809652000665665\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.054188817739486694\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10785014927387238\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13035736978054047\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013079635798931122\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19666308164596558\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0854366198182106\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06831412762403488\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09911941736936569\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09431876242160797\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05857732146978378\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10403841733932495\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09353777766227722\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15474702417850494\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06121944636106491\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13196434080600739\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11400088667869568\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14211110770702362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07755143195390701\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1527591049671173\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12047974020242691\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1530785709619522\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09382721781730652\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12443318963050842\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1582743525505066\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08679292351007462\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10355039685964584\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09563533961772919\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.12330470979213715\n",
      "\n",
      "Total benign train accuarcy: 97.064\n",
      "Total benign train loss: 33.44692820310593\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03210677579045296\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05783132463693619\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06792968511581421\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06212018430233002\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03662587329745293\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07404319941997528\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.063850998878479\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05362468212842941\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.051512137055397034\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05239849165081978\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05880490317940712\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07379139959812164\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02198738418519497\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.049569882452487946\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06900689005851746\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07019577920436859\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.061183780431747437\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06861159205436707\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09344785660505295\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07612419873476028\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07941734790802002\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.145210862159729\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12476804107427597\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18898583948612213\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1041586622595787\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029671087861061096\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05120972543954849\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08264464139938354\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08553089946508408\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11626987904310226\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10033243149518967\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.16956967115402222\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07131887972354889\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13695372641086578\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1323864758014679\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04226153716444969\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.21913723647594452\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14286157488822937\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.06497417390346527\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.13376761972904205\n",
      "\n",
      "Total benign train accuarcy: 96.938\n",
      "Total benign train loss: 34.68724640645087\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.057538311928510666\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06959229707717896\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.07240666449069977\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03817194327712059\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09523405879735947\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05094081163406372\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0925772413611412\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047289345413446426\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03178863227367401\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07523973286151886\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03881652280688286\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07877442985773087\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.060726236552000046\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03901466727256775\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06166001409292221\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0473296158015728\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08931800723075867\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05140861123800278\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015495695173740387\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07798774540424347\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06926658004522324\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09781315922737122\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09690525382757187\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07883156836032867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08822771161794662\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10877048224210739\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17527391016483307\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08818400651216507\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11847937107086182\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1499386876821518\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0988600105047226\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15305814146995544\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07962065190076828\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06194907799363136\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06473010033369064\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09028184413909912\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06070488318800926\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06453217566013336\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1157974973320961\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.09240146726369858\n",
      "\n",
      "Total benign train accuarcy: 97.052\n",
      "Total benign train loss: 33.67779075540602\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.046697817742824554\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045052073895931244\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.056176625192165375\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.027838226407766342\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0762203112244606\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03004871867597103\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09199779480695724\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04834451898932457\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.049200721085071564\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.049385521560907364\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08173208683729172\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0657305046916008\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08145607262849808\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06824585050344467\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.035255879163742065\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06341235339641571\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.090126633644104\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05575549229979515\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04171907156705856\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08176138997077942\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0784425288438797\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08528485149145126\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06442692875862122\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19393354654312134\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1039668396115303\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17343738675117493\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.053578224033117294\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11329351365566254\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10830572992563248\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0650339424610138\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1842775195837021\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06697278469800949\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1655372828245163\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16559772193431854\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16090597212314606\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10268782079219818\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08897843956947327\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15826761722564697\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10485891997814178\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1472684144973755\n",
      "\n",
      "Total benign train accuarcy: 96.886\n",
      "Total benign train loss: 35.67264294158667\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.043128907680511475\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07502914220094681\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12055552005767822\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06535742431879044\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07625827193260193\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05382193252444267\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.07477826625108719\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.053563281893730164\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.040862392634153366\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05722707882523537\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014446976594626904\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03283357992768288\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03770722076296806\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06606869399547577\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05801790580153465\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06302540749311447\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.037979982793331146\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09022903442382812\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10991973429918289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.029036307707428932\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03905678167939186\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09709110856056213\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11709237843751907\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07014213502407074\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11280082166194916\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04616929218173027\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08070395141839981\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13436685502529144\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09050485491752625\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11363710463047028\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11419367045164108\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16293135285377502\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09100756794214249\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046652909368276596\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.052284467965364456\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04357854649424553\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07028704136610031\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06317860633134842\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13840164244174957\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.08966324478387833\n",
      "\n",
      "Total benign train accuarcy: 97.12\n",
      "Total benign train loss: 32.671504753641784\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02157163992524147\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07202670723199844\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12367011606693268\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07200484722852707\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1311870962381363\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05136757716536522\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08624361455440521\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.042443595826625824\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036079999059438705\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061200883239507675\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.053952883929014206\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03524630144238472\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0412689670920372\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0565296895802021\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08289185911417007\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03723010793328285\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03588113561272621\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09457744657993317\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02694685198366642\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04394638165831566\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07071372866630554\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07741338014602661\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07902587205171585\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11952446401119232\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03988815099000931\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09016122668981552\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06878291070461273\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06774260848760605\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03669483959674835\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09791196137666702\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09994620084762573\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1717626005411148\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1289833039045334\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10541921854019165\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12865033745765686\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0893377810716629\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.09734436124563217\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10982394963502884\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06362111866474152\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1753663271665573\n",
      "\n",
      "Total benign train accuarcy: 97.228\n",
      "Total benign train loss: 31.28119333088398\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02946378104388714\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18023180961608887\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05120992660522461\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06907675415277481\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07946787029504776\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09150617569684982\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0782807245850563\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12718024849891663\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06534229218959808\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0948294922709465\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1389666348695755\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07394861429929733\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10469415038824081\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04896029084920883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04471215605735779\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1187867745757103\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2291889637708664\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06649737060070038\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13204149901866913\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08820323646068573\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08246959745883942\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1702895611524582\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0751420333981514\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10180919617414474\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12281472980976105\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05338827520608902\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10715815424919128\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0643964633345604\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10742354393005371\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13340923190116882\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07582475244998932\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06219238415360451\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03190508857369423\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07286463677883148\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0664234608411789\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10637329518795013\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15624448657035828\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09533865004777908\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04505690932273865\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.1033220887184143\n",
      "\n",
      "Total benign train accuarcy: 97.25\n",
      "Total benign train loss: 31.53694441355765\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04223419353365898\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061220910400152206\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03525281324982643\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12258212268352509\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08463426679372787\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05269765481352806\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044291477650403976\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1066960021853447\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08367215096950531\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.055433884263038635\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10627823323011398\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025137970224022865\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12921014428138733\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12283589690923691\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09195198863744736\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06985924392938614\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06909757107496262\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11966505646705627\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15633399784564972\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10065747052431107\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07406631857156754\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11921350657939911\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08434849977493286\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12006548047065735\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14246389269828796\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12257754057645798\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04455244168639183\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14735820889472961\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.08277150243520737\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10564310103654861\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.035099998116493225\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18370568752288818\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12471918016672134\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14643482863903046\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025539781898260117\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06967493891716003\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10320384800434113\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16377301514148712\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09921101480722427\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.05122853443026543\n",
      "\n",
      "Total benign train accuarcy: 96.684\n",
      "Total benign train loss: 36.98899429105222\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11639371514320374\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11502563208341599\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037260331213474274\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06655895709991455\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.2029636800289154\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11521568149328232\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.041926637291908264\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04246383532881737\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.033431779593229294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04349091649055481\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07624372094869614\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.013452581129968166\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010147081688046455\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04429982230067253\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12562021613121033\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1227058544754982\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.07547163963317871\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10207591950893402\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07489151507616043\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06376396119594574\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11841219663619995\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07805005460977554\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06044185534119606\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07380969822406769\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030210359022021294\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07234648615121841\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021305793896317482\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05619062855839729\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14640824496746063\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.044036488980054855\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11991246044635773\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09028317034244537\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1064123660326004\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06690537929534912\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10569841414690018\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06443027406930923\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08279158920049667\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09029026329517365\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07086176425218582\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.12226314842700958\n",
      "\n",
      "Total benign train accuarcy: 97.346\n",
      "Total benign train loss: 29.843567369505763\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05212854593992233\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037509020417928696\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05596501752734184\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06452085822820663\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03455730527639389\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05146074295043945\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0736125186085701\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04528188332915306\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04870127886533737\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04595880210399628\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061767637729644775\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09834445267915726\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14673683047294617\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03687896579504013\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09322123974561691\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09349513798952103\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04014812409877777\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08539296686649323\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09816214442253113\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09066037833690643\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13081666827201843\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07293450087308884\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09732510894536972\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18007883429527283\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07432279735803604\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10669542104005814\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07688423246145248\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06428979337215424\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06381978839635849\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17722035944461823\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14882443845272064\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07230919599533081\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17774207890033722\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11644408106803894\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08060232549905777\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.1810786873102188\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14405381679534912\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06522820889949799\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10354835540056229\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.07981117814779282\n",
      "\n",
      "Total benign train accuarcy: 96.938\n",
      "Total benign train loss: 34.08816622430459\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03768035024404526\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.128230020403862\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02055244892835617\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.055402811616659164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05745328590273857\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07841292768716812\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06691701710224152\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.041545283049345016\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09273079037666321\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.053161513060331345\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05207934230566025\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07741652429103851\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04453184828162193\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026828600093722343\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017442859709262848\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.043101344257593155\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07722797989845276\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06819994747638702\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03756034001708031\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0604865588247776\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05544956028461456\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06580329686403275\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1417967826128006\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08617334812879562\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0512826032936573\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1000630334019661\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09631411731243134\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08319247514009476\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12321539968252182\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.055586397647857666\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11879508197307587\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05007827654480934\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06487750262022018\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13605865836143494\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08413751423358917\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1988540142774582\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1890767365694046\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2385040521621704\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15583983063697815\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.04563208296895027\n",
      "\n",
      "Total benign train accuarcy: 97.202\n",
      "Total benign train loss: 32.22344357240945\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09145773202180862\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0536617785692215\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06260602176189423\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1355241984128952\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04729921743273735\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12460269778966904\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03886674344539642\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06539785116910934\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03448755666613579\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.046348173171281815\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06261567026376724\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15734301507472992\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047854986041784286\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04911133274435997\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03898511826992035\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03322500362992287\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05453095585107803\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06143774837255478\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09071803092956543\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09802532941102982\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06083573400974274\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04951128736138344\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045560918748378754\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04448608681559563\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037651825696229935\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07669685035943985\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09048422425985336\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08658450841903687\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.017460811883211136\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.058666251599788666\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06782307475805283\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06619513034820557\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06395188719034195\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09318522363901138\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16313637793064117\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18114346265792847\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07373429834842682\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14292988181114197\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10746923834085464\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.05622253939509392\n",
      "\n",
      "Total benign train accuarcy: 97.476\n",
      "Total benign train loss: 28.924551466479897\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06000616028904915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.054277852177619934\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08781681209802628\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08053611218929291\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05172918364405632\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08403963595628738\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.054205864667892456\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03303660452365875\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0548759400844574\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04161430522799492\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01817002333700657\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0922209769487381\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0768384039402008\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.046184662729501724\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026365753263235092\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09460290521383286\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04884077608585358\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04263107851147652\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15301766991615295\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05840562283992767\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04410041496157646\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02872496098279953\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017679978162050247\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0656803771853447\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07269147783517838\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08518234640359879\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.032233547419309616\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04896589368581772\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.054557714611291885\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10616479068994522\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02692180685698986\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07882751524448395\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07768797874450684\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10155719518661499\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1742013692855835\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08225743472576141\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06841742247343063\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13173717260360718\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1757402867078781\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.15047477185726166\n",
      "\n",
      "Total benign train accuarcy: 97.488\n",
      "Total benign train loss: 29.458946409635246\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04179250821471214\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13388663530349731\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09898023307323456\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06473797559738159\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08130032569169998\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05841118097305298\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03988884016871452\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09770072996616364\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.044204384088516235\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13378630578517914\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11137805134057999\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06327589601278305\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06980257481336594\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15462690591812134\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05838518217206001\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.038255151361227036\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07170028984546661\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.054855525493621826\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04290226474404335\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10577931255102158\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07762385159730911\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10623832792043686\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0455809123814106\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08708551526069641\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03145340085029602\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036279644817113876\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06333669275045395\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07457032054662704\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13101133704185486\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16648967564105988\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05532322824001312\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0669253021478653\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03893350064754486\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16680878400802612\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11113067716360092\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07606680691242218\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10384489595890045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16826222836971283\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06170498579740524\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.09328239411115646\n",
      "\n",
      "Total benign train accuarcy: 97.35\n",
      "Total benign train loss: 30.075608337298036\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.10592338442802429\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07235196232795715\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0338401272892952\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036562711000442505\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04679648205637932\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11730308830738068\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0494878776371479\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06797007471323013\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08731997758150101\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.023892443627119064\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0861324742436409\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0823388621211052\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028588498011231422\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07459429651498795\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07811770588159561\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06513280421495438\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12282044440507889\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06816436350345612\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11220594495534897\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08751385658979416\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09710557013750076\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.089970164000988\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08171237260103226\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08879050612449646\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08521159738302231\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14609898626804352\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0885973647236824\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11607681959867477\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07923633605241776\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09871021658182144\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06032325327396393\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.038817230612039566\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12129668891429901\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.10267868638038635\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04069940745830536\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08258535712957382\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08221737295389175\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07806487381458282\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05500083789229393\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.09319426119327545\n",
      "\n",
      "Total benign train accuarcy: 97.102\n",
      "Total benign train loss: 32.487302577123046\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09767477959394455\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0803203210234642\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050260383635759354\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05446510389447212\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07015588879585266\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.033522479236125946\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0777202844619751\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08083459734916687\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14188043773174286\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08127853274345398\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06279484182596207\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05818118527531624\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10308002680540085\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04314352199435234\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14725692570209503\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05975092574954033\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.18102490901947021\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0892520621418953\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06453384459018707\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12497147172689438\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06450704485177994\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11067365109920502\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10463995486497879\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05194069445133209\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10805229097604752\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11142574995756149\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07206340879201889\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11387915164232254\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06503769010305405\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13674572110176086\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.062395643442869186\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06168113648891449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15141557157039642\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08114109188318253\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2473011463880539\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.19525425136089325\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14532874524593353\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.23957955837249756\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.28987038135528564\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14014345407485962\n",
      "\n",
      "Total benign train accuarcy: 97.22\n",
      "Total benign train loss: 31.666991421952844\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08315713703632355\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14931875467300415\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04717647656798363\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06396951526403427\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05615311488509178\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07113078981637955\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06948450952768326\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05804489180445671\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05497543513774872\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06526313722133636\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030519183725118637\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.110322006046772\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044625457376241684\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015109563246369362\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09910012781620026\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.068975530564785\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11371968686580658\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08222658187150955\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0762099176645279\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08711905032396317\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.18302977085113525\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05269269645214081\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10541389882564545\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04903670400381088\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05744936689734459\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07513328641653061\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07820729166269302\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11075378954410553\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1696842908859253\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05055224150419235\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03786756470799446\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1648009866476059\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.064239501953125\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05361366271972656\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05046027898788452\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.023648617789149284\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04913674667477608\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07936794310808182\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06239727884531021\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 0.12487940490245819\n",
      "\n",
      "Total benign train accuarcy: 97.552\n",
      "Total benign train loss: 27.62114387191832\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026793263852596283\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0689118355512619\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07815135270357132\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04313303902745247\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02978709526360035\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045954909175634384\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04205235838890076\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04166077449917793\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027286546304821968\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05324465408921242\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07474123686552048\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08240808546543121\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0625837966799736\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07628042250871658\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.049657098948955536\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04777766764163971\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01584777608513832\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06158946081995964\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026251962408423424\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09590861201286316\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06731586158275604\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07552056759595871\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15017275512218475\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06704321503639221\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07037126272916794\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021138332784175873\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1293347179889679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10089536011219025\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10671490430831909\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.060233183205127716\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11107983440160751\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21736276149749756\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0648084506392479\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08439984917640686\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17815297842025757\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1064276397228241\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04031139984726906\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09062352031469345\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1593787670135498\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.10763387382030487\n",
      "\n",
      "Total benign train accuarcy: 97.406\n",
      "Total benign train loss: 29.443921602331102\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07640495151281357\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017210286110639572\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07211745530366898\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09137830883264542\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02550654485821724\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04181481897830963\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.1022891029715538\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05784790590405464\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.059699852019548416\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03519746661186218\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0708184465765953\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0792916938662529\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05883975327014923\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15159130096435547\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061165254563093185\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0853959172964096\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08237576484680176\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1210818886756897\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17035089433193207\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10244501382112503\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04460487142205238\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16540184617042542\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.17346635460853577\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.058706317096948624\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05418583005666733\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05183779075741768\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11804623156785965\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09111607819795609\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06601855903863907\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10296426713466644\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07969722896814346\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12004038691520691\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03947055712342262\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08388125896453857\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09044677764177322\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07164817303419113\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08127883821725845\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1568748503923416\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09719433635473251\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.036833662539720535\n",
      "\n",
      "Total benign train accuarcy: 97.1\n",
      "Total benign train loss: 33.16375629417598\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10087009519338608\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05727039650082588\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04268861189484596\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04581306874752045\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07248254865407944\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04963086172938347\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06767160445451736\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03499607369303703\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.062499918043613434\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04679446667432785\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025858519598841667\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04577659070491791\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07489032298326492\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07084398716688156\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03873700648546219\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08246218413114548\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1224507987499237\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05445520579814911\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.15323372185230255\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08326158672571182\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05333978682756424\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07062288373708725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06184689328074455\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13256892561912537\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13082841038703918\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0665111243724823\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16015703976154327\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05975193902850151\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1376534253358841\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05004049465060234\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08012913912534714\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.051297981292009354\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03689039871096611\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11285161226987839\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11472833156585693\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10210930556058884\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08757553994655609\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06332090497016907\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08600743114948273\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.10555233061313629\n",
      "\n",
      "Total benign train accuarcy: 97.41\n",
      "Total benign train loss: 28.998218312859535\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07393597811460495\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.032503314316272736\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06059702858328819\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10559467226266861\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08993787318468094\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08336785435676575\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07117964327335358\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05347247049212456\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02822505310177803\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07816560566425323\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.057397350668907166\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04485155642032623\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14548209309577942\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08161480724811554\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06109548732638359\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06631389260292053\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09739531576633453\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04968295246362686\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03641383349895477\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0330168791115284\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04256032407283783\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05661613494157791\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04788171872496605\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1298179179430008\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1488182693719864\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05136134475469589\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12328867614269257\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19643674790859222\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06939083337783813\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1707126945257187\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0813220888376236\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08600594848394394\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1153794452548027\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11966556310653687\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15332211554050446\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08888789266347885\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04372575506567955\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.21444310247898102\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13691172003746033\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.08838130533695221\n",
      "\n",
      "Total benign train accuarcy: 97.274\n",
      "Total benign train loss: 30.632925155572593\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05160847306251526\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0847901701927185\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.037668295204639435\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07689651101827621\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025352545082569122\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027561916038393974\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039686352014541626\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04372604563832283\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06927170604467392\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04117426648736\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.063290074467659\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03151177242398262\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09869561344385147\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031821414828300476\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09302939474582672\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021528156474232674\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05265199393033981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047268372029066086\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03856020048260689\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030981745570898056\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05855150520801544\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016609590500593185\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02554612047970295\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11813727021217346\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09504225850105286\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027939943596720695\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1280423402786255\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04392147436738014\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07860324531793594\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04383886232972145\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08899962902069092\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03875964507460594\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07637864351272583\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1730915606021881\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.042554546147584915\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08212870359420776\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08657221496105194\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09153006970882416\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09621024876832962\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.11790768802165985\n",
      "\n",
      "Total benign train accuarcy: 97.52\n",
      "Total benign train loss: 28.138374112546444\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034731779247522354\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042477622628211975\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1138649731874466\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031863268464803696\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0837974026799202\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08383575826883316\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04582439363002777\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03619720786809921\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08781521767377853\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04720902070403099\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06001215800642967\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07567163556814194\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08201023936271667\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06542690098285675\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08046206086874008\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05023851990699768\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07962918281555176\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059376735240221024\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05682961270213127\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06496750563383102\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09065249562263489\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05464458093047142\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10470719635486603\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0987151563167572\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.049624864012002945\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09462772309780121\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.049786318093538284\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048452574759721756\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.07828769832849503\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07996954023838043\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03593827784061432\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0791984423995018\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.20685087144374847\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13228246569633484\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.046137161552906036\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02973189949989319\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09522829949855804\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0672789067029953\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13048556447029114\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.10340577363967896\n",
      "\n",
      "Total benign train accuarcy: 97.468\n",
      "Total benign train loss: 28.70527034625411\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10173627734184265\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07328654825687408\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.058024246245622635\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06034431606531143\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037385836243629456\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05090295895934105\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04330449551343918\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.056174516677856445\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06640727072954178\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.037442490458488464\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07621272653341293\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09062538295984268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03314352408051491\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030352963134646416\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02788485959172249\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1040869951248169\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09599959850311279\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11132069677114487\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14547908306121826\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10655616223812103\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045000962913036346\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0421091690659523\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13171260058879852\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059509314596652985\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13267023861408234\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1663663238286972\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1198229193687439\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10394798964262009\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06759722530841827\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09890681505203247\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06099240481853485\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13550958037376404\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08088972419500351\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09903834760189056\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.14878758788108826\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.050978004932403564\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07165930420160294\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.09771569073200226\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08778209984302521\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13668572902679443\n",
      "\n",
      "Total benign train accuarcy: 97.13\n",
      "Total benign train loss: 33.10782880336046\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014897606335580349\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09910612553358078\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05161304026842117\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11461111903190613\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06544636189937592\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07001961022615433\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.031139450147747993\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05581146478652954\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03844069689512253\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.034398797899484634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.024346167221665382\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04843371361494064\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031739674508571625\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12180657684803009\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02602798491716385\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034959591925144196\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.060232680290937424\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028883397579193115\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10925653576850891\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08207856863737106\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03303726762533188\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06041213497519493\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05680987238883972\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05541342869400978\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06662958115339279\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04640769213438034\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07583481818437576\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10116945952177048\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10402430593967438\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2632552683353424\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1830821931362152\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19198793172836304\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.12564164400100708\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.14195464551448822\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07528034597635269\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06371831893920898\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06541314721107483\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08895500749349594\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.13313539326190948\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.08968096226453781\n",
      "\n",
      "Total benign train accuarcy: 97.538\n",
      "Total benign train loss: 28.363750343210995\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.044531043618917465\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037359438836574554\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03868955373764038\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03120204620063305\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07190771400928497\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.032562561333179474\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0716269314289093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0505489781498909\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02350626513361931\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0581294409930706\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06677457690238953\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01924813911318779\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0976581946015358\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03472784906625748\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.039619382470846176\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.029429864138364792\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05700250342488289\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07953716814517975\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04831566661596298\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0359376035630703\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11022913455963135\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014304826967418194\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12132561951875687\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05234505608677864\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04596059024333954\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09895028173923492\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.043254390358924866\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.1086406484246254\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.057264234870672226\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042178068310022354\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06976386904716492\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.042752157896757126\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07821808755397797\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06797447055578232\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05569760501384735\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06782245635986328\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1371159702539444\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06832756102085114\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.188099667429924\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.06258887052536011\n",
      "\n",
      "Total benign train accuarcy: 97.806\n",
      "Total benign train loss: 24.906475751660764\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.023032179102301598\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07842835038900375\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11283519119024277\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06834838539361954\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.057367194443941116\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009595662355422974\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04117589816451073\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06838775426149368\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.055397290736436844\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028818737715482712\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0742325484752655\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01819000393152237\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.032352253794670105\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08193077892065048\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06543818861246109\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07836584746837616\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06579066067934036\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05810375511646271\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06896558403968811\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06282960623502731\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10627751797437668\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3140958547592163\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0560993030667305\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04137615114450455\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.056385498493909836\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11850796639919281\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10431159287691116\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18893441557884216\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0355127677321434\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06201634183526039\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08401922881603241\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0836874395608902\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.172842875123024\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12427455931901932\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07725536078214645\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06563346087932587\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04155369848012924\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0345810241997242\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11186186224222183\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.05954846739768982\n",
      "\n",
      "Total benign train accuarcy: 97.424\n",
      "Total benign train loss: 30.151897218078375\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04045974090695381\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03848382458090782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05254947394132614\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09114720672369003\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06184228137135506\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046420905739068985\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06136724352836609\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07206987589597702\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06261776387691498\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021688813343644142\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05102955177426338\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08174638450145721\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10971563309431076\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10593666136264801\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09994889795780182\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06358760595321655\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026631513610482216\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04067089036107063\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05325835943222046\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07199595868587494\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10766134411096573\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0787465050816536\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0877731591463089\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10163110494613647\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05974509194493294\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06393925100564957\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07463939487934113\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03848213702440262\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07959304004907608\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07681667804718018\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03788130730390549\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.22448085248470306\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14920581877231598\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054349735379219055\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.043077223002910614\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10085445642471313\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06248778477311134\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059536099433898926\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1462409347295761\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9125\n",
      "Current benign train loss: 0.23736169934272766\n",
      "\n",
      "Total benign train accuarcy: 97.536\n",
      "Total benign train loss: 28.090597949922085\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07981500029563904\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039797574281692505\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05442393571138382\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052669599652290344\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18679864704608917\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04940010979771614\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0854932963848114\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06526201963424683\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03128519654273987\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039929598569869995\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030859127640724182\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09874074906110764\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036375634372234344\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06381922960281372\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05232110992074013\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0956946313381195\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17477154731750488\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11856590211391449\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07597829401493073\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12704233825206757\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09481196105480194\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07030937075614929\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0687916949391365\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10461103171110153\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03469139337539673\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03484321013092995\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.056928616017103195\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07289436459541321\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14395280182361603\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03191224858164787\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.1020466685295105\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0488363653421402\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06746785342693329\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11724383383989334\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10870495438575745\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09488912671804428\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12077075242996216\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10574983805418015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04205571487545967\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.07917355000972748\n",
      "\n",
      "Total benign train accuarcy: 97.278\n",
      "Total benign train loss: 31.25972031801939\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046253006905317307\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04528095945715904\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05840891972184181\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11409521847963333\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.024472961202263832\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10079161077737808\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025793077424168587\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05108025670051575\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03407103568315506\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09046780318021774\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08634860068559647\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10981841385364532\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07060202956199646\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.021349428221583366\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05723683536052704\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09395414590835571\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0716288834810257\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04188968613743782\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08451374620199203\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07528121769428253\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06678371876478195\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07898437976837158\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04852832481265068\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06498534232378006\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007156386040151119\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06341385841369629\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08308184146881104\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12165279686450958\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.06878542900085449\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12516619265079498\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07798339426517487\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10789618641138077\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0779084712266922\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07918474078178406\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0717306137084961\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04109838232398033\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08600303530693054\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.040224894881248474\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05743441358208656\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.1151827797293663\n",
      "\n",
      "Total benign train accuarcy: 97.478\n",
      "Total benign train loss: 28.43355688918382\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04561139643192291\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02538619004189968\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10723018646240234\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016633765771985054\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06460967659950256\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05302872881293297\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01378975436091423\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014509806409478188\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05038128048181534\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04123219475150108\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07170652598142624\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02832179144024849\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04715074971318245\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025464195758104324\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.018897337839007378\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07098262012004852\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03690756857395172\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07005832344293594\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06305351108312607\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04084714874625206\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06996854394674301\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042722370475530624\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028081096708774567\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08278187364339828\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059006836265325546\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.08208432793617249\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01404534187167883\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09421156346797943\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029758844524621964\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05324442312121391\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029822925105690956\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08067404478788376\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.068011075258255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07534496486186981\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06522169709205627\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08010270446538925\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07227690517902374\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07426997274160385\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.085340715944767\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.07856068015098572\n",
      "\n",
      "Total benign train accuarcy: 97.922\n",
      "Total benign train loss: 24.192696994170547\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030636942014098167\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11697854846715927\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06500918418169022\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07881055772304535\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.033182937651872635\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09428978711366653\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06357993185520172\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05803532898426056\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.046640314161777496\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04417024925351143\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.054816924035549164\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04719176143407822\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10593384504318237\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022060539573431015\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.024957723915576935\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13380348682403564\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0582299679517746\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.038016293197870255\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05869630351662636\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09829458594322205\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08621280640363693\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08666013926267624\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.050494663417339325\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05174747109413147\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050443384796381\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059001218527555466\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1097060889005661\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08217472583055496\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13199155032634735\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10110671073198318\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03593297302722931\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07353231310844421\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.048760317265987396\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10403978079557419\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17287008464336395\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06816606968641281\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08959384262561798\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.043234702199697495\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022026514634490013\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.08815215528011322\n",
      "\n",
      "Total benign train accuarcy: 97.26\n",
      "Total benign train loss: 31.057761507108808\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029885107651352882\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06513702124357224\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04514556750655174\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03703568875789642\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06586337089538574\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06247171014547348\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054534442722797394\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045546598732471466\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03591405972838402\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0187158714979887\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.023895788937807083\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01727856509387493\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.045886583626270294\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030626902356743813\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.023160450160503387\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036369532346725464\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10691129416227341\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.018531642854213715\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05450506880879402\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019175171852111816\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07789907604455948\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.040492817759513855\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04013955220580101\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03621911257505417\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10416002571582794\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11916624754667282\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.055499035865068436\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12119178473949432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06498684734106064\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05740685015916824\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09638036787509918\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12513193488121033\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.050973694771528244\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06690126657485962\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12832163274288177\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.14217883348464966\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07004711031913757\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12703247368335724\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18977463245391846\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.06024111062288284\n",
      "\n",
      "Total benign train accuarcy: 97.716\n",
      "Total benign train loss: 25.592456976417452\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07630851119756699\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08035352826118469\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05607534945011139\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07456868141889572\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0839577466249466\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0732867568731308\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048693932592868805\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08491379767656326\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03628702834248543\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08732681721448898\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022170130163431168\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08451719582080841\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05780010297894478\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08353587239980698\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039046525955200195\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05265447869896889\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05519703030586243\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007720795925706625\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05108698830008507\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03730374947190285\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05991543084383011\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05765734240412712\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030493509024381638\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04598213732242584\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07103732228279114\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06485456973314285\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08731147646903992\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048712342977523804\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0966033786535263\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0834927037358284\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04162546992301941\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.060051027685403824\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12016923725605011\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0756228119134903\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1086956039071083\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1143544614315033\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07692664116621017\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07839800417423248\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0387025885283947\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.10565169900655746\n",
      "\n",
      "Total benign train accuarcy: 97.484\n",
      "Total benign train loss: 28.614501299802214\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06737543642520905\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06617185473442078\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.04769551753997803\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06464968621730804\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08681192994117737\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03953050822019577\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11353371292352676\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07588101178407669\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03959120064973831\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048046279698610306\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05711286514997482\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09687201678752899\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0552048422396183\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04198881983757019\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06180247664451599\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025613676756620407\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12141235917806625\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052597735077142715\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0577189102768898\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0790814757347107\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03761164844036102\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06880101561546326\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06362434476613998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037497200071811676\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08584801852703094\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03525745868682861\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06188202649354935\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15684230625629425\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05713203549385071\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013663241639733315\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.19681398570537567\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031101709231734276\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12134081870317459\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13439041376113892\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11459793150424957\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14732186496257782\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10806114226579666\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10591112077236176\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.16953930258750916\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.07864563167095184\n",
      "\n",
      "Total benign train accuarcy: 97.568\n",
      "Total benign train loss: 28.23445377871394\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020065605640411377\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026044724509119987\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07600582391023636\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10611052066087723\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.059287916868925095\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029613839462399483\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04183673858642578\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06981589645147324\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.035759564489126205\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08754140883684158\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04519021138548851\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10065177083015442\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07706944644451141\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05002112314105034\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04485063999891281\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04440347105264664\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07363864034414291\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05196002498269081\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02877051755785942\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07218329608440399\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12696358561515808\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03196754679083824\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10453133285045624\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07505574822425842\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10728665441274643\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06416567414999008\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12566521763801575\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10785898566246033\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.16142581403255463\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09901712089776993\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06803444027900696\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07308420538902283\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034560225903987885\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08576615154743195\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028170324862003326\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04445747286081314\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1148233637213707\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1032523363828659\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.09123783558607101\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 0.20432639122009277\n",
      "\n",
      "Total benign train accuarcy: 97.674\n",
      "Total benign train loss: 26.507079505827278\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08705510199069977\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06939233839511871\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.059654444456100464\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05422583222389221\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019267207011580467\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02023424208164215\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06784018874168396\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0853055864572525\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029108203947544098\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0678410679101944\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04126507788896561\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07073730230331421\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01360985729843378\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03611534833908081\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01960516907274723\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04258282110095024\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09296548366546631\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06302663683891296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03018040582537651\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04317161440849304\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10689074546098709\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.038151927292346954\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11171682924032211\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05309198796749115\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1183900535106659\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17501217126846313\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05068378895521164\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08274219930171967\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044473275542259216\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08230506628751755\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04933421313762665\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08219250291585922\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05524488165974617\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11445128172636032\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10984086990356445\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16523616015911102\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07999717444181442\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0788082405924797\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1293363720178604\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18179026246070862\n",
      "\n",
      "Total benign train accuarcy: 97.208\n",
      "Total benign train loss: 31.892772608436644\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06947711855173111\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10224595665931702\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.125602126121521\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04504517838358879\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05254678055644035\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048847224563360214\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03240584209561348\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05096110701560974\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05346265062689781\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04539363458752632\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11949612200260162\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.041607968509197235\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.048368748277425766\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.048651427030563354\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15860912203788757\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13535663485527039\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.049143534153699875\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.040261995047330856\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06381255388259888\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.052735235542058945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02626240998506546\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04973743110895157\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04157547652721405\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07323930412530899\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0308737400919199\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08732419461011887\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048201609402894974\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027415547519922256\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0728740319609642\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04457229748368263\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03258403763175011\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2761479616165161\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04163317382335663\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0408262237906456\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12797288596630096\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07563957571983337\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08867629617452621\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09008735418319702\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.041314877569675446\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16802263259887695\n",
      "\n",
      "Total benign train accuarcy: 97.556\n",
      "Total benign train loss: 28.18669838272035\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04312252253293991\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02866945043206215\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18177787959575653\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08689852058887482\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08417652547359467\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059973254799842834\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.035495575517416\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08411207795143127\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.023933490738272667\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014568381011486053\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05406271293759346\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.027257120236754417\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07395746558904648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017495043575763702\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046596456319093704\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.039491601288318634\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03207434341311455\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0314752459526062\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029624760150909424\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10597454756498337\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022917499765753746\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11588079482316971\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.039437390863895416\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06710996478796005\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09915750473737717\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10430372506380081\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1094243973493576\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06030500307679176\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0639185756444931\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09303588420152664\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1063288003206253\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09888561069965363\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08455008268356323\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19213330745697021\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09615699201822281\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0798301100730896\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10418115556240082\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10638324171304703\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0753398984670639\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.042367227375507355\n",
      "\n",
      "Total benign train accuarcy: 97.64\n",
      "Total benign train loss: 26.699593133758754\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.057129595428705215\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06765884160995483\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006974115502089262\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01948760636150837\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.020379167050123215\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06596235930919647\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03123098984360695\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.031379226595163345\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04676121845841408\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04859144240617752\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04686163738369942\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.033736445009708405\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.014121055603027344\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03363893926143646\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1158732995390892\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.038092125207185745\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.062449123710393906\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030857188627123833\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10495242476463318\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04855247214436531\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05975204333662987\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06913253664970398\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05372869595885277\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12751886248588562\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12420867383480072\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08596276491880417\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09616202116012573\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12492011487483978\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14050447940826416\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05613284558057785\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12282821536064148\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.057465631514787674\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09677004814147949\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16129229962825775\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06568087637424469\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03809022158384323\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06591637432575226\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06485219299793243\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06039545312523842\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.03498204052448273\n",
      "\n",
      "Total benign train accuarcy: 97.696\n",
      "Total benign train loss: 26.475625628139824\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.020097441971302032\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05387045443058014\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07473268359899521\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.115298792719841\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09719201922416687\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03515772521495819\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05125530809164047\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039401762187480927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02503485418856144\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045804329216480255\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08746758848428726\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11518828570842743\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09529580920934677\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05106767639517784\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.015304356813430786\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02933717705309391\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0750044658780098\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09453665465116501\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.018284453079104424\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061621248722076416\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08699607104063034\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.054065316915512085\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05601225793361664\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11448747664690018\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18757058680057526\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.061078205704689026\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0679660215973854\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07920233905315399\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1139921322464943\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061824601143598557\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08127770572900772\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0743456706404686\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1966521143913269\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06776300072669983\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06844489276409149\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16070100665092468\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09438178688287735\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15991243720054626\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07117322832345963\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.10815608501434326\n",
      "\n",
      "Total benign train accuarcy: 97.64\n",
      "Total benign train loss: 27.230519266799092\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07407902926206589\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025410359725356102\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05680673196911812\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05747583881020546\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026846950873732567\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025813929736614227\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0618392676115036\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07007990032434464\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03722715750336647\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04592156037688255\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04074248671531677\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0388428196310997\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.058149199932813644\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.013504467904567719\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.037558212876319885\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04126368835568428\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.017502624541521072\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04263447970151901\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039695754647254944\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05664077773690224\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04684504121541977\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06499998271465302\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047808099538087845\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03457016870379448\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03350597992539406\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.16082945466041565\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046146370470523834\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09352319687604904\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.051154714077711105\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08583443611860275\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11450420320034027\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13591647148132324\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09678430110216141\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16550813615322113\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1586035043001175\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06445902585983276\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10031504929065704\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03795997053384781\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.15217047929763794\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1665208488702774\n",
      "\n",
      "Total benign train accuarcy: 97.568\n",
      "Total benign train loss: 27.93502309732139\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06476778537034988\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10030200332403183\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05363302677869797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05987333878874779\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.036248575896024704\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06659099459648132\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.034902773797512054\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06912075728178024\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03604264184832573\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05316207930445671\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030604183673858643\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03277159854769707\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03883933648467064\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04863578453660011\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009727679193019867\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008642308413982391\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08045139163732529\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017531346529722214\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.024699965491890907\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022410651668906212\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0622374527156353\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07265868782997131\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.056941431015729904\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08539078384637833\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03487595170736313\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05020957440137863\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05620570108294487\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028833674266934395\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10457809269428253\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.073915496468544\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08109389990568161\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15350426733493805\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15508103370666504\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04968159645795822\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06523258239030838\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04709913581609726\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08917684853076935\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10890325158834457\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0725884959101677\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20662322640419006\n",
      "\n",
      "Total benign train accuarcy: 97.732\n",
      "Total benign train loss: 26.442061154171824\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03600269928574562\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08023423701524734\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.043461255729198456\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.053298935294151306\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08110089600086212\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.054321736097335815\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05265653505921364\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.040713485330343246\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04904654249548912\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04988060146570206\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07543966919183731\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0661793127655983\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07473582774400711\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06501005589962006\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051688216626644135\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07668577879667282\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.024940915405750275\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05038057267665863\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06388694047927856\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05146922171115875\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06654658168554306\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.032225534319877625\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.060011882334947586\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10383264720439911\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05671194940805435\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06125444173812866\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034278228878974915\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059210631996393204\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02586386166512966\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13993409276008606\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03898519277572632\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05792396515607834\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11503258347511292\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05773892626166344\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03728858008980751\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10330125689506531\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.24192772805690765\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1343041956424713\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09146808087825775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.20572061836719513\n",
      "\n",
      "Total benign train accuarcy: 97.608\n",
      "Total benign train loss: 27.079905848950148\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07009641081094742\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029240185394883156\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07967301458120346\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.15931880474090576\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.10186915844678879\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031014995649456978\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.07255708426237106\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02378583885729313\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03622353449463844\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03245006501674652\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03582978993654251\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04933718219399452\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04481315240263939\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.035090163350105286\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.053557585924863815\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03877763822674751\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.054021697491407394\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05443860962986946\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0398188941180706\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030081279575824738\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09828395396471024\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037489742040634155\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10131829231977463\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0642060786485672\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.061706703156232834\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059738703072071075\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12121555954217911\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04231492429971695\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10113610327243805\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0959363654255867\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10846274346113205\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07053255289793015\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06176156550645828\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15785694122314453\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05900721624493599\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04113217443227768\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18450923264026642\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03393500670790672\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1631108820438385\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.12315633147954941\n",
      "\n",
      "Total benign train accuarcy: 97.52\n",
      "Total benign train loss: 28.348695480264723\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1130746528506279\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07183381170034409\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03901490941643715\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.05711590498685837\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09571197628974915\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0611087791621685\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02758757956326008\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028303787112236023\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02007611282169819\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02477988414466381\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06124233454465866\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04301135241985321\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030424481257796288\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06427779793739319\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.037763893604278564\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02909618429839611\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05010996386408806\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12077755481004715\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.040968701243400574\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03577904775738716\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054653577506542206\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030487127602100372\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054579105228185654\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16148433089256287\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07348226755857468\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15544407069683075\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11031584441661835\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08824092894792557\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1479089856147766\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07590251415967941\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050817959010601044\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11953109502792358\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12579777836799622\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0626484677195549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10201739519834518\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08821789920330048\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1873917430639267\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06806746870279312\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09317264705896378\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.13803961873054504\n",
      "\n",
      "Total benign train accuarcy: 97.4\n",
      "Total benign train loss: 29.36485766340047\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03391436114907265\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.111323282122612\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0857890173792839\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022844424471259117\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05764093995094299\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0352427177131176\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05080663412809372\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03300582990050316\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0823148563504219\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.024736270308494568\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02080625109374523\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042106714099645615\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051301825791597366\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.013439499773085117\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01389359962195158\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01984359323978424\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02127857506275177\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04079406335949898\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06882931292057037\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045404303818941116\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.027256309986114502\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03754809498786926\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02225821278989315\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.056991904973983765\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.032509319484233856\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04623794928193092\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06641702353954315\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.041609760373830795\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09648484736680984\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050450243055820465\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06903193891048431\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06028002128005028\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11147188395261765\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0915852040052414\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07373642176389694\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03181825578212738\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07939275354146957\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10400357097387314\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07300229370594025\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.1013287752866745\n",
      "\n",
      "Total benign train accuarcy: 97.786\n",
      "Total benign train loss: 25.42759408056736\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052924398332834244\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05287966877222061\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1021144762635231\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11309340596199036\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04172511771321297\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12258264422416687\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01640242710709572\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04874831810593605\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020270390436053276\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10851956158876419\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11063621938228607\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06402840465307236\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11027891933917999\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08305509388446808\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1060708612203598\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16528615355491638\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13281428813934326\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06431750953197479\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14654548466205597\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.023832643404603004\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.078816719353199\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0647856593132019\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.028817657381296158\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.038740623742341995\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04537508636713028\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04910365864634514\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06012803688645363\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08152031153440475\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11760986596345901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07147090882062912\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.12235593795776367\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.05900373309850693\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12611506879329681\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11997954547405243\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0429963618516922\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05115809664130211\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05286155268549919\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1305779218673706\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06901070475578308\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.07889464497566223\n",
      "\n",
      "Total benign train accuarcy: 97.744\n",
      "Total benign train loss: 25.73811153974384\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04441008344292641\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0754224881529808\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.109788678586483\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09995506703853607\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06294593214988708\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022153398022055626\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07925879210233688\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.1143995001912117\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09653374552726746\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025751499459147453\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11053971201181412\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04894455149769783\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045993492007255554\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.026906343176960945\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04852207377552986\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02152669057250023\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022629551589488983\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05298640951514244\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04525770992040634\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.058194033801555634\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042514313012361526\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02429574728012085\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051328808069229126\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03366568684577942\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04958005249500275\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04341607168316841\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09613215178251266\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.040801700204610825\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05420415475964546\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08707274496555328\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1415964663028717\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07035699486732483\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.056758686900138855\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04871358349919319\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04367518424987793\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10115467011928558\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08218612521886826\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10260795056819916\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08069316297769547\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.12874636054039001\n",
      "\n",
      "Total benign train accuarcy: 98.114\n",
      "Total benign train loss: 21.996696376241744\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0541284941136837\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10515138506889343\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10886475443840027\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04595028981566429\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08327673375606537\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.055283527821302414\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11743808537721634\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0585850328207016\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08453721553087234\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07418771833181381\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.026622146368026733\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07903756946325302\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10273817926645279\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03786754608154297\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06674916297197342\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02312505804002285\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07665860652923584\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05252847820520401\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06314428895711899\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022162938490509987\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.049153584986925125\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.037226684391498566\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08202865719795227\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06679205596446991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.049748633056879044\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.032235387712717056\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06993293762207031\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061502646654844284\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13499656319618225\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08937912434339523\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10106638073921204\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08557143062353134\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08224228024482727\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09953773021697998\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0576799213886261\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09892339259386063\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10263923555612564\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11225740611553192\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.15212246775627136\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.1305067241191864\n",
      "\n",
      "Total benign train accuarcy: 97.412\n",
      "Total benign train loss: 30.051590260118246\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07205019146203995\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06806395202875137\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06535352021455765\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13549844920635223\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03016972355544567\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04105472192168236\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03293151035904884\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05359131842851639\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11353538185358047\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11772634834051132\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07440952211618423\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09128671139478683\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.10627365857362747\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.027273094281554222\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014502665027976036\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07517904043197632\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06322058290243149\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.050021398812532425\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08376244455575943\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14803098142147064\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06284225732088089\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08752705901861191\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06334435194730759\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08988728374242783\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10223036259412766\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04973907768726349\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05345505475997925\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08860675245523453\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11106797307729721\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11705688387155533\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14825278520584106\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12263144552707672\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.145344540476799\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13510587811470032\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0711614191532135\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08372024446725845\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10354756563901901\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025643154978752136\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10287546366453171\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14822900295257568\n",
      "\n",
      "Total benign train accuarcy: 97.262\n",
      "Total benign train loss: 30.733934681862593\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05932013690471649\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.051708199083805084\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11865002661943436\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08820182085037231\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12365412712097168\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04632571339607239\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07930244505405426\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016967779025435448\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050188176333904266\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06439588218927383\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04335719719529152\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051117606461048126\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07413703948259354\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08521361649036407\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0529995933175087\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1123494803905487\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010043502785265446\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15965229272842407\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06086447089910507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07706383615732193\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06656308472156525\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07744927704334259\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07669606059789658\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05273124575614929\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.058439455926418304\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04092798009514809\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0553261898458004\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0709986537694931\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10458949953317642\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09035475552082062\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18026795983314514\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08760684728622437\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04664738103747368\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05491410568356514\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.07659777253866196\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10217424482107162\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05725512653589249\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06978191435337067\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11650204658508301\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.14227458834648132\n",
      "\n",
      "Total benign train accuarcy: 97.718\n",
      "Total benign train loss: 26.06057632341981\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09172233939170837\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04989888519048691\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03338431939482689\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045693881809711456\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05001053586602211\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027040498331189156\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06688643991947174\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09582746773958206\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06947669386863708\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04931239038705826\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03141707554459572\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0711192786693573\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07156586647033691\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07633841782808304\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06732842326164246\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08319292962551117\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02648599073290825\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.029926054179668427\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07880591601133347\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017999937757849693\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08632253110408783\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07161107659339905\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0359027199447155\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.065933957695961\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09274648129940033\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08314729481935501\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03929978609085083\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.055739860981702805\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.11201983690261841\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.034510284662246704\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12085609138011932\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12456107139587402\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07808766514062881\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1310245245695114\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06611276417970657\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1409268081188202\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07284499704837799\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1113811656832695\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16833630204200745\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.04225985333323479\n",
      "\n",
      "Total benign train accuarcy: 97.664\n",
      "Total benign train loss: 26.645435109734535\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08138023316860199\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07189459353685379\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07123083621263504\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02867542952299118\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0400049090385437\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08082009851932526\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02613348886370659\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08540985733270645\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.033782415091991425\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031508512794971466\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03758405148983002\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07637440413236618\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06733106076717377\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08975552767515182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07217869907617569\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04698909819126129\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04779711365699768\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.020965155214071274\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04939259961247444\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.15564759075641632\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07693657279014587\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.049308355897665024\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07234813272953033\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11822836846113205\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11911582201719284\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0674656480550766\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.039354950189590454\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04303855076432228\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04514197260141373\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10497474670410156\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07291049510240555\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.125966414809227\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050130974501371384\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.077088862657547\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05335584655404091\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06474120914936066\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08724076300859451\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10814458876848221\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09160006046295166\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.12892931699752808\n",
      "\n",
      "Total benign train accuarcy: 97.88\n",
      "Total benign train loss: 24.961162477266043\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012595062144100666\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06078615412116051\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031041722744703293\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01781969889998436\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.018144551664590836\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04319298639893532\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01477791927754879\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04326234385371208\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17943020164966583\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.041401851922273636\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03540109097957611\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05707947164773941\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.055801309645175934\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0846758484840393\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08292250335216522\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1970718950033188\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04750332236289978\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02480427548289299\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06378274410963058\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.058537427335977554\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06110305339097977\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04318836331367493\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029549110680818558\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12433038651943207\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06374465674161911\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03260021656751633\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0500408411026001\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09586193412542343\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0625445768237114\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09566739201545715\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07722200453281403\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1745063066482544\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0714251771569252\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05303557589650154\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10822241008281708\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.040185119956731796\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08490876853466034\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17183475196361542\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0553131178021431\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.14050531387329102\n",
      "\n",
      "Total benign train accuarcy: 97.772\n",
      "Total benign train loss: 26.076915851794183\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02160497009754181\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11090130358934402\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08067008852958679\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052572961896657944\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045957982540130615\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039454661309719086\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04505983367562294\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10104185342788696\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0927746593952179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05154993385076523\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.083974689245224\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04190029948949814\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1610172688961029\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.017176715657114983\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10780283063650131\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04227902367711067\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04285433888435364\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08920703083276749\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017817338928580284\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05987592414021492\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04424763470888138\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04552391916513443\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07434898614883423\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11623558402061462\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07499353587627411\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019230157136917114\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0199179295450449\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06630847603082657\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07457015663385391\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17153844237327576\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11721701920032501\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.044945064932107925\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05617525056004524\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03809751942753792\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04032798483967781\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06621424853801727\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.15016917884349823\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09081505239009857\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22442711889743805\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.10416607558727264\n",
      "\n",
      "Total benign train accuarcy: 97.62\n",
      "Total benign train loss: 27.562640186864883\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11437399685382843\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0521736666560173\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.021823588758707047\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05138489603996277\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04747115075588226\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011499136686325073\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014710430055856705\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08696681261062622\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0676850974559784\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10739066451787949\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06497111171483994\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11460401117801666\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07293717563152313\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07620861381292343\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02164323814213276\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08767236024141312\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046732839196920395\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07682681828737259\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08797015994787216\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05478949844837189\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04848906770348549\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.054391611367464066\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.038084760308265686\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0638679787516594\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.17013391852378845\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.027836700901389122\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08615068346261978\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06179820001125336\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09565550088882446\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06369712203741074\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06370830535888672\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05896041542291641\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08429025113582611\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0849444717168808\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12868523597717285\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10612683743238449\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1021234318614006\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05929873511195183\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1783791482448578\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.11739088594913483\n",
      "\n",
      "Total benign train accuarcy: 97.494\n",
      "Total benign train loss: 29.15932943392545\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09024396538734436\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03362356871366501\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09076546877622604\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05297137796878815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10629545897245407\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04661890119314194\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0846564769744873\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14647772908210754\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07691950350999832\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05874001607298851\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13489946722984314\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07785332947969437\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0310140959918499\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.062436461448669434\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07705949246883392\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06337768584489822\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022550197318196297\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02847098372876644\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08968792110681534\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07704313844442368\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09831488877534866\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.05962761119008064\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08005654811859131\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09166156500577927\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0682724267244339\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07641541957855225\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07951518893241882\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04774267226457596\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05397501215338707\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09770341962575912\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04565047845244408\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05671554058790207\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06308375298976898\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09923343360424042\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14923769235610962\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12288156151771545\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1485661417245865\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06162741780281067\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06115337833762169\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.07514946162700653\n",
      "\n",
      "Total benign train accuarcy: 97.616\n",
      "Total benign train loss: 26.38703088182956\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04641575366258621\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02076089382171631\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04727929085493088\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06868299841880798\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09464630484580994\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06139591708779335\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05742501839995384\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021938582882285118\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07771861553192139\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03207790479063988\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05322727560997009\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05848139524459839\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04123282805085182\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0350714847445488\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05338725075125694\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06396085023880005\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06285439431667328\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09558083117008209\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04417934641242027\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06442587822675705\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03795632719993591\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03709232807159424\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06737840920686722\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03960774838924408\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07327105849981308\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052981507033109665\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07691776752471924\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11048862338066101\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06935489922761917\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11568298935890198\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10149336606264114\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0972496047616005\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08242525160312653\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06482923030853271\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.033576782792806625\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12651419639587402\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06471918523311615\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10070472955703735\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09253516793251038\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.11208455264568329\n",
      "\n",
      "Total benign train accuarcy: 97.806\n",
      "Total benign train loss: 24.88983996771276\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044327422976493835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09712132066488266\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02362806722521782\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04329288750886917\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045699600130319595\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02824709750711918\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.013403236865997314\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.024734050035476685\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022825228050351143\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03396771103143692\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012635461986064911\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06153059005737305\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02092895656824112\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05318040773272514\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10648755729198456\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.061082445085048676\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02619774080812931\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014454938471317291\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04021522402763367\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03317641839385033\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08512001484632492\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.041594497859478\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06061660870909691\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03327435627579689\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04627746716141701\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09691829979419708\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07187625765800476\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11681666225194931\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04132304713129997\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.14847338199615479\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09297376871109009\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05019347742199898\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07173608988523483\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08307065814733505\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2313304841518402\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10070320218801498\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12736378610134125\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09578021615743637\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.059373848140239716\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.1423119604587555\n",
      "\n",
      "Total benign train accuarcy: 97.942\n",
      "Total benign train loss: 24.220488283783197\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03591660410165787\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13516752421855927\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10364072024822235\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06430700421333313\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.029663940891623497\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03951294720172882\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03223227709531784\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04031747952103615\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09223533421754837\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09817740321159363\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09392686933279037\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02230857126414776\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11747065931558609\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10000132024288177\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054663997143507004\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.055937837809324265\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031227940693497658\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.031749457120895386\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03569716215133667\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04596051573753357\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.021475210785865784\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.018756818026304245\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030064279213547707\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07094626873731613\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08556675910949707\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03740595653653145\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.021246572956442833\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03156828507781029\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11122694611549377\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06654143333435059\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05201517045497894\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.23587502539157867\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0538356713950634\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04819559305906296\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04310581833124161\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07086125761270523\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05231628194451332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0926908627152443\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10435204952955246\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.047046735882759094\n",
      "\n",
      "Total benign train accuarcy: 97.83\n",
      "Total benign train loss: 25.144855555146933\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05208410695195198\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026153305545449257\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05828886479139328\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.058506883680820465\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05004572868347168\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019446969032287598\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00843040645122528\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02406380884349346\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016335561871528625\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.028623290359973907\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.040364041924476624\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017824627459049225\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05055755376815796\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07614608854055405\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07504688948392868\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09702236950397491\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04116782546043396\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031628917902708054\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009500372223556042\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02767806500196457\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0973096713423729\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01041304413229227\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0841829925775528\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03457961976528168\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13401946425437927\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.057993337512016296\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03546806424856186\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07451290637254715\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.059696264564991\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.138511061668396\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048895463347435\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12636367976665497\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08409316837787628\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11309950798749924\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14934633672237396\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.16923163831233978\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0996449738740921\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04483905807137489\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11598120629787445\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.08561556041240692\n",
      "\n",
      "Total benign train accuarcy: 97.936\n",
      "Total benign train loss: 23.935641730204225\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08668770641088486\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06596692651510239\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05264682695269585\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02806578204035759\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0979534238576889\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05343027412891388\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0803169459104538\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03785846009850502\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12373866885900497\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03265802189707756\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07657309621572495\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03370022401213646\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045497093349695206\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09533610194921494\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10375867038965225\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07362691313028336\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05593739077448845\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0821654349565506\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08701103180646896\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06353124231100082\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07570626586675644\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.059208616614341736\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04945734888315201\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.027980972081422806\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06699726730585098\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022367896512150764\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03435591235756874\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04537750035524368\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06274141371250153\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05598150193691254\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07486298680305481\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.055475588887929916\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0450611375272274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04882941395044327\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04536629095673561\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11759250611066818\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0981137752532959\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05582722648978233\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14540700614452362\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.10660743713378906\n",
      "\n",
      "Total benign train accuarcy: 97.478\n",
      "Total benign train loss: 28.83259048499167\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07243668287992477\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11325599253177643\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027334880083799362\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1383441984653473\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025982197374105453\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.057625286281108856\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0327395424246788\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07449058443307877\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013314729556441307\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12267018854618073\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044928789138793945\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.08727468550205231\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1037958413362503\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0785156637430191\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07776575535535812\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12999291718006134\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13400202989578247\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0739085003733635\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10074904561042786\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10183940082788467\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08063430339097977\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05254923552274704\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1770852506160736\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05625804141163826\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04166072607040405\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11929972469806671\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08055447041988373\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08508378267288208\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05949478968977928\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06595100462436676\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04265960305929184\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04931841418147087\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08698591589927673\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.030472470447421074\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09341289103031158\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.061442334204912186\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03619195148348808\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07451063394546509\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10072075575590134\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 0.11564654111862183\n",
      "\n",
      "Total benign train accuarcy: 97.528\n",
      "Total benign train loss: 27.709976164624095\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020821772515773773\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07538893818855286\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06187571957707405\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07723883539438248\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06440962851047516\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08298574388027191\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11784312129020691\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1838122308254242\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10342700034379959\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07929582893848419\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08452712744474411\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10057604312896729\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11549785733222961\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11438625305891037\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06212048605084419\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0726088359951973\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09344130009412766\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09195069968700409\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048939116299152374\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09954433888196945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08813849091529846\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0777585357427597\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.035882335156202316\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08288844674825668\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.042581167072057724\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.041617684066295624\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.084963358938694\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06874862313270569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05553460121154785\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04103882983326912\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08379407227039337\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.050159189850091934\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04566888511180878\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11991191655397415\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07195785641670227\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08143465220928192\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05157945305109024\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1517925262451172\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16358202695846558\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9125\n",
      "Current benign train loss: 0.21693024039268494\n",
      "\n",
      "Total benign train accuarcy: 97.33\n",
      "Total benign train loss: 29.953085888177156\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036027565598487854\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10398007929325104\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04184422641992569\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02252005785703659\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06919029355049133\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.061219047755002975\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06590431928634644\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02580738067626953\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.052523285150527954\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03851174935698509\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05459097400307655\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.038078803569078445\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0624474361538887\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03549172356724739\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07191085070371628\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017450500279664993\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07493972033262253\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05375681072473526\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01951613277196884\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04654170572757721\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042894769459962845\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06067259609699249\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030361752957105637\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07567683607339859\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0475035086274147\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04254927858710289\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01979346200823784\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034286778420209885\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06277567148208618\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09227043390274048\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1405022293329239\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11879574507474899\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09097884595394135\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11434908211231232\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0908162072300911\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10822348296642303\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04763133078813553\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06480962783098221\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15702135860919952\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.04754215478897095\n",
      "\n",
      "Total benign train accuarcy: 97.848\n",
      "Total benign train loss: 25.006717225536704\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08945837616920471\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05862123519182205\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.038822732865810394\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0433802492916584\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05040719360113144\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04260706529021263\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015754977241158485\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06057969853281975\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046578966081142426\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.057325348258018494\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1358546018600464\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12280713766813278\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022381486371159554\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06414343416690826\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03812753036618233\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09378208965063095\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14239385724067688\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.047470077872276306\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06368507444858551\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03706064447760582\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03038075938820839\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03320916369557381\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11370386183261871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.043443500995635986\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019938357174396515\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06313348561525345\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028722155839204788\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10899464786052704\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03282073885202408\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10526534914970398\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02096947282552719\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06991056352853775\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08072724938392639\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1051361933350563\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12822626531124115\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11745904386043549\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10566560924053192\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1288280040025711\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08565609157085419\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.038040753453969955\n",
      "\n",
      "Total benign train accuarcy: 97.858\n",
      "Total benign train loss: 24.153470239136368\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08852547407150269\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03417649492621422\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.053647927939891815\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052959341555833817\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026224836707115173\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0799398347735405\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05232374370098114\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10419251769781113\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08157432079315186\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010548730380833149\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02562151663005352\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051428426057100296\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03612552583217621\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03696000203490257\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07249244302511215\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08277884125709534\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.050539061427116394\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.035496316850185394\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06099718436598778\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022686604410409927\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09518975019454956\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03478119522333145\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0993981882929802\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.032656364142894745\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06566465646028519\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02839815244078636\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05930832028388977\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.039205245673656464\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09513131529092789\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14677953720092773\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06300750374794006\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03270253911614418\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08725376427173615\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10109007358551025\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1011834591627121\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11159386485815048\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09576208889484406\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07090181112289429\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07188563048839569\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1326945275068283\n",
      "\n",
      "Total benign train accuarcy: 97.47\n",
      "Total benign train loss: 28.90723212994635\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04655132070183754\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.034942664206027985\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04705951735377312\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04900757968425751\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0665048137307167\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07251047343015671\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029661014676094055\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.028086412698030472\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07122603058815002\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10045744478702545\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08421691507101059\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010937673971056938\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010903904214501381\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.053853411227464676\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045418038964271545\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022176750004291534\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.045852236449718475\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08465215563774109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034371085464954376\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03474190831184387\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03889498487114906\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11297090351581573\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03731752559542656\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.042650505900382996\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09450491517782211\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.058066073805093765\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05571597442030907\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08222987502813339\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1118064820766449\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.034533821046352386\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.049750916659832\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08438541740179062\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04495503753423691\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05240429565310478\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13226310908794403\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0917239785194397\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07843709737062454\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11618860065937042\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09892356395721436\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9625\n",
      "Current benign train loss: 0.15827251970767975\n",
      "\n",
      "Total benign train accuarcy: 97.968\n",
      "Total benign train loss: 24.014819165226072\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03777036443352699\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04801109433174133\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07295697182416916\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06054580211639404\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.039845097810029984\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05712991580367088\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04320291057229042\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05363800749182701\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02480708435177803\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04395149275660515\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06040767952799797\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05293608084321022\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05176081508398056\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06361810863018036\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09088161587715149\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08880200237035751\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.033914994448423386\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04767146706581116\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04395920783281326\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07974085211753845\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03943939507007599\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08782936632633209\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013192761689424515\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028677836060523987\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04798278585076332\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04022948816418648\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1257895529270172\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0810718908905983\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1184064969420433\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13488838076591492\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020175863057374954\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14687681198120117\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12362775206565857\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1151685044169426\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1274614930152893\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07948824018239975\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05923144146800041\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.054742299020290375\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08306019753217697\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 0.16252420842647552\n",
      "\n",
      "Total benign train accuarcy: 97.876\n",
      "Total benign train loss: 24.480753054842353\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.045021675527095795\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0956539660692215\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.027726203203201294\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061057306826114655\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05496901646256447\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05983157455921173\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07061199098825455\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05569790303707123\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07392687350511551\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10876063257455826\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01830597221851349\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.023731674998998642\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0424010269343853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09857311844825745\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.031500741839408875\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08713101595640182\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10203380137681961\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06191081553697586\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1317351758480072\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03408486768603325\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1176857054233551\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.161946102976799\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05128347501158714\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014641433954238892\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02606268599629402\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07604802399873734\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07575052976608276\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03721044212579727\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029514530673623085\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10112693160772324\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04387917369604111\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09304946660995483\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03050403669476509\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03794682398438454\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04971339553594589\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.035959720611572266\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08465667068958282\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2315240353345871\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17255988717079163\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.19515714049339294\n",
      "\n",
      "Total benign train accuarcy: 97.698\n",
      "Total benign train loss: 26.76399885583669\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03848795220255852\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0678919181227684\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12924450635910034\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03951535001397133\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016044186428189278\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04951896518468857\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028914768248796463\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.033215176314115524\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0589100606739521\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03251692280173302\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03476244583725929\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04946168139576912\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05491229519248009\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02891402691602707\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11481710523366928\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.026384802535176277\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03139825537800789\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0663844645023346\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.10498688369989395\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1380685418844223\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09053011238574982\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.042494840919971466\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05510660633444786\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.046434663236141205\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045466192066669464\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13510452210903168\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0596214197576046\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.048968274146318436\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04326430708169937\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10418932884931564\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08502247929573059\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08802621066570282\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09219001978635788\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08187971264123917\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1622491329908371\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1170516163110733\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08673300594091415\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07408607006072998\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17988063395023346\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.0382375493645668\n",
      "\n",
      "Total benign train accuarcy: 97.92\n",
      "Total benign train loss: 24.966759850271046\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09407314658164978\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08655370771884918\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028319112956523895\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.016338694840669632\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05331094563007355\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08408346027135849\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09475056082010269\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06213226169347763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08735167235136032\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.046979546546936035\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04196105897426605\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08637998253107071\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03475823253393173\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04701667279005051\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07853583991527557\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016166426241397858\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04709421098232269\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04586663097143173\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07802947610616684\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04566570371389389\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07520931214094162\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.048414215445518494\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04439292103052139\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.033390454947948456\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04351867362856865\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0281185582280159\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09781628847122192\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10821107029914856\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06739220023155212\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09465373307466507\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07086405158042908\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06499000638723373\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1212499588727951\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13442634046077728\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0763561800122261\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04411458969116211\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025098271667957306\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.059415023773908615\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13713128864765167\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.1101902574300766\n",
      "\n",
      "Total benign train accuarcy: 97.544\n",
      "Total benign train loss: 27.611622244119644\n",
      "\n",
      "[ Train epoch: 95 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08865413069725037\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054940365254879\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04236259683966637\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013350075110793114\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1108996644616127\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08970913290977478\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03595058247447014\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04304657131433487\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04819873720407486\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07366754114627838\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05648677051067352\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04129908233880997\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0547456257045269\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09649710357189178\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013918494805693626\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08981979638338089\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06038825586438179\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03746822476387024\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045369669795036316\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.032365474849939346\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10838967561721802\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06680380553007126\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.057294756174087524\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05435195565223694\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07992810010910034\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05384347587823868\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1221403032541275\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051929350942373276\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16039657592773438\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046508852392435074\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03224889561533928\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07415639609098434\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044972024857997894\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03360241279006004\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04107845947146416\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08962295204401016\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03505801782011986\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13057084381580353\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07235897332429886\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.08969219028949738\n",
      "\n",
      "Total benign train accuarcy: 97.898\n",
      "Total benign train loss: 24.863406216725707\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08478613197803497\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03633945435285568\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06287309527397156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05632924288511276\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06095387786626816\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031355634331703186\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029199449345469475\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11152972280979156\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03130291402339935\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04041089862585068\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.054027408361434937\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.034738264977931976\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0202085729688406\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06690189987421036\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07033892720937729\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02861694060266018\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06981770694255829\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03106028400361538\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012370302341878414\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.028177564963698387\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.060946546494960785\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022749945521354675\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04601249098777771\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07110292464494705\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0657922625541687\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08740846067667007\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0855439156293869\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0676395446062088\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05174677073955536\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06315336376428604\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06551054865121841\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04633524268865585\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02867424674332142\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.037932153791189194\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13251103460788727\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13202281296253204\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11307232826948166\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06622076779603958\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04320238158106804\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14289334416389465\n",
      "\n",
      "Total benign train accuarcy: 97.994\n",
      "Total benign train loss: 23.72410256974399\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05102815106511116\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03996255621314049\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05042104795575142\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.033145856112241745\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.043602850288152695\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04904019832611084\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05396704748272896\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0637601837515831\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.062271568924188614\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05202842876315117\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02487439103424549\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08003365248441696\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029381893575191498\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11838372051715851\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14495545625686646\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09287863969802856\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.020466716960072517\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05813226103782654\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11717180162668228\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03914199024438858\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025936800986528397\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02480722777545452\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03594529256224632\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0892762541770935\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.049487363547086716\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0929204672574997\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08585785329341888\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042476147413253784\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05836573243141174\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03935038670897484\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16657161712646484\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05924799293279648\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04111987352371216\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030734622851014137\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08016610145568848\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.118766188621521\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06863552331924438\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14502853155136108\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1406782865524292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.95\n",
      "Current benign train loss: 0.12394104897975922\n",
      "\n",
      "Total benign train accuarcy: 97.662\n",
      "Total benign train loss: 27.215633939485997\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0955023244023323\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03097139112651348\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06978970021009445\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11396156251430511\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05890209972858429\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05560002103447914\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07632306218147278\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06132737547159195\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08874880522489548\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.029391763731837273\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03237484022974968\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02365591749548912\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04166882112622261\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02978154458105564\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.018344368785619736\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030178973451256752\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04261207953095436\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012759455479681492\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03745933622121811\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03414802998304367\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.07936607301235199\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.047895461320877075\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009863142855465412\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04013330489397049\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01235442329198122\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10189559310674667\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08322729915380478\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10305936634540558\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.060254551470279694\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05818814039230347\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08040091395378113\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1349753439426422\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06447841972112656\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10707076638936996\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08390390872955322\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18845264613628387\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03346487879753113\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12218884378671646\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09042572230100632\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 0.1821739375591278\n",
      "\n",
      "Total benign train accuarcy: 97.674\n",
      "Total benign train loss: 26.786821336485445\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014802742749452591\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12068209052085876\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03370164707303047\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08073881268501282\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.13338138163089752\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.039962287992239\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1253008246421814\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0572943240404129\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027181776240468025\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.032292623072862625\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06958974897861481\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17638108134269714\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06498820334672928\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.058212149888277054\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11577236652374268\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036109231412410736\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03982483223080635\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02810327149927616\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022422613576054573\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09825622290372849\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022147227078676224\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11022879183292389\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06287307292222977\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03862381353974342\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06931693106889725\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0936964601278305\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03338965028524399\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05091390758752823\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09841862320899963\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04469115659594536\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0768512636423111\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06612543761730194\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03352867439389229\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09249573945999146\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11653111129999161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07693764567375183\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06906889379024506\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07353413105010986\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11317974328994751\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.975\n",
      "Current benign train loss: 0.11665169149637222\n",
      "\n",
      "Total benign train accuarcy: 97.748\n",
      "Total benign train loss: 26.10951743926853\n",
      "\n",
      "[ Train epoch: 100 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11045855283737183\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11117345839738846\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03086959198117256\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03226986527442932\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04543279483914375\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011545148678123951\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029607463628053665\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05491358041763306\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011394968256354332\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0336068719625473\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015589376911520958\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027091598138213158\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.023124555125832558\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00737623730674386\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009706107899546623\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026429012417793274\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010828065685927868\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025948431342840195\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02204718627035618\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03052229806780815\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006033780053257942\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010216161608695984\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046590473502874374\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03203016519546509\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02697104774415493\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005627966020256281\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0060411663725972176\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.018481874838471413\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01570655032992363\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02624989114701748\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.018192781135439873\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.023633603006601334\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02293146587908268\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011075693182647228\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02291874587535858\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0045783631503582\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.010351499542593956\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005546387284994125\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01222575455904007\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031753957737237215\n",
      "\n",
      "Total benign train accuarcy: 99.432\n",
      "Total benign train loss: 7.778265726519749\n",
      "\n",
      "[ Train epoch: 101 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033432883210480213\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004819809924811125\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012143025174736977\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00395349133759737\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016568801365792751\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003863096470013261\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003961146343499422\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.013934493996202946\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003831340465694666\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002549736527726054\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003797583980485797\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031568999402225018\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001655845670029521\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004917995538562536\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004221383482217789\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00801730714738369\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002722731325775385\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003303609788417816\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005961517803370953\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007652455009520054\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022674768697470427\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029902372043579817\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00360001134686172\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023791661951690912\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013475674204528332\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019042203202843666\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028983927331864834\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003896124428138137\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019065700471401215\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006089828908443451\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006129790563136339\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00567958177998662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016664665890857577\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023514374624937773\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002668108558282256\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031546896789222956\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028899770695716143\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003592265537008643\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012292880564928055\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004714515991508961\n",
      "\n",
      "Total benign train accuarcy: 99.976\n",
      "Total benign train loss: 1.6200751118012704\n",
      "\n",
      "[ Train epoch: 102 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003140835091471672\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002474734093993902\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002734681125730276\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031736199744045734\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003840747056528926\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016921591013669968\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036663322243839502\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004308817442506552\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019425064092501998\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022079155314713717\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034645467530936003\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025725015439093113\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023860957007855177\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00135006383061409\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030342009849846363\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003866561921313405\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022030645050108433\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00128321279771626\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003225502325221896\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027433543000370264\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002025071531534195\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012558508897200227\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001896535512059927\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020198989659547806\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011741332709789276\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00224861316382885\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033327192068099976\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002527548000216484\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014921986730769277\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018963294569402933\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018985674250870943\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013798745349049568\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012414579978212714\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001322100288234651\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027450004126876593\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002094524446874857\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029735350981354713\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002958228811621666\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012636854080483317\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.9875\n",
      "Current benign train loss: 0.027082938700914383\n",
      "\n",
      "Total benign train accuarcy: 99.996\n",
      "Total benign train loss: 1.0506338923005387\n",
      "\n",
      "[ Train epoch: 103 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012089948868378997\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014704898931086063\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001800601719878614\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019756625406444073\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002216995693743229\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012402040883898735\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013621712569147348\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008882661932148039\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020888890139758587\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00149648473598063\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016299404669553041\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015771619509905577\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029189540073275566\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022540336940437555\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005570531822741032\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017476199427619576\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009609573753550649\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024393273051828146\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011766571551561356\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00266388151794672\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012511804234236479\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021811651531606913\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002098853001371026\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010823854245245457\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002308790571987629\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001096933032386005\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015020654536783695\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036047298926860094\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018180657643824816\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001877831295132637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002778280759230256\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001732471282593906\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010661433916538954\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002651405753567815\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017238296568393707\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0049898684956133366\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001528599881567061\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000846655631903559\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014101736014708877\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002448692452162504\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.8171688266447745\n",
      "\n",
      "[ Train epoch: 104 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017481991089880466\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005177211947739124\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010166859719902277\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00224647531285882\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013354102848097682\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011908048763871193\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020611330401152372\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014332846039906144\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021099518053233624\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008462445111945271\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020001213997602463\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014502097619697452\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010230804327875376\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013314922107383609\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018070851219817996\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042388340807519853\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027723878156393766\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002121120924130082\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012868737103417516\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002041078405454755\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032041040249168873\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001312251202762127\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019691847264766693\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012189855333417654\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018104268237948418\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016935195308178663\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008998893317766488\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010524196550250053\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011261485051363707\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015928950160741806\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002931770635768771\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017221523448824883\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017360836500301957\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009387731552124023\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014626664342358708\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007626318838447332\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020159913692623377\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012858199188485742\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002672414528205991\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021516489796340466\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.7245899567205925\n",
      "\n",
      "[ Train epoch: 105 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006252786843106151\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025329000782221556\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002104751532897353\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013435487635433674\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013188142329454422\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014036638895049691\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013238403480499983\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012320618843659759\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014904070412740111\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001296470989473164\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014817035989835858\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009104476193897426\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011167514603585005\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001530189416371286\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016038704197853804\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001233752933330834\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014234038535505533\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00206302129663527\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001813796116039157\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001276685856282711\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001146059948951006\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025372293312102556\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038771021645516157\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001855384325608611\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018858198309317231\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014390053693205118\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011985147139057517\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001699549611657858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027241206262260675\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014364643720909953\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00091877969680354\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007080872310325503\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016097790794447064\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011994709493592381\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00156962382607162\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002177267335355282\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012145508080720901\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009027508203871548\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008625511545687914\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021843696013092995\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.6132291400281247\n",
      "\n",
      "[ Train epoch: 106 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014084128197282553\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013884345535188913\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019135706825181842\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002185886725783348\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0046763052232563496\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009962485637515783\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009032637462951243\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006503941840492189\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014760950580239296\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001067760749720037\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011040345998480916\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027736087795346975\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006349227041937411\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010098719503730536\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031251495238393545\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019846674986183643\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008957496611401439\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005015599308535457\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001729433424770832\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005149251315742731\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011347157415002584\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001287883729673922\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015288465656340122\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007346378406509757\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002909494796767831\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001020005438476801\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011178255081176758\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002984856953844428\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017179693095386028\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015024789609014988\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011391794541850686\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001049323589541018\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012744558043777943\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009121682960540056\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013354708207771182\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015288353897631168\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001193277188576758\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011300668120384216\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001695864018984139\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032571807969361544\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.5843091155402362\n",
      "\n",
      "[ Train epoch: 107 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013078092597424984\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020311158150434494\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011638989672064781\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014046333963051438\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023802302312105894\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001413897261954844\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007674742373637855\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010777574498206377\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010541811352595687\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016322085866704583\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007908747065812349\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019055125303566456\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014038309454917908\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010911669814959168\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015755337662994862\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006995246512815356\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012031010119244456\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018121598986908793\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008567410404793918\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012064010370522738\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006589466938748956\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012939766747877002\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009083620388992131\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011757152387872338\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004595308564603329\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033010030165314674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007355834823101759\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010862129274755716\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012910341611132026\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006375866360031068\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014786937972530723\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003910758066922426\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013821050524711609\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001086025731638074\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014385210815817118\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012730470625683665\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013351066736504436\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007468941621482372\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015105667989701033\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024424721486866474\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.548274274013238\n",
      "\n",
      "[ Train epoch: 108 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013605145504698157\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001330215367488563\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002413245616480708\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013248453615233302\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007707001059316099\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011982354335486889\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010289765195921063\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012100739404559135\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012013691011816263\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008449871675111353\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007624097634106874\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010909534757956862\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017845920519903302\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011558362748473883\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00134965346660465\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028315468225628138\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014207669300958514\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008408850408159196\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010763842146843672\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001049852347932756\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013430530671030283\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019530957797542214\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014413787284865975\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001256379997357726\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001306172227486968\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016290294006466866\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008457991061732173\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012743507977575064\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010937792249023914\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013585384003818035\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007828915258869529\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014769250992685556\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007237751851789653\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007858048775233328\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015726679703220725\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018760868115350604\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009220280917361379\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006890054210089147\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007185472641140223\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016110524302348495\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.5027810512401629\n",
      "\n",
      "[ Train epoch: 109 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016597865615040064\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007740548462606966\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007724654278717935\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009813228389248252\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010922184446826577\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012161150807514787\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013631073525175452\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009391671628691256\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010410217801108956\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00092645816039294\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009989237878471613\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007782193715684116\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010599656961858273\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010864522773772478\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000863280554767698\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006384954904206097\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006775843212381005\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001530056819319725\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011670172680169344\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009093486005440354\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013008395908400416\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009685271070338786\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013685637386515737\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001148514449596405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013926834799349308\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008789637358859181\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009521658066660166\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013984289253130555\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014822430675849319\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001141831511631608\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007875123410485685\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009635220048949122\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006153231952339411\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014172886731103063\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006929789669811726\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017965228762477636\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008997946861200035\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007531067240051925\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009088600054383278\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011245569912716746\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4834938271960709\n",
      "\n",
      "[ Train epoch: 110 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010108151473104954\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001106524607166648\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008872714824974537\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010602911934256554\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012343745911493897\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002094336785376072\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001093193655833602\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019595306366682053\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012710742885246873\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021532641258090734\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011120708659291267\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014773644506931305\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020406474359333515\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009506369242444634\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017897988436743617\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017717814771458507\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010487225372344255\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011207862989977002\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010517104528844357\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011393958702683449\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001180535415187478\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010808762162923813\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007281248108483851\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016197895165532827\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009144968935288489\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008676521247252822\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003646483412012458\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009831652278080583\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006744222482666373\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001502686645835638\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009001754806376994\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006799611728638411\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008383634267374873\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010286967735737562\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013538590865209699\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013156644999980927\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008910971228033304\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019538486376404762\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018520469311624765\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001037204870954156\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.46569413534598425\n",
      "\n",
      "[ Train epoch: 111 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010995838092640042\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015173852443695068\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007768626674078405\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001197114703245461\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009206152753904462\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009863615268841386\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010800488526001573\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009800402913242579\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010611442849040031\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016417554579675198\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008154952665790915\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001511239679530263\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008786201942712069\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013688541948795319\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014970132615417242\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017000378575176\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010432485723868012\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000979086384177208\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000930488167796284\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001103889779187739\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016744616441428661\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011279912432655692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00085892912466079\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009373571956530213\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009569764952175319\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012015257962048054\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008062819833867252\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001777363009750843\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009649995481595397\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012780558317899704\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00117992062587291\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017311334377154708\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011406055418774486\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010901478817686439\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012874240055680275\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008497274247929454\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008285327348858118\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009014540119096637\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000812609912827611\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010482079815119505\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.43633739338838495\n",
      "\n",
      "[ Train epoch: 112 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007008655229583383\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007546615088358521\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019335285760462284\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011727429227903485\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007966574630700052\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012193903094157577\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001211143913678825\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001117791049182415\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012900858419016004\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007261421415023506\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013021548511460423\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013517366023734212\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000803189177531749\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010542876552790403\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002292666118592024\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007408674573525786\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001240895944647491\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007504989625886083\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010800526943057775\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00110900797881186\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009603079524822533\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007110548904165626\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001121282810345292\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009519879822619259\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007789640803821385\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002226451179012656\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001026030397042632\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014362353831529617\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007394394488073885\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014314797008410096\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018922857707366347\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007469773408956826\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011330179404467344\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000852575059980154\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014703422784805298\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013776625273749232\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011660844320431352\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009695398039184511\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009728620643727481\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00159378198441118\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4467797426332254\n",
      "\n",
      "[ Train epoch: 113 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007769622025080025\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002191490028053522\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010366968344897032\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005287356907501817\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000819526903796941\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000755931599996984\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013489542761817575\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001108224387280643\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012905990006402135\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012145309010520577\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007986145792528987\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014253100380301476\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00109927449375391\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000870303891133517\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005990427453070879\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011553536169230938\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014439685037359595\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008631222299300134\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008013478363864124\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009489076910540462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018632268765941262\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004604328714776784\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008061921689659357\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00047638919204473495\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009303949773311615\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008585725445300341\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011911295587196946\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010474644368514419\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00071458809543401\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015858836704865098\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012469289358705282\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018411625642329454\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011172040831297636\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007809434900991619\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011177744017913938\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012727797729894519\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008256747387349606\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010427838424220681\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004460440541151911\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009593108552508056\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4270967344637029\n",
      "\n",
      "[ Train epoch: 114 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018946286290884018\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007845054497011006\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007706992328166962\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008825741242617369\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010781515156850219\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009031013469211757\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012084520421922207\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013456513406708837\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006186458049342036\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001009311992675066\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011409041471779346\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015175853623077273\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006989155663177371\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001025666599161923\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006295571802183986\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009896174306049943\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005657404544763267\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006969733512960374\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027420634869486094\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006888897623866796\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014162517618387938\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014152491930872202\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011138950940221548\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016218862729147077\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008633529650978744\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009848923655226827\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007232495700009167\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015114557463675737\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001128633040934801\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000997850438579917\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010299194836989045\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008566246833652258\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001027371734380722\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011186337796971202\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008533358341082931\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042966881301254034\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007452434510923922\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007644290453754365\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002262398134917021\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001417588209733367\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4174591340997722\n",
      "\n",
      "[ Train epoch: 115 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006920027080923319\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006443647434934974\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009105690405704081\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011826622067019343\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008136134129017591\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008181518060155213\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007919775671325624\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010693531949073076\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009164868388324976\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001853743102401495\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014628991484642029\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013065501116216183\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009745564893819392\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006461252341978252\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008882847032509744\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007037479081191123\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011080007534474134\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012584729120135307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008846392738632858\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000655992014799267\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001036028377711773\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007517596823163331\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009459672728553414\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000866906251758337\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010773189133033156\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010843676282092929\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007869155379012227\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001049487735144794\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016196820652112365\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008590236539021134\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005715659935958683\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018875848036259413\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007901795906946063\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006183499353937805\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006637601181864738\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010750795481726527\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001095177372917533\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012634251033887267\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007141766836866736\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010001382324844599\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.42295079631730914\n",
      "\n",
      "[ Train epoch: 116 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009387368918396533\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010800848249346018\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008742547943256795\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011965916492044926\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001058096531778574\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010316739790141582\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010755803668871522\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009328635642305017\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015127613442018628\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008378343190997839\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001175374141894281\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007317570270970464\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008675107383169234\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006544878124259412\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017384771490469575\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008817347115837038\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018975194543600082\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007530355942435563\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011313249124214053\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016130238072946668\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007267195614986122\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008333215373568237\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001151799107901752\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009207542752847075\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009163599461317062\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009880362777039409\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008600331493653357\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005508822505362332\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012316161300987005\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007242096471600235\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006467328639701009\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010597922373563051\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00089018460130319\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017765050288289785\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007427018135786057\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001131759723648429\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008717133314348757\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008881414541974664\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013322689337655902\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001054168795235455\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.40592596677015536\n",
      "\n",
      "[ Train epoch: 117 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002328804461285472\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014155720127746463\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009536450961604714\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010097242193296552\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007411160040646791\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000680251105222851\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009238093043677509\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007785880006849766\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007995989290066063\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007798500009812415\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008390358416363597\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006189813720993698\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010679787956178188\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010268475161865354\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009617541800253093\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012997891753911972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006658943020738661\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001601921976543963\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012398844119161367\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006226424593478441\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009081309544853866\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009102142066694796\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007001056801527739\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011274972930550575\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008388222195208073\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007146687130443752\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001298548304475844\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006418504635803401\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009755691862665117\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006647378904744983\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012941251043230295\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007949215942062438\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009318961529061198\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005953220534138381\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013863275526091456\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009554774733260274\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005627847858704627\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000992664834484458\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007623581914231181\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020964336581528187\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3996708083432168\n",
      "\n",
      "[ Train epoch: 118 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006379062542691827\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008759637712500989\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009143903153017163\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013822747860103846\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007254942320287228\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009396157693117857\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007218534010462463\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009063441539183259\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008540736162103713\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010064468951895833\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000914134958293289\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007016075542196631\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006367670721374452\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009315853239968419\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006072387914173305\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007516600308008492\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001206925604492426\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005647404468618333\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007823172491043806\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008456411887891591\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007518322672694921\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007601630641147494\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00145668291952461\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00201490824110806\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005721684428863227\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013542966917157173\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001547715743072331\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014615682885050774\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001814022078178823\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006792610511183739\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008882523979991674\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007021015626378357\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009314252529293299\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007922022487036884\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008975759265013039\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006410191999748349\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013375262496992946\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009194323210977018\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009308632579632103\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002789380494505167\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4123045204905793\n",
      "\n",
      "[ Train epoch: 119 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001529647153802216\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007549832225777209\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006484128534793854\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006302347173914313\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010023768991231918\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008288135868497193\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006669210852123797\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006674756295979023\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014640312874689698\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008107568137347698\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007643990102224052\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007750458898954093\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010160792153328657\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001137333340011537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011983613949269056\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000889987510163337\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012381310807541013\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008579493733122945\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007703154115006328\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007644380093552172\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020255090203136206\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001434791018255055\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010017466265708208\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007486984832212329\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001009860192425549\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019790225196629763\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008734935545362532\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007566052954643965\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007182394620031118\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001009918749332428\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012018900597468019\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013090032152831554\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012767384760081768\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009069042280316353\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008580419817008078\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006421093130484223\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008830350125208497\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011648160871118307\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001003148383460939\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010387959191575646\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3966763635107782\n",
      "\n",
      "[ Train epoch: 120 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014154767850413918\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005441515240818262\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014903234550729394\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008813586318865418\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006193486624397337\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000992619781754911\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032139974646270275\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007413977291435003\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007033858564682305\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005723172798752785\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000898101890925318\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008816742338240147\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012395078083500266\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009277400095015764\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005841698148287833\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010017633903771639\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008156415424309671\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012117525329813361\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008246064535342157\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017738700844347477\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010661386186257005\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011362704681232572\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017830991419032216\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014307729434221983\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008136231917887926\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007948484853841364\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000988001236692071\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007808917434886098\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003421098808757961\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007369749946519732\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000704066944308579\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007360514719039202\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010038187028840184\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008977999095804989\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016531123546883464\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006162358913570642\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005277846357785165\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015072958776727319\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010012468555942178\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013242182321846485\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39668290835106745\n",
      "\n",
      "[ Train epoch: 121 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011497733648866415\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009505475172773004\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006969344685785472\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011140898568555713\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00062714604428038\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001315286965109408\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007901479839347303\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007090942235663533\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001111104036681354\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008251852705143392\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011447503929957747\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009686275152489543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008280761539936066\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001250057597644627\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007364520570263267\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008418907527811825\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007918449700810015\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012951352400705218\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001831353991292417\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011054935166612267\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010676798410713673\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010837328154593706\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022248656023293734\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009057297138497233\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000968246953561902\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005649987724609673\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009668741258792579\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00088735471945256\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007332952227443457\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008700354374013841\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006073855911381543\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000968789157923311\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008543287985958159\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009486971539445221\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007634258363395929\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014070551842451096\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008560672285966575\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014537045499309897\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010476596653461456\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007763558533042669\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39770706367562525\n",
      "\n",
      "[ Train epoch: 122 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010252022184431553\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008679237216711044\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007400817121379077\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013299313141033053\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005644336924888194\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011708075180649757\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008983307634480298\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014821022050455213\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008535078959539533\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008148892666213214\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001421793713234365\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000826134579256177\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011035241186618805\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001184128224849701\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009243326494470239\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012088249204680324\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011394312605261803\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014017665525898337\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007730342913419008\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009956498397514224\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008332074503414333\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009501079330220819\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001135195721872151\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006464290199801326\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004784364136867225\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005734228761866689\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009636636241339147\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006853592931292951\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008120138663798571\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006363397114910185\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010344922775402665\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000523584836628288\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019998480565845966\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005575756076723337\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011018668301403522\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013419092865660787\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010146934073418379\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011525878217071295\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001152779906988144\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011058652307838202\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39076877155457623\n",
      "\n",
      "[ Train epoch: 123 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008942857384681702\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011196956038475037\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006875491817481816\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006885741022415459\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011351816356182098\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007411174010485411\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005670099053531885\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006953077390789986\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011463704286143184\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012041805312037468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012615300947800279\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000938605924602598\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009875250980257988\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014472942566499114\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007164051057770848\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021113846451044083\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007280532736331224\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011715673608705401\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008391893934458494\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008388894493691623\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008779027266427875\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014431604649871588\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006191938300617039\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008891255711205304\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015525418566539884\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001985150156542659\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008837766945362091\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010423792991787195\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007391904946416616\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012809010222554207\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001170139410533011\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008565823081880808\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000970338995102793\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009163324721157551\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013123333919793367\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009108353988267481\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018855615053325891\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014673499390482903\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008312095887959003\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008721107733435929\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3904816653812304\n",
      "\n",
      "[ Train epoch: 124 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002138916403055191\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008306161616928875\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011541120475158095\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006929209921509027\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017694069538265467\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009251325391232967\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006201008800417185\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017369294073432684\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011451075552031398\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005770266288891435\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001192657626233995\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008695970755070448\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008155503892339766\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006694505573250353\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008551570936106145\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010630948236212134\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012807021848857403\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008402421954087913\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000844782218337059\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010870032710954547\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007940660580061376\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008866650168783963\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009836605750024319\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012188195250928402\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009353155619464815\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010267700999975204\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019787615165114403\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010094392346218228\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000828016025479883\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009649276034906507\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006147208623588085\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006000316352583468\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00046834725071676075\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000933967181481421\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007267468026839197\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012595192529261112\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008426681743003428\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011350333224982023\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011005187407135963\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001360912574455142\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4055514083884191\n",
      "\n",
      "[ Train epoch: 125 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012028857599943876\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007427294040098786\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00076727953273803\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012606201926246285\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006591315031982958\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008376090554520488\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008249573293142021\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018907171906903386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001016420079395175\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005537362885661423\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010375439887866378\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006746021681465209\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008264128700830042\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018838044488802552\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008289776742458344\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007167548756115139\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00041875746683217585\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015612400602549314\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008350511780008674\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008766924147494137\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00099327159114182\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005222843028604984\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006442739395424724\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010100369108840823\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011327352840453386\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000949651759583503\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000651841051876545\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001016368274576962\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007625175639986992\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011239107698202133\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008823447860777378\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008991261711344123\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007587713771499693\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008952365024015307\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002388225169852376\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007919474155642092\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001096391468308866\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010127821005880833\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008309244876727462\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002928415546193719\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3929449978459161\n",
      "\n",
      "[ Train epoch: 126 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000783244613558054\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014524227008223534\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008406752604059875\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000711370084900409\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006944743799977005\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010463022626936436\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013516448670998216\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007516901241615415\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010177528019994497\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006676277262158692\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008794678142294288\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009455017279833555\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018073528772220016\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012136533623561263\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006863106973469257\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010545598343014717\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010336177656427026\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008077578968368471\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009465128532610834\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009219774510711432\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009989675600081682\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006098195444792509\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008089277544058859\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007582518737763166\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007204607827588916\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010923160007223487\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001447557588107884\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008669209782965481\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007683131261728704\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000828848744276911\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006583028589375317\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009872829541563988\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011623306199908257\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007965262630023062\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010930454591289163\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009613016154617071\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000781745184212923\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008416793425567448\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012349962489679456\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015238607302308083\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.4015655774855986\n",
      "\n",
      "[ Train epoch: 127 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011079258983954787\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000809650169685483\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007309084758162498\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007628785097040236\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009514029370620847\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009496704442426562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005900795804336667\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012509451480582356\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012716882629320025\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006235375185497105\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012763945851475\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007704290910623968\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006948968512006104\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007106825360096991\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001022926764562726\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000539766566362232\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012465053005144\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020378308836370707\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001017570379190147\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010529301362112164\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000981960678473115\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008692934643477201\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017411167500540614\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001000736840069294\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011271957773715258\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013596848584711552\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017622604500502348\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001143312663771212\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000630173075478524\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008567028562538326\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011591616785153747\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007414366700686514\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006857175030745566\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008808940183371305\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008070679614320397\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009303247788920999\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009451517253182828\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006398637196980417\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006384573644027114\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016362164169549942\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39581189447198994\n",
      "\n",
      "[ Train epoch: 128 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016685479786247015\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009232057491317391\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006510220700874925\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014858611393719912\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001233975519426167\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008468175074085593\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008289842517115176\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015243950765579939\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011978867696598172\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008873328915797174\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011684322962537408\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006539879250340164\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006578587926924229\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009789994219318032\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008003046386875212\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009131254628300667\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006903624744154513\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007245994056575\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009827413596212864\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013982933014631271\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012844470329582691\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008573119412176311\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013868865789845586\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000727305538021028\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001793178846128285\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010565874399617314\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001059993403032422\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005732065765187144\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008561690337955952\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010495421011000872\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012286745477467775\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008947819587774575\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000988743151538074\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012264003744348884\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009735515341162682\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010752788512036204\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008827794808894396\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002212916500866413\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000792365288361907\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013417539885267615\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38470559011329897\n",
      "\n",
      "[ Train epoch: 129 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006675980985164642\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008379350183531642\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006938496953807771\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008581478614360094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008163847378455102\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008604263421148062\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010254096705466509\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009238406200893223\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001083236769773066\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007186884758993983\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007111540762707591\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006617907201871276\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012555212015286088\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015643557999283075\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015881131403148174\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009711976745165884\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008470433531329036\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008814017637632787\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001357526984065771\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007609962485730648\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011788122355937958\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010720300488173962\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008797917398624122\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005690891412086785\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014281197218224406\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009991270489990711\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013342528836801648\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007227123714983463\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011717886663973331\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006878173444420099\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009802369168028235\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007415709551423788\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009031644440256059\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007388345547951758\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001649142475798726\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014676438877359033\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006752985063940287\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011925386497750878\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013089224230498075\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016866311198100448\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3960430372389965\n",
      "\n",
      "[ Train epoch: 130 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001751745119690895\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007976056658662856\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006803559372201562\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013140506343916059\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007022802019491792\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007409629761241376\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006424204329960048\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007683193543925881\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011443688999861479\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000702825840562582\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001169663853943348\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013257869286462665\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009419173584319651\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012662152294069529\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011522111017256975\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009298321674577892\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013448805548250675\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017447980353608727\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012582539347931743\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011512228520587087\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011112797074019909\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006852851365692914\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007387418299913406\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014118679100647569\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008492963388562202\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008957750978879631\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009018689161166549\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012913927203044295\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012647327966988087\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008429479203186929\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008078289683908224\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009138377499766648\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001145704765804112\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008553229854442179\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001113428850658238\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001012544147670269\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012938216095790267\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017374573508277535\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010639451211318374\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011474124621599913\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3969570944609586\n",
      "\n",
      "[ Train epoch: 131 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007074271561577916\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009538698359392583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007690535858273506\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023931143805384636\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006865194300189614\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008370745927095413\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008279134053736925\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011102320859208703\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001114962506107986\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010598921217024326\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009326423751190305\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010261785937473178\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008986085304059088\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010328543139621615\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007136217318475246\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009927675127983093\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009571639820933342\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000846663664560765\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010032957652583718\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013403313932940364\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009573792340233922\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013812966644763947\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010449191322550178\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008041959954425693\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008922421257011592\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009566194494254887\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010278226109221578\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011786973336711526\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007927471306174994\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007704420131631196\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012012537335976958\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008164048776961863\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011100679403170943\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006904281908646226\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008964730659499764\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005506047164089978\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009468828793615103\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008769991691224277\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008449925226159394\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007401465554721653\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39025024173315614\n",
      "\n",
      "[ Train epoch: 132 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013517944607883692\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011742287315428257\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010176821378991008\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001380602247081697\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001686733914539218\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008452204638160765\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007879579206928611\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008745082886889577\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010784703772515059\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006617865874432027\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009503620094619691\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011872967006638646\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015800142427906394\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00090828473912552\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001716996543109417\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009358148090541363\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013086522230878472\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012443343875929713\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004993324400857091\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006748547311872244\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012844920856878161\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010578609071671963\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011392321903258562\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009453116217628121\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000697142502758652\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011544389417394996\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005213411059230566\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007045850506983697\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012738058576360345\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012670009164139628\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008273856365121901\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006901412270963192\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006408012704923749\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000871968106366694\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008905207505449653\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000810438534244895\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006237025372684002\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010346724884584546\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016173595795407891\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015903275925666094\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39114221098134294\n",
      "\n",
      "[ Train epoch: 133 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016320421127602458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008141868165694177\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012848112965002656\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007208437891677022\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011297701857984066\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009344540885649621\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006688227294944227\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007067361148074269\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009216673788614571\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006946243229322135\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012619121698662639\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032475737389177084\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011997456895187497\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00118497502990067\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006631441647186875\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001579122501425445\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006417746189981699\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008681875187903643\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006681007798761129\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001908963662572205\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007430323166772723\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011314196744933724\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014808785635977983\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013704998418688774\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007448646356351674\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00066802540095523\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007585656130686402\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007031767163425684\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011132765794172883\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013326628832146525\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001008400460705161\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007986165001057088\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009126940276473761\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00139702670276165\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010459086624905467\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008949046023190022\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00084301846800372\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013231025077402592\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010420953622087836\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001073134713806212\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3981261327571701\n",
      "\n",
      "[ Train epoch: 134 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000643320323433727\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022587552666664124\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020237131975591183\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008740568300709128\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008121349383145571\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008654168341308832\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011892589973285794\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007995629566721618\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009600981138646603\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007380081224255264\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006131856353022158\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008156205294653773\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008871486643329263\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001982596702873707\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019053482683375478\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008122285944409668\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013530416181311011\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000670946144964546\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012450347421690822\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001119176740758121\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008516889647580683\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012073575053364038\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010133740724995732\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007511781295761466\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008180099539458752\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008723417413420975\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007025956874713302\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006585607188753784\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006667691050097346\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005575814284384251\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000743017764762044\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008488313178531826\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009443421149626374\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000885130139067769\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006473983521573246\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001189841772429645\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00090601242845878\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009251319570466876\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011039783712476492\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008849151199683547\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39362499362323433\n",
      "\n",
      "[ Train epoch: 135 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008889747550711036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012640358181670308\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008142726146616042\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015146532095968723\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001646166667342186\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001157163642346859\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010798394214361906\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005663933116011322\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008288074168376625\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011510243639349937\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010536721674725413\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007698859553784132\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009556311997584999\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010195389622822404\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007610957836732268\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001162468339316547\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006702582468278706\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008018390508368611\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008551800274290144\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000916786550078541\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010044357040897012\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008492330671288073\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011277047451585531\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009300537058152258\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000856646103784442\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001684247050434351\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009162377682514489\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007711209473200142\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008839821093715727\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009182075154967606\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007088166894391179\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005819887737743556\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014499268727377057\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013427279191091657\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006221114890649915\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001113898935727775\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009582332568243146\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011303112842142582\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001363376504741609\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015128370141610503\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38872982951579615\n",
      "\n",
      "[ Train epoch: 136 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006975845317356288\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000618250691331923\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005368630518205464\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011892708716914058\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000984499230980873\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009763049311004579\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011669035302475095\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014659569133073092\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011497436789795756\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001673731952905655\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008488452876918018\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008968453039415181\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008428988512605429\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007586590363644063\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000910346454475075\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011173191014677286\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008648171788081527\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001312385662458837\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009033411624841392\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012468673521652818\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009776075603440404\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012187381507828832\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006556033040396869\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008867532014846802\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008311524288728833\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010650327894836664\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001680913264863193\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007831845432519913\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008714619325473905\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008125334861688316\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012935890117660165\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014173270901665092\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006857839180156589\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007006891537457705\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010541880037635565\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001746928202919662\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010953509481623769\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005988649209029973\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010024193907156587\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006601629429496825\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39477860045735724\n",
      "\n",
      "[ Train epoch: 137 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001145443762652576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007286630570888519\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00110408547334373\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016297345282509923\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009294853662140667\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001277731149457395\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008155023097060621\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006239975336939096\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002352976705878973\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013087393017485738\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010252733482047915\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008621349115855992\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008405016269534826\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009770200122147799\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009537817095406353\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001038801041431725\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009807692840695381\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00103952141944319\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011370155261829495\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010638185776770115\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001223511528223753\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009784826543182135\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008325279341079295\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000617167039308697\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001149319694377482\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011613309616222978\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009495153790339828\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001439979998394847\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000720213633030653\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094971434213221\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010491162538528442\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007691349019296467\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012560401810333133\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009470075601711869\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010428084060549736\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007661975105293095\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009911238448694348\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010869489051401615\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011209531221538782\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002400910947471857\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39805352545226924\n",
      "\n",
      "[ Train epoch: 138 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008843825780786574\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008361208601854742\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011972864158451557\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001347981276921928\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005522090359590948\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014794450253248215\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006984601495787501\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009064372861757874\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006141068879514933\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001207721303217113\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00122714857570827\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007860719342716038\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009913885733112693\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006401731516234577\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010736454278230667\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006912879180163145\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008202607277780771\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017890902236104012\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006163743091747165\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004779846640303731\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009346106089651585\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008780944626778364\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008805193356238306\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012763740960508585\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014225913910195231\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007029151893220842\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009070985252037644\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008065407746471465\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001712396857328713\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011261843610554934\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009288726141676307\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007613985217176378\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011092228814959526\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008229058003053069\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009653247543610632\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019022126216441393\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007846832741051912\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000699502183124423\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008890615426935256\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008427524007856846\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39361413722508587\n",
      "\n",
      "[ Train epoch: 139 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001098371809348464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007332901004701853\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016794016119092703\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010700953425839543\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017273824196308851\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007663751021027565\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009456875268369913\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008596283732913435\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006873185629956424\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002967020496726036\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009589772089384496\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008240451570600271\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009387856116518378\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006096161087043583\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016579348593950272\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012192430440336466\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012353349011391401\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014327005483210087\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007790142553858459\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006259262445382774\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008002939284779131\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006499440059997141\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005012810579501092\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005604395410045981\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006915794801898301\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006622700020670891\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014765902888029814\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012067666975781322\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013220278779044747\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009882538579404354\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000658967939671129\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001320475828833878\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001087501528672874\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001615710905753076\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014051856705918908\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013103631790727377\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007847629021853209\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010163775878027081\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009128318051807582\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005905902944505215\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3934368571790401\n",
      "\n",
      "[ Train epoch: 140 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010776463896036148\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010646936716511846\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009596385061740875\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006208177655935287\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009311182657256722\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001083461451344192\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013398975133895874\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010332184610888362\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007547585992142558\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001015655929222703\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007815333665348589\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006965718348510563\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000831371231470257\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007755893166176975\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017433653119951487\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000728333427105099\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009763505659066141\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005464947898872197\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007806798676028848\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013653053902089596\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007080576615408063\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000946434389334172\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007603801204822958\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007217552629299462\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008640362066216767\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000991962617263198\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012184205697849393\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007519696955569088\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009568451205268502\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007725214818492532\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006589689292013645\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008149336790665984\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001253782189451158\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008966937311924994\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001437634346075356\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00104288209695369\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013186767464503646\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020044927950948477\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007181823602877557\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020360047928988934\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3877958379453048\n",
      "\n",
      "[ Train epoch: 141 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010271106148138642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001320000970736146\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007841105689294636\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007741887820884585\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008678951999172568\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008430095622316003\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009846074972301722\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011890577152371407\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007850442780181766\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006549858371727169\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011721249902620912\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008370815776288509\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007952068117447197\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008320430060848594\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007179984822869301\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009193848236463964\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011640392476692796\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001160095795057714\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010437252931296825\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010402335319668055\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008248868980444968\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007328219944611192\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011655964190140367\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001162699656561017\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007108782883733511\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009431710350327194\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009589831461198628\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012329862220212817\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008970488561317325\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001054022228345275\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016244219150394201\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010309854988008738\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008583412272855639\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000820827845018357\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013400564203038812\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007939811912365258\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008391921292059124\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008934868965297937\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007833078852854669\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017662517493590713\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3874766562948935\n",
      "\n",
      "[ Train epoch: 142 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011741664493456483\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006332751363515854\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008710529073141515\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006963249761611223\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009631992434151471\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010365722700953484\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001036641071550548\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008054781355895102\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005984295275993645\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009407603065483272\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011461360845714808\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001456640544347465\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007071914151310921\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008697066805325449\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007074893219396472\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006039341096766293\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00099236611276865\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011939893011003733\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001201148726977408\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010542302625253797\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006529024103656411\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006575580919161439\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009929290972650051\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011783703230321407\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011901005636900663\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012138731544837356\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001366979326121509\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008586015901528299\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000921419239602983\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008418054203502834\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008583743474446237\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008828106219880283\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000792877224739641\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007711075013503432\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007407786906696856\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007170342141762376\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014016448985785246\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008143186569213867\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012682954547926784\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018952531972900033\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3903487890493125\n",
      "\n",
      "[ Train epoch: 143 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009571868577040732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009475338156335056\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012759944656863809\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007110820151865482\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008941409760154784\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009865687461569905\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009767450392246246\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010056482860818505\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008462427067570388\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000615126162301749\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010003517381846905\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000533529557287693\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009461287991143763\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000748521531932056\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008870690362527966\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009125876240432262\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011078044772148132\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009191372082568705\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007215089281089604\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007450972916558385\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006097405566833913\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016127647832036018\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008342599612660706\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00114929280243814\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000862293760292232\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009135096915997565\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008823847165331244\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008088047034107149\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000801866699475795\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013988680439069867\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014050554018467665\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013934795279055834\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001283270656131208\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001108820317313075\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005411827587522566\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006970543181523681\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012662188382819295\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008197136339731514\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011625443585217\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007729431381449103\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.39147761499043554\n",
      "\n",
      "[ Train epoch: 144 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006855835672467947\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007642825366929173\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008439915254712105\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001248786342330277\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001084168441593647\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011628796346485615\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015223008813336492\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009144471259787679\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014458638615906239\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007977967034094036\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008546173921786249\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008399991784244776\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008345909882336855\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009066496277227998\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007925597601570189\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007805366767570376\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007495669415220618\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008782612858340144\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007658622344024479\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009759023087099195\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015016291290521622\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010992998722940683\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007208446622826159\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007730945944786072\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008823385578580201\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007583963451907039\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009332020417787135\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013936187606304884\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012203099904581904\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009332920308224857\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011633243411779404\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011989237973466516\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010263562435284257\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008436002535745502\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008773767622187734\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008531457860954106\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008424269617535174\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006997903692536056\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001005344558507204\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016740690916776657\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38978590728947893\n",
      "\n",
      "[ Train epoch: 145 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000883568252902478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010477588512003422\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007506990805268288\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008355359896086156\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009936463320627809\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011323918588459492\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010742621961981058\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008570750360377133\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007573209004476666\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008406492997892201\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008095807861536741\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007745692855678499\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011535629164427519\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012226488906890154\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010010884143412113\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000672967522405088\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000708696199581027\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008433753391727805\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013016583397984505\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010810642270371318\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008535495144315064\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009275981574319303\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008384727407246828\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011774625163525343\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001318619353696704\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000731137115508318\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009099774761125445\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009612385183572769\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008096908568404615\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007822984480299056\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009516093414276838\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011561313876882195\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009535821154713631\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010736753465607762\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011907543521374464\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008416211348958313\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017929932801052928\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000952845613937825\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000909522466827184\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010931937722489238\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38801387569401413\n",
      "\n",
      "[ Train epoch: 146 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001811223104596138\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008477228693664074\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006501314346678555\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001399040105752647\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009412641520611942\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006840713322162628\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006273749168030918\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008651574607938528\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012626316165551543\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007004605722613633\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008731447160243988\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007535767508670688\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007668444304727018\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007830671383999288\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009289428708143532\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012121053878217936\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008154019596986473\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000748249760363251\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000893239164724946\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013150465674698353\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006971059483475983\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000941313395742327\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001071167178452015\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011367510305717587\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000879705126862973\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008856941130943596\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009554075659252703\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007095798500813544\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008227245998568833\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006949507514946163\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000800830777734518\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008193314424715936\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011246850481256843\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007949302671477199\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008588669588789344\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001139660831540823\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000753160216845572\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008405055268667638\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000855346443131566\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012274530017748475\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37896138266660273\n",
      "\n",
      "[ Train epoch: 147 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014937376836314797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006583149661310017\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00132463697809726\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009052662062458694\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010102562373504043\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008784766541793942\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009478583815507591\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000796680455096066\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009938509901985526\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012056874111294746\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010506463004276156\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006796944653615355\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007112534949555993\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013875974109396338\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001091772224754095\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007866251398809254\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006262616370804608\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011206947965547442\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009836711687967181\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017567550530657172\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011353060835972428\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008019116939976811\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001083020819351077\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007681510760448873\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014944556169211864\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007699576672166586\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007629847968928516\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001018407172523439\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009265081607736647\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008448020671494305\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006105578504502773\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010946093825623393\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001527581480331719\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007676074164919555\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007927328115329146\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006437950069084764\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011513667413964868\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010492777219042182\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007843389175832272\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016233252827078104\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3808349352912046\n",
      "\n",
      "[ Train epoch: 148 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010373033583164215\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011605460895225406\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001320067560300231\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007166928262449801\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000867148395627737\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010594967752695084\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012479900615289807\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011282284976914525\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007104253163561225\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008460840908810496\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009197902982123196\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010985693661496043\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007962919189594686\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009112180559895933\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008443879196420312\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012803090503439307\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007968197460286319\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009281720849685371\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000623605155851692\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009527114452794194\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007916344329714775\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018179230391979218\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009763092384673655\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001743474043905735\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001253885100595653\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008959221304394305\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011456308420747519\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006620145868510008\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012448952766135335\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000795224099420011\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013004442444071174\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006846060859970748\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009575422154739499\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011388668790459633\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007845479412935674\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010979898506775498\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010714699747040868\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009676067857071757\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010615632636472583\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001359862508252263\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38623520015971735\n",
      "\n",
      "[ Train epoch: 149 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011918148957192898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001837390474975109\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008092938223853707\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008492505294270813\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006887205527164042\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008543099975213408\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001110545126721263\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008752702851779759\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010204528225585818\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011802352964878082\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009024825412780046\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005957173416391015\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014352274592965841\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009031304507516325\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006532823899760842\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012167098466306925\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010440099285915494\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009561812039464712\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009267244022339582\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005790199502371252\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008878290536813438\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008751567802391946\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006706224521622062\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007578073418699205\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009733736515045166\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016172528266906738\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000668465974740684\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008598123677074909\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009590981644578278\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000883684610016644\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007682882715016603\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010940787615254521\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011250575771555305\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000864485336933285\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008105394663289189\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009238807833753526\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008496138034388423\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001210315153002739\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015996441943570971\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007082369411364198\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38265213041449897\n",
      "\n",
      "[ Train epoch: 150 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010409638052806258\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007995508494786918\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015142079209908843\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001315669622272253\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011880790116265416\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009224132518284023\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007449404802173376\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010681358398869634\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008493791101500392\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008209966472350061\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010475791059434414\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008141531143337488\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008444571285508573\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006570550031028688\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007503823726437986\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007248573238030076\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007167771109379828\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000717140210326761\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008456200594082475\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010057005565613508\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007651642081327736\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009407297475263476\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009362815180793405\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008727571694180369\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008876002975739539\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010231853229925036\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012792620109394193\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009513725526630878\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008509106119163334\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006516315042972565\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009660432697273791\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007832873961888254\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012189920525997877\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007845168001949787\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001004692749120295\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007618480594828725\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010432626586407423\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011123664444312453\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009585653897374868\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013241436099633574\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3831318113952875\n",
      "\n",
      "[ Train epoch: 151 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015184922376647592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011274067219346762\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012310482561588287\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008708092500455678\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001046896679326892\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008383064996451139\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008133089868351817\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014306638622656465\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012543554184958339\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007296571275219321\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009408093756064773\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007579638040624559\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011400640942156315\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007916955510154366\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010630062315613031\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007895221351645887\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011036423966288567\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011026922147721052\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012232220033183694\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007321791490539908\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010095782345160842\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008549049962311983\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007165438728407025\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010593098122626543\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001196698285639286\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007983638788573444\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010342271998524666\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009246678673662245\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013345006154850125\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001110798679292202\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008188763167709112\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009938307339325547\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007154428749345243\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008062073029577732\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007963001262396574\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001126113929785788\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011079420801252127\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015254283789545298\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007600061944685876\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013625063002109528\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3787205531843938\n",
      "\n",
      "[ Train epoch: 152 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006531774415634573\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011984665179625154\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008422227692790329\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008941220003180206\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007517259218730032\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009799745166674256\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014298625756055117\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008187709026969969\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008237065048888326\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009638197952881455\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010170353343710303\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008551362552680075\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004652644973248243\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010586711578071117\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007173064514063299\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011476706713438034\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006614802405238152\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006962241022847593\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001332951127551496\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000885655521415174\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009149225079454482\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008053645142354071\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009802405256778002\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007372332620434463\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008324815426021814\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007289253990165889\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010110196890309453\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007368118967860937\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010059719206765294\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001336576882749796\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001269431202672422\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016341565642505884\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00078186223981902\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008138064877130091\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008294412400573492\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008741291821934283\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009750672616064548\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009329871973022819\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006231594597920775\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010456719901412725\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37900572357466444\n",
      "\n",
      "[ Train epoch: 153 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006672573508694768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008154751849360764\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006344018038362265\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012113128323107958\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011762615758925676\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010813941480591893\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012095689307898283\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011689881794154644\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010399747407063842\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008973082876764238\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009331486071459949\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006328104645945132\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001983212074264884\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010854360880330205\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010396097786724567\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008134927484206855\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00084920838708058\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009524113265797496\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006934232078492641\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007823455962352455\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000668407476041466\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011999005218967795\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010365593479946256\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008857965003699064\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007768531213514507\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011166256153956056\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011139257112517953\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000998921343125403\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019733563531190157\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009537520236335695\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008331745048053563\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007071337895467877\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010386815993115306\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007245785091072321\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008805684046819806\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007089240825735033\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006618359475396574\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007505135727114975\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000764718628488481\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007599199889227748\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37834013416431844\n",
      "\n",
      "[ Train epoch: 154 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010655529331415892\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012105191126465797\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007375358836725354\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010871783597394824\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001083745388314128\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009898996213451028\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011892294278368354\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008110260823741555\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007968043209984899\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011818059720098972\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009211834985762835\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000897243560757488\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001455005258321762\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007369917584583163\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010485887760296464\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007385259959846735\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010317466221749783\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008696522563695908\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012351092882454395\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008978309342637658\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000892016279976815\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012732029426842928\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012405122397467494\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015491497470065951\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008880026871338487\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011953276116400957\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000755718385335058\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008706520311534405\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000765613338444382\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008912011398933828\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014498730888590217\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000729893334209919\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009975217981263995\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007616259972564876\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011498825624585152\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009372500935569406\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008051241748034954\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010649817995727062\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013301994185894728\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010389878880232573\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37895862344885245\n",
      "\n",
      "[ Train epoch: 155 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010095247998833656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007349675288423896\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007446154486387968\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000882610387634486\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001773844356648624\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009038121206685901\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025792233645915985\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006934928242117167\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013794680126011372\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008023146656341851\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007697049877606332\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011730713304132223\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008616846753284335\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008334119920618832\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015959892189130187\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008250047685578465\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014933353522792459\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007960568764247\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009418561821803451\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007925460813567042\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008059131796471775\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007190803880803287\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007364933844655752\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012045296607539058\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006258766516111791\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008951543131843209\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015856832033023238\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009290389134548604\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010839976603165269\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000845337868668139\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008300780900754035\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009231794392690063\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005739947082474828\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015739845111966133\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009255163604393601\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000663805054500699\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007653009961359203\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008381836232729256\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009735348867252469\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011297819437459111\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3785477193305269\n",
      "\n",
      "[ Train epoch: 156 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008556033135391772\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008264701464213431\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011172539088875055\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009151791455224156\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008418350480496883\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009419121779501438\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000757841975428164\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009400811977684498\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009387697791680694\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000707199505995959\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011322360951453447\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009111751569435\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018980047898367047\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009671317529864609\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013172533363103867\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00091644556960091\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001433085766620934\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008818429196253419\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007528429268859327\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007295531104318798\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011082760756835341\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012201983481645584\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006422371952794492\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008951372583396733\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008621063316240907\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008746192906983197\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008465562132187188\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000995151000097394\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007456739549525082\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007539577200077474\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008249233360402286\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015986496582627296\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016742546577006578\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007404673960991204\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012033885577693582\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008544143056496978\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009577638702467084\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009671419975347817\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007961662486195564\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014442631509155035\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3813856411143206\n",
      "\n",
      "[ Train epoch: 157 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007758661522530019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006654990138486028\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008482185658067465\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009316634968854487\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010232353815808892\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009015948744490743\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006114656571298838\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009908421197906137\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013867334928363562\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025358672719448805\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008864424889907241\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006720113451592624\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010870007099583745\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011886385036632419\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000886220543179661\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010006874799728394\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013325910549610853\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010518657509237528\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009160151821561158\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008798540220595896\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001846429193392396\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010345815680921078\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008628948708064854\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009323448757641017\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001583693316206336\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009690705919638276\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008579549612477422\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008393661119043827\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007884491933509707\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010331139201298356\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009243142558261752\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006782005075365305\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009328362066298723\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013468170072883368\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008345138630829751\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007929480052553117\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012882174924015999\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000760951079428196\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007433790015056729\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001287564868107438\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3767769744154066\n",
      "\n",
      "[ Train epoch: 158 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009012380614876747\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000825845287181437\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001227139844559133\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000658937671687454\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006769170868210495\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008886656723916531\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009221054497174919\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010281503200531006\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007888070540502667\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006054035620763898\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009704332915134728\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005773691227659583\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011564198648557067\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010529482970014215\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009006867185235023\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007611337350681424\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007303333841264248\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008275203290395439\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008960964041762054\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000648035085760057\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007458831532858312\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007844389765523374\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013851671246811748\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011646854691207409\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010658439714461565\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000882416614331305\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000733542547095567\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007395315333269536\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010534872999414802\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009387220488861203\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011249019298702478\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012697348138317466\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012849868508055806\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010281892027705908\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012664067326113582\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010316800326108932\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006545273936353624\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009939110605046153\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009416565299034119\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015483367023989558\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3784188127028756\n",
      "\n",
      "[ Train epoch: 159 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008516693487763405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009322752594016492\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000923226005397737\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005973118240945041\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008096820674836636\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008319005719386041\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001122256857343018\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017090046312659979\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012711009476333857\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011149892816320062\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009025419130921364\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007561115780845284\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00092861003940925\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006927576032467186\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013547304552048445\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009054301190190017\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008235466084443033\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007432285929098725\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001037830370478332\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010186327854171395\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006566226365976036\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010556962806731462\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009094434208236635\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007052271394059062\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008492814959026873\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006569518591277301\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007665809243917465\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010002664057537913\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007682208088226616\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006668115966022015\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009509551455266774\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008407147252000868\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013782421592622995\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016424355562776327\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010491469874978065\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001023393007926643\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011203500907868147\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000906898349057883\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007310090586543083\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019088627304881811\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38185806991532445\n",
      "\n",
      "[ Train epoch: 160 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000953609764110297\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010261955903843045\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008572912774980068\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008747002575546503\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001354357460513711\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005214046686887741\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008175099501386285\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000606807298026979\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011054137721657753\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009694127948023379\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008148616179823875\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018675393657758832\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008991838549263775\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006894658436067402\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014505489962175488\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009220990468747914\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012012490769848228\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008265553624369204\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007300357683561742\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001255225739441812\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011853310279548168\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001069474034011364\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008008452714420855\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011753037106245756\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006837242399342358\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010123216779902577\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011746909003704786\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009667640551924706\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006626950344070792\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007250467897392809\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000995286158286035\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001042171148583293\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009341121185570955\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008421549573540688\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016325374599546194\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010194758651778102\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001110103097744286\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001126528950408101\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007726544863544405\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007826843066141009\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3847525405290071\n",
      "\n",
      "[ Train epoch: 161 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007618063245899975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009015285759232938\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008389927097596228\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006459291325882077\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008760771597735584\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006845407770015299\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011182422749698162\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007863701321184635\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000845416565425694\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000756064779125154\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009632740402594209\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011520576663315296\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001198982703499496\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007568711298517883\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013581959065049887\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007253334042616189\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009693659958429635\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001049569807946682\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011114971712231636\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008834500331431627\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008142493315972388\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009193338919430971\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009672875748947263\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001179404091089964\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00111260951962322\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000877675018273294\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008890901226550341\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006344552966766059\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007626527221873403\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013626166619360447\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006833871593698859\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007353725959546864\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00123991456348449\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006990125984884799\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000984639162197709\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005304312217049301\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009521398460492492\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006967486115172505\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008033635094761848\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010851637925952673\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3797931906883605\n",
      "\n",
      "[ Train epoch: 162 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010902414796873927\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007570389425382018\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000863822060637176\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007774760597385466\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001024108612909913\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009009609930217266\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006380460690706968\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011415519984439015\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007310212240554392\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013892133720219135\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008701776969246566\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008704697829671204\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010118926875293255\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008585876203142107\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006117341108620167\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010098266648128629\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008778867777436972\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011264985660091043\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000920045655220747\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010905098170042038\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009081015596166253\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011041975812986493\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011936590308323503\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008998933481052518\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010522282682359219\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008381991647183895\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006896756822243333\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009331891196779907\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008021566900424659\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009620049386285245\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007677661487832665\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010320964502170682\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008862711256369948\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007104284013621509\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011367624392732978\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001181763014756143\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014717582380399108\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008682443294674158\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008462577825412154\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007001863559707999\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3801562047447078\n",
      "\n",
      "[ Train epoch: 163 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011725455988198519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012527338694781065\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008273257990367711\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001343239564448595\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008711594273336232\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008490897016599774\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007929929997771978\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016115037724375725\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010941025102511048\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008704363717697561\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012842308497056365\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002489672042429447\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011650879168882966\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001164122368209064\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008423038525506854\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007653277716599405\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010788310319185257\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000941153266467154\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009851829381659627\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009289754088968039\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012975300196558237\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008639829466119409\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009984038770198822\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007176843355409801\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015591034898534417\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018603993812575936\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013152894098311663\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007473544683307409\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010050443233922124\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013923353981226683\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007138546206988394\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007021029596216977\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007068734266795218\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023830553982406855\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010570725426077843\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001164063229225576\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012903015594929457\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000830100616440177\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007883558864705265\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007770966039970517\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37697753740940243\n",
      "\n",
      "[ Train epoch: 164 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008943736902438104\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001500389538705349\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007023540092632174\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012018874986097217\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009127923985943198\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007540699443779886\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010629489552229643\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008286490919999778\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001000508083961904\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009532533003948629\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002172463806346059\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001419014297425747\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007941744406707585\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00159250118304044\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011711473343893886\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00087085145059973\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009319748496636748\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008146206964738667\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008092166390269995\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000763563672080636\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008338805637322366\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001253898604772985\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009897524723783135\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010936863254755735\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007713978411629796\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017428183928132057\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006954603013582528\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006958224694244564\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009526085341349244\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008479100652039051\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007768264040350914\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007560435333289206\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006983987987041473\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011030657915398479\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007538626086898148\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009299138328060508\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013972840970382094\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009189244592562318\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001301388256251812\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003028667764738202\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3844429146265611\n",
      "\n",
      "[ Train epoch: 165 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006713963812217116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017658796859905124\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007137515349313617\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008805276011116803\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012808491010218859\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007915921160019934\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006499040755443275\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008029625751078129\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007549797301180661\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000759103219024837\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008398148929700255\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007720815483480692\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009434635285288095\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008502909913659096\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007783071487210691\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009180911583825946\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009029586799442768\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009680825169198215\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009016884723678231\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014066536678001285\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000997742172330618\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006943528424017131\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007841721526347101\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008108480833470821\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007435156730934978\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011235496494919062\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010848446981981397\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000735183188226074\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008538609836250544\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007193704368546605\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009517173748463392\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008030571625567973\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011295838048681617\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009023750899359584\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007628476596437395\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001288847648538649\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009236827027052641\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001048316597007215\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00269977655261755\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009964010678231716\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3706429377780296\n",
      "\n",
      "[ Train epoch: 166 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007617752999067307\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008624494657851756\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008410829468630254\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014842093223705888\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010364650515839458\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008327628602273762\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005434162449091673\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008514304645359516\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009527918300591409\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008434934425167739\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000975388684310019\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000659536337479949\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008731082198210061\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008736858726479113\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006490927771665156\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011065838625654578\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006074669072404504\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006501392344944179\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007000513141974807\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009644417441450059\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009133669082075357\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006473612738773227\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012941585155203938\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010777722345665097\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013029142282903194\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012429443886503577\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009317040676251054\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011603148886933923\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008630718220956624\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001238074037246406\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005943476571701467\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000828415562864393\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008546342141926289\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007264650193974376\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008061041589826345\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007827978115528822\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011932721827179193\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012261060765013099\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011339096818119287\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013483039801940322\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38565307710086927\n",
      "\n",
      "[ Train epoch: 167 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007519439095631242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009620962664484978\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007477361359633505\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008844351978041232\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008244978380389512\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008176218252629042\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007233145297504961\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008806319092400372\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008515809313394129\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006815853412263095\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007852365961298347\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008902451954782009\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008020536042749882\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019060352351516485\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007611533510498703\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001022843411192298\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008391147130168974\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012185698142275214\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007039638003334403\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010204166173934937\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006849885103292763\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011680172756314278\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00127727584913373\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009155530133284628\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008920003892853856\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011630821973085403\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010077066253870726\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007906823884695768\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008860331727191806\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009672596934251487\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012829483021050692\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010870235273614526\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010402404004707932\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000755412969738245\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007608087616972625\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001117660547606647\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012306761927902699\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007966686389409006\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010834462009370327\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017720448086038232\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3894763832213357\n",
      "\n",
      "[ Train epoch: 168 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012844481971114874\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009738446096889675\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010840947506949306\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006511415122076869\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010434490395709872\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015168774407356977\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006818780675530434\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009603022481314838\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009304944542236626\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008590966463088989\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001030733692459762\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008394231554120779\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006816915119998157\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008428473374806345\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006276889471337199\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009503909386694431\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009851232171058655\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012118680169805884\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001253770780749619\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006617089966312051\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009131324477493763\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011429411824792624\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008480720571242273\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008983637671917677\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008124880259856582\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007846306543797255\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013143300311639905\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010819935705512762\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012914356775581837\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009071131353266537\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013992601307108998\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008229437517002225\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001034048036672175\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009761297260411084\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010674025397747755\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006950257229618728\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010060560889542103\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00101411750074476\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007273430819623172\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010801139287650585\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3788425177335739\n",
      "\n",
      "[ Train epoch: 169 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008026824798434973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008588002528995275\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010592034086585045\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012901297304779291\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008967923931777477\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007417564047500491\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009772212943062186\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012248699786141515\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021752617321908474\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009233542950823903\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009501497261226177\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010321716545149684\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010367833310738206\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010287445038557053\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011602203594520688\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011873608455061913\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009117628214880824\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000679311400745064\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008151502697728574\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007083966047503054\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007671676576137543\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012997727608308196\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000952136586420238\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000978113734163344\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006583905778825283\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007649743929505348\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012667657574638724\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008552464423701167\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009523851913399994\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008439772063866258\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011813819874078035\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007948720012791455\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000736416841391474\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010319242719560862\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007649306789971888\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000975540722720325\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008783688535913825\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009074817062355578\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008323786896653473\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012645797105506063\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3831587833701633\n",
      "\n",
      "[ Train epoch: 170 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010673454962670803\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007993557373993099\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006928616785444319\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009806354064494371\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008908293093554676\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000778332119807601\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007781591266393661\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012950211530551314\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006283189286477864\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008882568799890578\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009078256553038955\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009845023741945624\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008628296782262623\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008940054685808718\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001035412889905274\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007889528060331941\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001106436480768025\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007560999365523458\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011335877934470773\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007146490388549864\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010325635084882379\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001323052099905908\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008987485780380666\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007969298167154193\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018035747343674302\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009541664621792734\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011015889467671514\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008783636731095612\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010891415877267718\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001432393561117351\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006948868394829333\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010043890215456486\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006823428557254374\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018195555312559009\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001159180304966867\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010969680733978748\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015716988127678633\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006038326537236571\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001258845441043377\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019252666970714927\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3806169598829001\n",
      "\n",
      "[ Train epoch: 171 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008524559088982642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007977354689501226\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010490173008292913\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006826625321991742\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000809495453722775\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009266318520531058\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000880288949701935\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018083323957398534\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009056065464392304\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009302861290052533\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009482033201493323\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001187005895189941\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010726817417889833\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010819971794262528\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000874287448823452\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006607314571738243\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007338464492931962\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006974764401093125\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001068239682354033\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007790421368554235\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009285568376071751\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015370482578873634\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006276981439441442\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007723874878138304\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008156537660397589\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001113906386308372\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009764459682628512\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008176163537427783\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006754706846550107\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009102115873247385\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012289227452129126\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014082376146689057\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006766293663531542\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008053750498220325\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011329265544191003\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010182132245972753\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00101947330404073\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000899511156603694\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000722300261259079\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013032868737354875\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37255267589353025\n",
      "\n",
      "[ Train epoch: 172 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009011004003696144\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000922841252759099\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010608131997287273\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008162643061950803\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009338452364318073\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007598004303872585\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010861572809517384\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022181053645908833\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007177879451774061\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008723836508579552\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006604886148124933\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000980592449195683\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000919272075407207\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008306049276143312\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008510662009939551\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008124109590426087\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006457807030528784\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010166086722165346\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006150621920824051\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000742655189242214\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007369885570369661\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011237743310630322\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009243040694855154\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010564933763816953\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009715148480609059\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010671276831999421\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006720999954268336\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015844509471207857\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009401357383467257\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008357564220204949\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000826026254799217\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009200247004628181\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006364717264659703\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008606664487160742\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008529294282197952\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014061639085412025\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008102679857984185\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009138241875916719\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000693847774527967\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018462485168129206\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3818918121396564\n",
      "\n",
      "[ Train epoch: 173 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008291881531476974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015280001098290086\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010872778948396444\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008568072807975113\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008672173134982586\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000896537909284234\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020162391010671854\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007276156102307141\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012952710967510939\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008624349720776081\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000974545138888061\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009981620823964477\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011415128828957677\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014683441258966923\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007266798638738692\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000878506398294121\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009765345021151006\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000864634697791189\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010236063972115517\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012503572506830096\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006876735133118927\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005930703482590616\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010441369377076626\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007210124167613685\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009191918070428073\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007824636995792389\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008546760655008256\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010735070100054145\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001107027637772262\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007777084247209132\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015286370180547237\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011388241546228528\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010068370029330254\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008590893121436238\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009069528896361589\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007108959835022688\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011793079320341349\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007706848555244505\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000771863094996661\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007620404358021915\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.374605805875035\n",
      "\n",
      "[ Train epoch: 174 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018999986350536346\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009400962153449655\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007985787815414369\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001048555481247604\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008627568022347987\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010011474369093776\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010623852722346783\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009166952804662287\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007805248606018722\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006588929682038724\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001016558613628149\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005552314105443656\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000671056448481977\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001270802691578865\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019017307786270976\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008839470683597028\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009643303346820176\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016078264452517033\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007089896243996918\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008340970380231738\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00089088553795591\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010542977834120393\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008197221322916448\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010061220964416862\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001251045148819685\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009381917770951986\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001178648672066629\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007254963857121766\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006179761840030551\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007788376533426344\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012359338579699397\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009561952319927514\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000817282882053405\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009651099680922925\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007592554320581257\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007920402567833662\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009281469392590225\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007876827148720622\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009223396773450077\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008186153136193752\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37451662827515975\n",
      "\n",
      "[ Train epoch: 175 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008351347642019391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009164850343950093\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001143741188570857\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009134167921729386\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010780267184600234\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010349882068112493\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014598943525925279\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001102939830161631\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000866018352098763\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008323121583089232\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009216300677508116\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024217681493610144\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010666442103683949\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008196845301426947\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009726642747409642\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008935787482187152\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010923233348876238\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011015948839485645\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008099870756268501\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009445659816265106\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012808515457436442\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007585689309053123\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007381102768704295\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00253991293720901\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012036394327878952\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001908669131807983\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007736069383099675\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000684485596138984\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013876912416890264\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007124254480004311\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008117440738715231\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000738337286747992\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006501980242319405\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011028200387954712\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007799985469318926\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018683373928070068\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011467760195955634\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011174826649948955\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006740166572853923\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002173860091716051\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3830441871541552\n",
      "\n",
      "[ Train epoch: 176 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011796689359471202\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012828801991418004\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011957555543631315\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010476813185960054\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009662816300988197\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011518123792484403\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007640168769285083\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011605896288529038\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009741634130477905\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000718643597792834\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008204552577808499\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008513726643286645\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008486348087899387\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008761376375332475\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008156585390679538\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012165666557848454\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017720767064020038\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000697194307576865\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001029997249133885\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000758020265493542\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006271355086937547\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006106371874921024\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007088678539730608\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014099180698394775\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008882295223884284\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012365112779662013\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007529398426413536\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009553220588713884\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010701382998377085\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007653410430066288\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030095181427896023\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001566388295032084\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007202633423730731\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007756500272080302\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009960178285837173\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006633216980844736\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007531434530392289\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010551131563261151\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001749719027429819\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000487316312501207\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37702300227829255\n",
      "\n",
      "[ Train epoch: 177 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006730209570378065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010117983911186457\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006183430086821318\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007247114554047585\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010108728893101215\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001045098528265953\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008202415774576366\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000924560590647161\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000650540110655129\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008411518065258861\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007609184249304235\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001060591428540647\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022229081951081753\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011018671793863177\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008109620539471507\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005841141100972891\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007419105968438089\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000791120866779238\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008289542165584862\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008074116776697338\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008514408837072551\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011254303390160203\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008153578964993358\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007109262514859438\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008138245902955532\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008232515538111329\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011971648782491684\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011653543915599585\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009465489420108497\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008593894308432937\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006146790110506117\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010947262635454535\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009829059708863497\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009089615195989609\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007958433125168085\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006022137822583318\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009564188658259809\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008047197479754686\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008889453019946814\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011160856811329722\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38218742643948644\n",
      "\n",
      "[ Train epoch: 178 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007485355599783361\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010477711912244558\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011104823788627982\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007596296491101384\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000697456591296941\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006466911872848868\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001465828507207334\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001229091896675527\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001062149996869266\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008842919487506151\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010588208679109812\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011296567972749472\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007594580529257655\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011938998941332102\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007003048085607588\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011129045160487294\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010041019413620234\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007654628716409206\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000890296942088753\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009957728907465935\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010250445920974016\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001541145029477775\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014182206941768527\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013332146918401122\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010465399827808142\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001111550023779273\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009108639205805957\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011986229801550508\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008229060913436115\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008804550161585212\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008130279602482915\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008345134556293488\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009069176740013063\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001331449020653963\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010162463877350092\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008393257157877088\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009322079713456333\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008061074768193066\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013890559785068035\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009861465077847242\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3927703130757436\n",
      "\n",
      "[ Train epoch: 179 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001110446872189641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010380033636465669\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009053771500475705\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009727884898893535\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013018737081438303\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010114931501448154\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005726643721573055\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010670090559870005\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008806977421045303\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011348648695275187\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00111802585888654\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001068750163540244\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013934930320829153\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008358359918929636\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012635099701583385\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009607076644897461\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010352501412853599\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007595759234391153\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013051875866949558\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009377627866342664\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001452071825042367\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006859643035568297\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007292579393833876\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011779118794947863\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007905003149062395\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008200756856240332\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000531705969478935\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009860225254669785\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011167330667376518\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012227731058374047\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008438008953817189\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009011682122945786\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007803250919096172\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008560257847420871\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007880288758315146\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006902408204041421\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011259129969403148\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007007078966125846\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006841610302217305\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021331256721168756\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37751943268813193\n",
      "\n",
      "[ Train epoch: 180 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010434318101033568\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013948985142633319\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011961772106587887\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010127078276127577\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005984664894640446\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006756247603334486\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011997316032648087\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014132763026282191\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008500349940732121\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011698126327246428\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012903081951662898\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008926931186579168\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008844024268910289\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009283199906349182\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008555855019949377\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009193291189149022\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015348352026194334\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008693949785083532\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010425628861412406\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006708128494210541\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008665006025694311\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011497704545035958\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007263710140250623\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008759174379520118\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011386944679543376\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007925594109110534\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011683456832543015\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014654058031737804\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006972332485020161\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000664240273181349\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007046328391879797\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010635898215696216\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00137932354118675\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010124017717316747\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006778591778129339\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012404953595250845\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007828605594113469\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011947270249947906\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010066981194540858\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009257273050025105\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3809903109795414\n",
      "\n",
      "[ Train epoch: 181 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009998066816478968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011706692166626453\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001386603806167841\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012916774721816182\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008320367778651416\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010879405308514833\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000736056943424046\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000909102731384337\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008427771390415728\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008063914719969034\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011872679460793734\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010839765891432762\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011381363729014993\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010546203702688217\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008334960439242423\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008939410327002406\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008945329464040697\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009806656744331121\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008252732804976404\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002082443330436945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010377209400758147\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010043408256024122\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012279730290174484\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011630709050223231\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000728047511074692\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008697835146449506\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012797201052308083\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010793627006933093\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016425198409706354\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010513814631849527\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014692686963826418\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009373591165058315\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010574444895610213\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008397304336540401\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008807979756966233\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001209096284583211\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009317636722698808\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008425643900409341\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010825209319591522\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007637617527507246\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38354384270496666\n",
      "\n",
      "[ Train epoch: 182 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009218135965056717\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009779148967936635\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008554774103686213\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008785405079834163\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010150669841095805\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008009274024516344\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006677349447272718\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009379999246448278\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014792353613302112\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008412108290940523\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008219417650252581\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009462060406804085\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017740182811394334\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012867844197899103\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013326857006177306\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001440557069145143\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001318491529673338\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013218674575909972\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008256988949142396\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009131587576121092\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007419062312692404\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009541711187921464\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008155449759215117\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009424185263924301\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001218490768224001\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009468870121054351\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008466378785669804\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009626456303521991\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013436214067041874\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008294058497995138\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007936675101518631\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009341842378489673\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009710707236081362\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008123959414660931\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008742542122490704\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006595743470825255\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012103092158213258\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011547231115400791\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008439000230282545\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010449154069647193\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3870156640186906\n",
      "\n",
      "[ Train epoch: 183 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000644270156044513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000893503543920815\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00116851890925318\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016310211503878236\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006947365473024547\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007213966455310583\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006124461651779711\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006669079884886742\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002426705788820982\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010420745238661766\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006897653802298009\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007323225145228207\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009209283743984997\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008089072653092444\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008003484690561891\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009112699772231281\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011146434117108583\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010262926807627082\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010376647114753723\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005992266815155745\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000700885895639658\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011269525857642293\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011747853131964803\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007672241772525012\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094497973099351\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009459980647079647\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010334665421396494\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007745304610580206\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010928948177024722\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010838587768375874\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010956766782328486\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013233950594440103\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010267370380461216\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009010522626340389\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008778792689554393\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010446516098454595\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010377512080594897\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007993094623088837\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007017429452389479\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008975408272817731\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37690481171011925\n",
      "\n",
      "[ Train epoch: 184 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001212635892443359\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012243185192346573\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010971130104735494\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007476899772882462\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012818115064874291\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014104009605944157\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009974853601306677\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007348507060669363\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009152654674835503\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015574375865980983\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005843415856361389\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011967255268245935\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007312076631933451\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010868929093703628\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012236584443598986\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009246940026059747\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008223001495935023\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009583210339769721\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009296669159084558\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094294129870832\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001707160146906972\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00118886714335531\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012194818118587136\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000679043703712523\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007900212076492608\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008594850660301745\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010368353687226772\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017656737472862005\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008970187627710402\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007535991026088595\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001033903332427144\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010932760778814554\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006618750630877912\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006601105560548604\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010138505604118109\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011384306708350778\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015342673286795616\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001123895519413054\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000737454742193222\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015809682663530111\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3814531625248492\n",
      "\n",
      "[ Train epoch: 185 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006508706137537956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008718171739019454\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001424411660991609\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007121388916857541\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008927035960368812\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010604658164083958\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008502097916789353\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005226911744102836\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008422821410931647\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007355937850661576\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008522327989339828\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013185815187171102\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008772686123847961\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008584798197261989\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011400164803490043\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009361929260194302\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007865096558816731\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012471176451072097\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007820588070899248\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009132196428254247\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010682797292247415\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009284168481826782\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013282105792313814\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014586886391043663\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008903334964998066\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010818308219313622\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001074149738997221\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009787394665181637\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007883539656177163\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001562523189932108\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011227725772187114\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009156744345091283\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007785652996972203\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002109258435666561\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008836032939143479\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010051373392343521\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001001256168819964\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016634796047583222\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001419788459315896\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010922385845333338\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3889056199695915\n",
      "\n",
      "[ Train epoch: 186 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001767773530445993\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010471970308572054\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000839973974507302\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006331661716103554\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016016061417758465\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007773939869366586\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006559495232068002\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009465005132369697\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008717951131984591\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001168524264357984\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010168610606342554\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009207534603774548\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000931556336581707\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008398492936976254\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012213352601975203\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010493907611817122\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008744799415580928\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006290153251029551\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001313143176957965\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001082895090803504\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00124612997751683\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010631760815158486\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006318428204394877\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010144570842385292\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007577092619612813\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006819965201430023\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008688863599672914\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001269084052182734\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014854696346446872\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007811475079506636\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009008584311231971\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001007847604341805\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008242946933023632\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008898346568457782\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00119606067892164\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008518770337104797\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007914422894828022\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008211755775846541\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008862680406309664\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00081335857976228\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3856238158768974\n",
      "\n",
      "[ Train epoch: 187 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011537250829860568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000805275107268244\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007341045420616865\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001116118859499693\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016053086146712303\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001169260940514505\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006850458448752761\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011913953348994255\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009177299216389656\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010032904101535678\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010200318647548556\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007625885773450136\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009823112050071359\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007611460750922561\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008183146710507572\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008273375569842756\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000852139899507165\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000994086149148643\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008923293207772076\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006948795635253191\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008372548618353903\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010020711924880743\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005931963096372783\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012379434192553163\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008028565789572895\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009410471539013088\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000923704996239394\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008625203627161682\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010880200425162911\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007407883531413972\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007110171718522906\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010420908220112324\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007320719305425882\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008151907240971923\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008032022742554545\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010103500680997968\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006709906156174839\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008452223846688867\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012620135676115751\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008419983787462115\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3702397554880008\n",
      "\n",
      "[ Train epoch: 188 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000631902483291924\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008877591462805867\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009257769561372697\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006862890440970659\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007194406352937222\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007972517050802708\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012751796748489141\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010023629292845726\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007952224696055055\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009508176590315998\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010418783640488982\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008781972574070096\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010354110272601247\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009593250579200685\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010103125823661685\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001100911176763475\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009058000869117677\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000892292766366154\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008482031989842653\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000640553655102849\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001173138152807951\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011905716964975\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008324025548063219\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016716113314032555\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009986211080104113\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005633821128867567\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009967568330466747\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010452177375555038\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009710032027214766\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008040966931730509\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009558540186844766\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008136066608130932\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009126143995672464\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009210754069499671\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013106092810630798\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009009554050862789\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008613336831331253\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006844456074759364\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007570019806735218\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0052397968247532845\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38725152547704056\n",
      "\n",
      "[ Train epoch: 189 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001123567926697433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007073906599543989\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010467597749084234\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009781363187357783\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009231602307409048\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017346973763778806\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009712175233289599\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008852972532622516\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000872548611368984\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001441833097487688\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018197230529040098\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001247528474777937\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015182652277871966\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009675347246229649\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001040617236867547\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006810860941186547\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006883303285576403\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011923626298084855\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014341195346787572\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010192438494414091\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014448389410972595\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017695014830678701\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010146168060600758\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006101481267251074\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008687949739396572\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013721785508096218\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000962490332312882\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007702214643359184\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007182686822488904\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009085668134503067\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001492304727435112\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009183737565763295\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014233759138733149\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010611509205773473\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009428655030205846\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011382109951227903\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005515298107638955\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006269275909289718\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010452561546117067\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011453169863671064\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38830147578846663\n",
      "\n",
      "[ Train epoch: 190 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011842556996271014\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012270375154912472\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009541474282741547\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007680383860133588\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006985096842981875\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006872571539133787\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014126318274065852\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000848958792630583\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008809267892502248\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007176271756179631\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013495536986738443\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007758890860714018\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000675575400236994\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010210576001554728\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008886292926035821\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006909280782565475\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007012841524556279\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015332865295931697\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009648085688240826\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007212635246105492\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008767248946242034\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012919299770146608\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010009593097493052\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001469690934754908\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008361341897398233\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007663524011150002\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010107995476573706\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008266133372671902\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008678196463733912\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010395284043624997\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011928348103538156\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001251467620022595\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001323381788097322\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007462655776180327\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008158715208992362\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016781121958047152\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010118994396179914\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011604924220591784\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014803041703999043\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007818228332325816\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3818992049782537\n",
      "\n",
      "[ Train epoch: 191 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009234827011823654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005849961307831109\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006762327393516898\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000864935340359807\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007626977749168873\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007001390913501382\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010149118024855852\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014075167709961534\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009510755771771073\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011701174080371857\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008025104179978371\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007524759275838733\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005662087933160365\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001433692523278296\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009463552851229906\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009241099469363689\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010033344151452184\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009616777533665299\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010637114755809307\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011008868459612131\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007618267554789782\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009012521477416158\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008029242744669318\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009210911812260747\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007584468694403768\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009092873660847545\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008584922179579735\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009957606671378016\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011467423755675554\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009140880429185927\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011021830141544342\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006410969654098153\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010496991453692317\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008414597250521183\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010396295692771673\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016015239525586367\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007170297321863472\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001221754471771419\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000841127650346607\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008609105716459453\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37583241501124576\n",
      "\n",
      "[ Train epoch: 192 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008467963198199868\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008454297203570604\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009590494446456432\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006741506513208151\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012731199385598302\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006831336650066078\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008358354680240154\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013713798252865672\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016978458734229207\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006310424651019275\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009480100707150996\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008505746372975409\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015304526314139366\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014200251316651702\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001539728487841785\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008685463690198958\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008022636757232249\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014711483381688595\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00078239431604743\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009476547129452229\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012767729349434376\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006131797563284636\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009280950762331486\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011405190452933311\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008716020383872092\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018288514111191034\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007904939702711999\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008289582910947502\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027859616093337536\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008703069179318845\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010437899036332965\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007749237702228129\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008741763303987682\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00141037255525589\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010091899894177914\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007499629864469171\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013219777029007673\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010199673706665635\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009712206665426493\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012057279236614704\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38252603414002806\n",
      "\n",
      "[ Train epoch: 193 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008883115369826555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013818277511745691\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009428835473954678\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014288839884102345\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007297074189409614\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009080867166630924\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006763232522644103\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010344249894842505\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012274645268917084\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016516197938472033\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007411197293549776\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008305070223286748\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094078877940774\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008357829065062106\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007731004152446985\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001234068418852985\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009044912294484675\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011415129993110895\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000944330939091742\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001751789590343833\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014261482283473015\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000772511528339237\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008358696359209716\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011005861451849341\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012046659830957651\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000745263765566051\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007918789051473141\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006471513188444078\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008763057994656265\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009620278142392635\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007287529879249632\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001105939969420433\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007740352302789688\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014351106947287917\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006890559452585876\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000991094158962369\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010074649471789598\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008145319879986346\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006361251580528915\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011235557030886412\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38470289757242426\n",
      "\n",
      "[ Train epoch: 194 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013309047790244222\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006467299535870552\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008560008136555552\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009119868045672774\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007314153481274843\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006160411867313087\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014895536005496979\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007860730402171612\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012075923150405288\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007989346049726009\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008750343695282936\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009446373442187905\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008035628125071526\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014482905389741063\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013501847861334682\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009701575618237257\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001081797992810607\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008336890605278313\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008777572074905038\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009805307490751147\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006636334001086652\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009797833627089858\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007628324092365801\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000755051732994616\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010690914932638407\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008157354895956814\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015303855761885643\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009251242154277861\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006596476887352765\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009955797577276826\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008437291835434735\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009407147881574929\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001606786623597145\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011597205884754658\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009965095669031143\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008200203301385045\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000671712274197489\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007131233578547835\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001025155303068459\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011002188548445702\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3830549734411761\n",
      "\n",
      "[ Train epoch: 195 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011722780764102936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009316573850810528\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007912438595667481\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007268273620866239\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012131166877225041\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012495709815993905\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008315135492011905\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019149231957271695\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008980815182439983\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007685763412155211\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007183711277320981\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008724461658857763\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001104829483665526\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007313357200473547\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010683562140911818\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006116002914495766\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008600656874477863\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010908696567639709\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007157288491725922\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009217237820848823\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011125176679342985\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012930466327816248\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008314255974255502\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011903943959623575\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012049897341057658\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00109009793959558\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008167366031557322\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009707809658721089\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008568797493353486\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012713317992165685\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002003492321819067\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000945800740737468\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001077320659533143\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006567441741935909\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008781205979175866\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009055276168510318\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008719145553186536\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009794801007956266\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009302172693423927\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002179989591240883\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38492636586306617\n",
      "\n",
      "[ Train epoch: 196 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007768793730065227\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008359572966583073\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007903515943326056\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00098310480825603\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007413704879581928\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008367534028366208\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008767173276282847\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014169559581205249\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007055956521071494\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009117164881899953\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009055089321918786\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001025373232550919\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007473654695786536\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006693986360915005\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013405266217887402\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006205423269420862\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010123805841431022\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008386225090362132\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014187111519277096\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010016022715717554\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007084966637194157\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007656854577362537\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006280618254095316\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001098911976441741\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008201971650123596\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006276443018577993\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001136133330874145\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009744107373990119\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010672693606466055\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007152697071433067\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015631279675289989\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001153521123342216\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011835546465590596\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000978729804046452\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009858988923951983\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014558796538040042\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008602487505413592\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010720820864662528\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009011515066958964\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007696625543758273\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.36900846275966614\n",
      "\n",
      "[ Train epoch: 197 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013592462055385113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010542008094489574\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008298866450786591\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001255555311217904\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009447070769965649\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009340575779788196\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008674468263052404\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008526469464413822\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010268923360854387\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008962384890764952\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009203515946865082\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011689632665365934\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013946008402854204\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010993385221809149\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000876610167324543\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013203840935602784\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012395090889185667\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008534471271559596\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008864561095833778\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009144545765593648\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001068752957507968\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008343322551809251\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009261235827580094\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019154755864292383\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008821920491755009\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007454879814758897\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008730391855351627\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007740810397081077\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009189971606247127\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008325162343680859\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008981494465842843\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008790017454884946\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009430342470295727\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001110923825763166\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008512904751114547\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010159770026803017\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008090944029390812\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007970096776261926\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011745963711291552\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008419732330366969\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37827412015758455\n",
      "\n",
      "[ Train epoch: 198 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013071289286017418\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008914534701034427\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006850530044175684\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011828503338620067\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010890091070905328\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006722186226397753\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000858509389217943\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008885895949788392\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007986377459019423\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012434151722118258\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012768913293257356\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007271061767823994\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009349780739285052\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008005968411453068\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010918774642050266\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008753790752962232\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009255623444914818\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010230524931102991\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000979117234237492\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008324450463987887\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007695420645177364\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008775694295763969\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008795454050414264\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001195412827655673\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011456304928287864\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007428639219142497\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007799193845130503\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007658074609935284\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001315403962507844\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007510560099035501\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00113390339538455\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008989536436274648\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008229982340708375\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012624431401491165\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000753811385948211\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011499363463371992\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008874291670508683\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000989251770079136\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008131418726406991\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001695652725175023\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3812436696025543\n",
      "\n",
      "[ Train epoch: 199 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014483279082924128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010468843393027782\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011158892884850502\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011641366872936487\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011495387880131602\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000904326094314456\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009494165424257517\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011899981182068586\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006461413577198982\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021044714376330376\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011676361318677664\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001055295579135418\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011750556295737624\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006966411019675434\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009768783347681165\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001201412989757955\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018228586995974183\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008581251022405922\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007848776294849813\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000723785487934947\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009259067010134459\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020085033029317856\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010267437901347876\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000932522932998836\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011661872267723083\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010258711408823729\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009799543768167496\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015902790473774076\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011018066434189677\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008189736399799585\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012250959407538176\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000669304165057838\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010272760409861803\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008198556024581194\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007407108787447214\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009257213096134365\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006426367908716202\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007760831504128873\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000893804884981364\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007562711252830923\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.380853769776877\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 200):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    #test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2072661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Test epoch: 199 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7186563014984131\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 3.79893159866333\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 1.0755268335342407\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 3.8852109909057617\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9439548254013062\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 4.361649513244629\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6866134405136108\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 3.604046106338501\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.49680861830711365\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 3.544793128967285\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.6276976466178894\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 3.566344976425171\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.901292622089386\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 4.187230110168457\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.735951840877533\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 3.935539960861206\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.5564322471618652\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 3.601238489151001\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6089067459106445\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 3.6751785278320312\n",
      "\n",
      "Total benign test accuarcy: 77.74\n",
      "Total adversarial test Accuarcy: 34.66\n",
      "Total benign test loss: 84.3372463285923\n",
      "Total adversarial test loss: 391.7827262878418\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fda870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 200 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008726849919185042\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011476755607873201\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008728919201530516\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008452764013782144\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008205946651287377\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006833854131400585\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008279865724034607\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009972886182367802\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013399501331150532\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009013168164528906\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008664547931402922\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007930532447062433\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000766829471103847\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008390277507714927\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010216882219538093\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001181404571980238\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011138336267322302\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000965972663834691\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001143731758929789\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009373203502036631\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008796112961135805\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008593284874223173\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009239945793524384\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000696258619427681\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006598914624191821\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008369936840608716\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000819725391920656\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011753173312172294\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008437801734544337\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007843868224881589\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006555200088769197\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008649559458717704\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008032404002733529\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006756389630027115\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000843506888486445\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008548754267394543\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007675807573832572\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000964044127613306\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000756436085794121\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001077180728316307\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.36925722868181765\n",
      "\n",
      "[ Train epoch: 201 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006834217347204685\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008669801172800362\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002007189439609647\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007566530257463455\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001045695855282247\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010081230429932475\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007412264822050929\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011994022643193603\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011575251119211316\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008409360307268798\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001120384898968041\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007538856007158756\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007382710464298725\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001089367433451116\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009892454836517572\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001360216992907226\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000928615452721715\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001159460050985217\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011657560244202614\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006790072657167912\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001459176535718143\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015117571456357837\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006680565420538187\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008334810263477266\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008553843363188207\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000797484302893281\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012329260352998972\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007380053284578025\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010155073832720518\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008587907068431377\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008034351048991084\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008162213489413261\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010437547462061048\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011023819679394364\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007354365661740303\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009585533407516778\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006586782401427627\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009611936402507126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008837330969981849\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010760993463918567\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37962731398874894\n",
      "\n",
      "[ Train epoch: 202 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007047982071526349\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006337295635603368\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006715378258377314\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007772587705403566\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008966124150902033\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008894114871509373\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009236379992216825\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009879088029265404\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010801040334627032\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001215609721839428\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007246133172884583\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001805122708901763\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008279292960651219\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009192958241328597\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000984541024081409\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008211630629375577\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007975978660397232\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008246432989835739\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012497373390942812\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008345430251210928\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013223628047853708\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009746594587340951\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008557711844332516\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010121188824996352\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007781932945363224\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009442503214813769\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009679759969003499\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000657382479403168\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007771693635731936\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010765076149255037\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010511758737266064\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010717010591179132\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015167377423495054\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007089976570568979\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007448118412867188\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012343813432380557\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010253899963572621\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009075429406948388\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006835946696810424\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014658832224085927\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3757977770874277\n",
      "\n",
      "[ Train epoch: 203 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006920548039488494\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001010580570437014\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001093554776161909\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010274170199409127\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009245703113265336\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011493767378851771\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009627147810533643\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010195971699431539\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001396339270286262\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007320674485526979\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011543212458491325\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008205086342059076\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009834269294515252\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007750227814540267\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007191280601546168\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001037686481140554\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000969921937212348\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000819663458969444\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001354286796413362\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008632539538666606\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010788023937493563\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011482336558401585\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008202424505725503\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009516042191535234\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011268964735791087\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009669804712757468\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006711832247674465\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008403713000006974\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012955015990883112\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012032607337459922\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008461206452921033\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000989734660834074\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009232911397702992\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011047970037907362\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009701047674752772\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007003966020420194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012861621798947453\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007976031629368663\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007432460552081466\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008095150697045028\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3741050589014776\n",
      "\n",
      "[ Train epoch: 204 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009069652878679335\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001160734798759222\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010223411954939365\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000842770969029516\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008128603221848607\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009667453705333173\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010198102099820971\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010448425309732556\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008544144220650196\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001045901095494628\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010600718669593334\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015115432906895876\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005554307717829943\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007237233803607523\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018742566462606192\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011016405187547207\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009550058166496456\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008749558473937213\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008751078275963664\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012143721105530858\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008237824076786637\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011164029128849506\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009307622676715255\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008050712640397251\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009506630594842136\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007473747245967388\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008264036732725799\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008947063470259309\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008422919199801981\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000693871988914907\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001373235834762454\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009015544783324003\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006393796647898853\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008507828461006284\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001167421811260283\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008171529043465853\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001073802006430924\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009359489777125418\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010616460349410772\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006388083565980196\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3809268204495311\n",
      "\n",
      "[ Train epoch: 205 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010471896966919303\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00116345239803195\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008618362480774522\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006661448860540986\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007489735726267099\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007993842591531575\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008328246767632663\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012065102346241474\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000978158670477569\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012806643499061465\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009456833940930665\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007963463431224227\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009551774710416794\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000722248456440866\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008405124535784125\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007168589509092271\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007478662300854921\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007985086413100362\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008818817441351712\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009706031414680183\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008045866270549595\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006685626576654613\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001218602410517633\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000982835190370679\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007452174322679639\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007976798224262893\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005991546204313636\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007773774559609592\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001006297767162323\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009383068536408246\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006530257523991168\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008959321421571076\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006936665740795434\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005966786993667483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007496271282434464\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010346267372369766\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007696680258959532\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00124267372302711\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014649438671767712\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036189532838761806\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37311598082305863\n",
      "\n",
      "[ Train epoch: 206 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009080374147742987\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007730508805252612\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008465842693112791\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005928913597017527\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008814505417831242\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013155800988897681\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014465347630903125\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008877742802724242\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009232491138391197\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010758987627923489\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010823728516697884\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006132786511443555\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001060017733834684\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025389150250703096\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009388633770868182\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008411065209656954\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010651908814907074\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007036186871118844\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010505252284929156\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009046206250786781\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013376197312027216\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008483873680233955\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007665867451578379\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007434586877934635\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010467410320416093\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001365878153592348\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013085756218060851\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000837168307043612\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010378975421190262\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010663813445717096\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008439923403784633\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008165200124494731\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00100632943212986\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006595419836230576\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008851616876199841\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011283919448032975\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010809592204168439\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014920416288077831\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009445056202821434\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000841860193759203\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3843946557608433\n",
      "\n",
      "[ Train epoch: 207 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010992997558787465\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010580905945971608\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007298851269297302\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014322082279250026\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007545597036369145\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010249505285173655\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006901905289851129\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008838891517370939\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006675610784441233\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006327084265649319\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006971103721298277\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007366116042248905\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008255230495706201\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007359697483479977\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008082480053417385\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008227150538004935\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007912353030405939\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007073020678944886\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010852239793166518\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000869372277520597\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001382352551445365\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007992048631422222\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007370142848230898\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009264074615202844\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009692170424386859\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007790692034177482\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008451255271211267\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001037013833411038\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011297353776171803\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014040697133168578\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007893910515122116\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010406210785731673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008964731241576374\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010407078079879284\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000621309329289943\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009692201856523752\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007138709770515561\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001087578129954636\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008312542922794819\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008242543553933501\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37711553723784164\n",
      "\n",
      "[ Train epoch: 208 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000626171356998384\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008899928070604801\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009262724779546261\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015771571779623628\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000662384380120784\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011798356426879764\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010872253915295005\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001101320143789053\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009823637083172798\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007355190464295447\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001626942539587617\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000749412109144032\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008149613277055323\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000807743170298636\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008422539685852826\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007000677287578583\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000726357102394104\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008194646798074245\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007307162159122527\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009461709996685386\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000803477771114558\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007813891279511154\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013251168420538306\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001065718592144549\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009908289648592472\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001131600234657526\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001169046270661056\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008325864910148084\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000886932946741581\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007235191878862679\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012910746736451983\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001304870005697012\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000693442823830992\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008368971757590771\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008893365738913417\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008518382092006505\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006257898639887571\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009627751423977315\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001711866119876504\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016023239586502314\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38078824745025486\n",
      "\n",
      "[ Train epoch: 209 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009595153387635946\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010871056001633406\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012539264280349016\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006919241277500987\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001203392632305622\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009016453404910862\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012812057975679636\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007217812235467136\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010367921786382794\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000781400827690959\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010506890248507261\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000866801361553371\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009016137337312102\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006285619456321001\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007435138104483485\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006861925940029323\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006709969020448625\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007356083951890469\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005860118544660509\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008151105721481144\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007089724531397223\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012204700615257025\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007424316136166453\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011497524101287127\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008542832802049816\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008020176319405437\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015746786957606673\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006383362924680114\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008034078637138009\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007358618313446641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005940329283475876\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010164172854274511\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007879552431404591\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008894035127013922\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009020850411616266\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008178093121387064\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001393824932165444\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010839826427400112\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001467990456148982\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024860540870577097\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.36241326114395633\n",
      "\n",
      "[ Train epoch: 210 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016342325834557414\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007897118339315057\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006791000487282872\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007830430986359715\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012363255955278873\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006889913929626346\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011071136686950922\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008860251400619745\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022773274686187506\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001409616437740624\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00046005338663235307\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001069620018824935\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005588287604041398\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006797692622058094\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010646458249539137\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006756348302587867\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000650068512186408\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011312391143292189\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008284352370537817\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009096342837437987\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008952784119173884\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000719756877515465\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007387205259874463\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008138907724060118\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008761389763094485\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001072410959750414\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009017480770125985\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008076737285591662\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000913081516046077\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019042225321754813\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011650396045297384\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006974050775170326\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001004476798698306\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007339285220950842\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009856147225946188\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008727535023353994\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006337731028907001\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011073484783992171\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009914039401337504\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011226802598685026\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3818204377312213\n",
      "\n",
      "[ Train epoch: 211 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000694539281539619\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009825057350099087\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006802691495977342\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008215485140681267\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012807429302483797\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007741998415440321\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009114663116633892\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008889582823030651\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007235833327285945\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006497099529951811\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014481920516118407\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011503930436447263\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009183514048345387\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006760759279131889\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007263218285515904\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008401856757700443\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009397267713211477\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007322717574425042\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008477377705276012\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008630393422208726\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008413910982199013\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000886817928403616\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015839211409911513\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000903323118109256\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001990547636523843\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008985207532532513\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007558765937574208\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008495414513163269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001134387799538672\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009211773867718875\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009229028364643455\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010378658771514893\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016298668924719095\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008889120072126389\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012327756267040968\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016997831407934427\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008765548118390143\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008650796371512115\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011407132260501385\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009700442897155881\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38033615407766774\n",
      "\n",
      "[ Train epoch: 212 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009542936459183693\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011126484023407102\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009918131399899721\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011575776152312756\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006206199177540839\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005890098982490599\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010897759348154068\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013618358643725514\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009691605810075998\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008840212831273675\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006505220080725849\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007070982246659696\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006556342705152929\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009631599532440305\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006839742418378592\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009931439999490976\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009225719841197133\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008332395227625966\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009045282495208085\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000780370261054486\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008553575607948005\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000815180130302906\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007175858481787145\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007630217005498707\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001031549763865769\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007109899306669831\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009013458038680255\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013367016799747944\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008946540765464306\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010108432034030557\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005659100133925676\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000706304213963449\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010734412353485823\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011133395601063967\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001044998993165791\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007790320087224245\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011735555017367005\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000960558361839503\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009594181319698691\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010136319324374199\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.373892015311867\n",
      "\n",
      "[ Train epoch: 213 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001027022022753954\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020218612626194954\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006282153772190213\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008682549232617021\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007335605914704502\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006688100402243435\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008038967498578131\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008444455452263355\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010225019650533795\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007163274567574263\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009806009475141764\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010049451375380158\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008340671192854643\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009037454146891832\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008646291098557413\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009172932477667928\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001121901092119515\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001275309594348073\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009166722884401679\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008086434681899846\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009506694041192532\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007914940360933542\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008194887195713818\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009633955196477473\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011011920869350433\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010448646498844028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011797385523095727\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001045200158841908\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009760110988281667\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008381895022466779\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008993241935968399\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010874264407902956\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007509379065595567\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016218415694311261\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007234975346364081\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009204104426316917\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001176116056740284\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009005919564515352\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009253026801161468\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000958923832513392\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37493155075935647\n",
      "\n",
      "[ Train epoch: 214 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016202179249376059\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006983642233535647\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009518071310594678\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000633921183180064\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010912440484389663\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009927550563588738\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000956880918238312\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001102756941691041\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014372783480212092\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009365843725390732\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008240960305556655\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008750013657845557\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007213730714283884\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001373474719002843\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010225813603028655\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009577117743901908\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008448638254776597\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008292931015603244\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010488484986126423\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012352894991636276\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007730352226644754\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007550274604000151\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008174789836630225\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000876889971550554\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011048226151615381\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009172646095976233\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002161637647077441\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010326046030968428\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007639183313585818\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011985526653006673\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006910153315402567\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008703822968527675\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008788295090198517\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010257938411086798\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006560462061315775\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007111986051313579\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008685381035320461\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009699540678411722\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008138178382068872\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001304660108871758\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3827023541671224\n",
      "\n",
      "[ Train epoch: 215 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007420424371957779\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008771553984843194\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022692678030580282\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009708736906759441\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010390703100711107\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008586478070355952\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012387590250000358\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008200522279366851\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008127386681735516\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011243053013458848\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010686394525691867\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010141314705833793\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008242956828325987\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010439822217449546\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011574862292036414\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009519995655864477\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000765775388572365\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012168970424681902\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011880387319251895\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010353724937886\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008214935660362244\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007451999699696898\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008629313670098782\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010952807497233152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011118281399831176\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006367177702486515\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009472634992562234\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009042379097081721\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007227918831631541\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000687086780089885\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007245070300996304\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008421906386502087\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001345721771940589\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013251991476863623\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008680348400957882\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012770721223205328\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007242248975671828\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009137277374975383\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011212402023375034\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011020757956430316\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3797188755706884\n",
      "\n",
      "[ Train epoch: 216 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007403953932225704\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000924662163015455\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006093289121054113\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008416944765485823\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008143119630403817\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012042487505823374\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006235854234546423\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008437603828497231\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008498121169395745\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009035558323375881\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001116555999033153\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007467175018973649\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001289595034904778\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011229133233428001\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012055813567712903\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007207292946986854\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005132977967150509\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006249893340282142\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013189869932830334\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000815106148365885\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012176160234957933\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012425023596733809\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007232604548335075\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009104729979299009\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009855448734015226\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006718539516441524\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001127038151025772\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009588708635419607\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006577963358722627\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009693930041976273\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007303692982532084\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001040422823280096\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008322166977450252\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007575302151963115\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008831373997963965\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011608905624598265\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001447330811060965\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007783983601257205\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009166855015791953\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001123646623454988\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3702924145036377\n",
      "\n",
      "[ Train epoch: 217 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010567980352789164\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008939921972341835\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005643655895255506\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00080929568503052\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006684493273496628\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009231072617694736\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007536232587881386\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008398616919294\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001902117975987494\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000833605881780386\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007278541452251375\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008185741025954485\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008755691815167665\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008643293986096978\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011870904127135873\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009292973554693162\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001024972298182547\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007045582169666886\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000600100145675242\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009663006057962775\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009317522635683417\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014163947198539972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009750794852152467\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007444732473231852\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011479113018140197\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008476937655359507\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008640617597848177\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007200416293926537\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007229892071336508\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007497004698961973\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000708453357219696\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000710102787707001\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000838924665004015\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000952334376052022\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001120954635553062\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001211401540786028\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001289954874664545\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006784036522731185\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008122189901769161\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010334029793739319\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3681931358878501\n",
      "\n",
      "[ Train epoch: 218 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010768467327579856\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000970418332144618\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007953760214149952\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008379875798709691\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000901574909221381\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009201406501233578\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001351485145278275\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006819083355367184\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008543157018721104\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008444080594927073\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007381852483376861\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001169526600278914\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008869051816873252\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008955278899520636\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007832155679352582\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010813107946887612\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009683617390692234\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010174489580094814\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007834007847122848\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009539158781990409\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012076456332579255\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00156144960783422\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009187149116769433\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008134074741974473\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009861375438049436\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008989608031697571\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010244870791211724\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011515987571328878\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008945771842263639\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010149598820134997\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009980776812881231\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010584756964817643\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007344133919104934\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003085533855482936\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013699071714654565\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013883330393582582\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008450283203274012\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008441359386779368\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007185674621723592\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010511537548154593\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.378037852991838\n",
      "\n",
      "[ Train epoch: 219 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006423295708373189\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013942602090537548\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006837862310931087\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020509897731244564\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009492195094935596\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001050436869263649\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009355272050015628\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008417266653850675\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009873410454019904\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008318297332152724\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001145059010013938\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006533450214192271\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008522435091435909\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012374373618513346\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011714439606294036\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011147877667099237\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000619303435087204\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008516506059095263\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009134779684245586\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009491436649113894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00086068210657686\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010428049135953188\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010421340120956302\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009283760446123779\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000834161473903805\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011965403100475669\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011640775483101606\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001234832569025457\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009909941582009196\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008026143768802285\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009719837107695639\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012615869054570794\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000962314021307975\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009418684057891369\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000962454651016742\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007566052372567356\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012791320914402604\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013730254722759128\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012992664705961943\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008589060162194073\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3855958999483846\n",
      "\n",
      "[ Train epoch: 220 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012771969195455313\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008890840690582991\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006730321329087019\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00127368641551584\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007594175403937697\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010158524382859468\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006156978779472411\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007562859100289643\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008358522900380194\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010553499450907111\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016188116278499365\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010558994254097342\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008118682308122516\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007712208316661417\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009019249700941145\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011342598590999842\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007201028638519347\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006845888565294445\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008959447150118649\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009877458214759827\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013584016123786569\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009885814506560564\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008153149974532425\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015922749880701303\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007829704554751515\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007134017068892717\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005546762840822339\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000868909468408674\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009243342210538685\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015438260743394494\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013148451689630747\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007231790223158896\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010686647146940231\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012908276403322816\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015136393485590816\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012119632447138429\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005728644318878651\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007123450632207096\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002014403697103262\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001591845997609198\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37874791881768033\n",
      "\n",
      "[ Train epoch: 221 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009201533976010978\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008607792551629245\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001192640047520399\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008658576407469809\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009235406760126352\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009714991319924593\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009188333060592413\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010670660994946957\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013478384353220463\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007875682204030454\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008292261627502739\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006046743365004659\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010543061653152108\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009367071324959397\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008651238749735057\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009912309469655156\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007650438346900046\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009074375848285854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010301985312253237\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013313386589288712\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014431776944547892\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008046617149375379\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008519955445080996\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008904035785235465\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094051986001432\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008700782782398164\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011912040645256639\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010828344384208322\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011326457606628537\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010627290466800332\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007435076404362917\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008170533692464232\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007529054419137537\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008053016499616206\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006104905041866004\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001518820645287633\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001289648120291531\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012229784624651074\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009178218897432089\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011444422416388988\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3754897622275166\n",
      "\n",
      "[ Train epoch: 222 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015802509151399136\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007880168268457055\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006155699957162142\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006563373026438057\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008783396333456039\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008242552285082638\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007464096415787935\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006859055138193071\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007364470511674881\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008093979558907449\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006653969176113605\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010445525404065847\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008974639931693673\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000874884077347815\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010624544229358435\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009659503120929003\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008429773733951151\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007833566633053124\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008181309676729143\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007109896978363395\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007584529230371118\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008136059623211622\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007751910015940666\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007650541374459863\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001048967824317515\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006341200205497444\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007443010690622032\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006545872311107814\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013171336613595486\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009809331968426704\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007887711399234831\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009473440004512668\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001408079988323152\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007359154988080263\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012619461631402373\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005706565571017563\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012460523284971714\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001059803063981235\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009242102387361228\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009493568213656545\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3692082205088809\n",
      "\n",
      "[ Train epoch: 223 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006210481515154243\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000860096886754036\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010104189859703183\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007453278522007167\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007131122401915491\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009134277934208512\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010295695392414927\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008144031744450331\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009144173236563802\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008261090260930359\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008664933848194778\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008991204085759819\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008643473265692592\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001060035196132958\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007142350659705698\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014842951204627752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010971807641908526\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001017328817397356\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008151213405653834\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010600925888866186\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019581206142902374\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011031720787286758\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006150755798444152\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007629045867361128\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010037121828645468\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005987949552945793\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012992420233786106\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008415113552473485\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008879632805474102\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007457855390384793\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007720854482613504\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000724014185834676\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009123182971961796\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006981782498769462\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010899050394073129\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006679160287603736\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000951370457187295\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001437393599189818\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000701403827406466\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006769031169824302\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3802580841584131\n",
      "\n",
      "[ Train epoch: 224 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008557020919397473\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009452603990212083\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001102528185583651\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007255635573528707\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011960698757320642\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000822548579890281\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007412456907331944\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001262009609490633\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010705646127462387\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006021729786880314\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001014547306112945\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008058687089942396\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007610509055666625\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008699008612893522\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001647209981456399\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009445562027394772\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009280236554332078\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015052163507789373\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000817224383354187\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010177287040278316\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009693896863609552\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012372948694974184\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007588827284052968\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009739234810695052\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006953084957785904\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012064388720318675\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009672573069110513\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010554578620940447\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011897009098902345\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008271305705420673\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007341805612668395\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010345878545194864\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010660492116585374\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007754375692456961\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007279218407347798\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006643926026299596\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012154353316873312\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008033306221477687\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010823868215084076\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013231250923126936\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37871088652173057\n",
      "\n",
      "[ Train epoch: 225 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009901096345856786\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010331080993637443\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010185742285102606\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012167455861344934\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010892199352383614\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001005158992484212\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013124817050993443\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007825650973245502\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011850374285131693\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011674826964735985\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009548499947413802\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000882457010447979\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009228924755007029\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009473590762354434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00105736602563411\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008355064783245325\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008051645127125084\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013148717116564512\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006599390762858093\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008389902650378644\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008044970454648137\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006552370032295585\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010092841694131494\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011749526020139456\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009088251972571015\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000981415854766965\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011044704588130116\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000971631146967411\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001121857319958508\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012310207821428776\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009209357085637748\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006585526280105114\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009605843806639314\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005896810907870531\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001103803631849587\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008911692420952022\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008462969562970102\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012545718345791101\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007575806812383235\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006769233732484281\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38200421479996294\n",
      "\n",
      "[ Train epoch: 226 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008056472870521247\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006594909937120974\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001119315391406417\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000943302467931062\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008232192485593259\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00089683459373191\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006790214101783931\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005909701576456428\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012157510500401258\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006656479672528803\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012373876525089145\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010433890856802464\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008023658883757889\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011633659014478326\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010443845530971885\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010002286871895194\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007293346570804715\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008460769313387573\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008692959672771394\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007858207100071013\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008296712767332792\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001076765009202063\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001067973324097693\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018404030706733465\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011323823127895594\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000819288135971874\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007530354196205735\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010348003124818206\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000937892880756408\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011741871712729335\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010103220120072365\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008158556302078068\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006393291987478733\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001316275098361075\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001338742789812386\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008066680748015642\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014367561088874936\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007525166729465127\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001207218854688108\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011486220173537731\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37896476505557075\n",
      "\n",
      "[ Train epoch: 227 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007484916131943464\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009906511986628175\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006794817745685577\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009233791497536004\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010912218131124973\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012717141071334481\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014896433567628264\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009125625947490335\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000670111330691725\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013448725221678615\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017613096861168742\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007440928020514548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000956743024289608\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006968380184844136\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008331309072673321\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010575150372460485\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008785270038060844\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007609662134200335\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014029539888724685\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008120405836962163\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008483905112370849\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008383193053305149\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007540039950981736\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000861902954056859\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011483562411740422\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010065409587696195\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009250309085473418\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011897978838533163\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007886996027082205\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007958573405630887\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006083205807954073\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007683956064283848\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011615868424996734\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000932804134208709\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009477235726080835\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00153815234079957\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008350829593837261\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011250958777964115\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007839160389266908\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000539835193194449\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3729124850942753\n",
      "\n",
      "[ Train epoch: 228 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008893772610463202\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011787007097154856\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008235436398535967\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007849066751077771\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000796077772974968\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000887982256244868\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007774229161441326\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007311456138268113\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007362915202975273\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008098003454506397\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006531268008984625\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011025392450392246\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008951343479566276\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001765181077644229\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001659276895225048\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000855111749842763\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009327325387857854\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008659909944981337\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008802887750789523\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001556424773298204\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008007014985196292\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00062852498376742\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001536943600513041\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011638645082712173\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006845268071629107\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008233615662902594\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008140528807416558\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008114617667160928\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016207074513658881\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007409563404507935\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007878754986450076\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012231122236698866\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008414367330260575\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007146238931454718\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001004703575745225\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012699536746367812\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008614501566626132\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009526643552817404\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008096607052721083\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001800687052309513\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3811759378295392\n",
      "\n",
      "[ Train epoch: 229 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009757106308825314\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010099695064127445\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007396478904411197\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013574615586549044\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011651116656139493\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010262085124850273\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011794213205575943\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007800675230100751\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017239040462300181\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009729319135658443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010404250351712108\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007333928951993585\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002952555427327752\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017102399142459035\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008771767024882138\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008934838115237653\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010566108394414186\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000947632419411093\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015134861459955573\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010251447092741728\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014088330790400505\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007823688210919499\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007463103975169361\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009868601337075233\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009694125037640333\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001065122545696795\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007820093305781484\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009646288235671818\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012001276481896639\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001035531866364181\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000738103874027729\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010361351305618882\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008909222087822855\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008647628710605204\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009849196067079902\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009507337235845625\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009228115086443722\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015197431202977896\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008744312217459083\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011761218775063753\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.382768735580612\n",
      "\n",
      "[ Train epoch: 230 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001109406934119761\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010646528098732233\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007344745681621134\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013499561464414\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009419654961675406\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007404382922686636\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007127521093934774\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007352044340223074\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008023491827771068\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007968268473632634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00048035680083557963\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000993106048554182\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015616950113326311\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009875609539449215\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010887118987739086\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008937353850342333\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008360593928955495\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000779984868131578\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008454950875602663\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008267375524155796\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001458270475268364\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007472830475308001\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006789559847675264\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008019847446121275\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008388921269215643\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011241937754675746\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006958994781598449\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007411126280203462\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016561911907047033\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007180907414294779\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008577285334467888\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008995587704703212\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008283851202577353\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009439649293199182\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012188411783427\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009444294264540076\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001440018997527659\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007410653051920235\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008782490040175617\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012792362831532955\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3751549001899548\n",
      "\n",
      "[ Train epoch: 231 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001688966527581215\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007010196568444371\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008015265921130776\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010700409766286612\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020509148016572\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007295436807908118\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006632806034758687\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002561586908996105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008316619787365198\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007605652790516615\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007716026157140732\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006944345077499747\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008695158758200705\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008705391664989293\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007520435028709471\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008830581209622324\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009714548941701651\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010827304795384407\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008146559703163803\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011376675684005022\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013712941436097026\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001219955156557262\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018143004272133112\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001021438161842525\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011923759011551738\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010534717002883554\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011157318949699402\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008542215218767524\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010335511760786176\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000995222944766283\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013669353211298585\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008811826701276004\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008830702281557024\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007804128108546138\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007912745350040495\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000909872935153544\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007519500213675201\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001067217905074358\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010829265229403973\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010642444249242544\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.376978121639695\n",
      "\n",
      "[ Train epoch: 232 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007163857808336616\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010353089310228825\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00128934218082577\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010723621817305684\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009693792089819908\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009314533672295511\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007874772418290377\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007723093731328845\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008741324418224394\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008707490051165223\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012188541004434228\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008294677245430648\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008442410617135465\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007639913237653673\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000721809861715883\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008318587788380682\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008702430059202015\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007928251870907843\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007917112670838833\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007519838400185108\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007286308100447059\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008113114163279533\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001430098433047533\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013373825931921601\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013532263692468405\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013026263331994414\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000779870490077883\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011095392983406782\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012746950378641486\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009213423472829163\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008276565349660814\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008384598768316209\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001161062391474843\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001111527904868126\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011253884295001626\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000900253769941628\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014921517577022314\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010584532283246517\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006675674230791628\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009102729381993413\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3782232357771136\n",
      "\n",
      "[ Train epoch: 233 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000984278623946011\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009231118019670248\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000819800014141947\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009939175797626376\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001267174375243485\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009301115642301738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011036667274311185\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013025184161961079\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001016518333926797\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008861913811415434\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007294256356544793\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006848964258097112\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014691692776978016\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000786046264693141\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008005379349924624\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015337906079366803\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011515443911775947\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010511277941986918\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011256774887442589\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009212931036017835\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008221188327297568\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007502942462451756\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007945800316520035\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010282050352543592\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008072227356024086\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007608332089148462\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009506687056273222\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006294943741522729\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008991049835458398\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013971531298011541\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018364976858720183\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008280889596790075\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007830443209968507\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008033651392906904\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007790804957039654\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006945327040739357\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012420869898051023\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009072227985598147\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000928254914470017\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013104890240356326\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3760224943398498\n",
      "\n",
      "[ Train epoch: 234 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011995056411251426\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007616594666615129\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009193406440317631\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000536546460352838\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013395502464845777\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009493219549767673\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009665439720265567\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010201451368629932\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009491016389802098\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010474473237991333\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012146160006523132\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007264086743816733\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010195476934313774\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009720610687509179\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008033640333451331\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001110136741772294\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009667443227954209\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009092195541597903\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010480141500011086\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009152607526630163\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009872226510196924\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000731391366571188\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000820793560706079\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008166321786120534\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016452284762635827\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000911215553060174\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000965391518548131\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010241029085591435\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000797118351329118\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012037662090733647\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006639602943323553\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006729061715304852\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006751312175765634\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011830360163003206\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006189249106682837\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011842167004942894\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006036385311745107\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008135561947710812\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010560030350461602\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009159707697108388\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3706600844161585\n",
      "\n",
      "[ Train epoch: 235 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008899837266653776\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009406536119058728\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011269084643572569\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000818046391941607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007502055377699435\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000865229987539351\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008894071215763688\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009549770620651543\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001022259471938014\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010877072345465422\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001169633585959673\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006849518395029008\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008454308263026178\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013077950570732355\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008641170570626855\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014774348819628358\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001271198969334364\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008112819050438702\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007657880196347833\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012478920398280025\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011343829100951552\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010896272724494338\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008719784091226757\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001252282178029418\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009490958764217794\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011972784996032715\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008581720176152885\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010727113112807274\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012504771584644914\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010929021518677473\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007587859872728586\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008403891697525978\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009169677505269647\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009050224907696247\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007797768921591341\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008946011075749993\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010711239883676171\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008407355053350329\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005973821971565485\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011136267567053437\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.35508908290648833\n",
      "\n",
      "[ Train epoch: 236 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006760040414519608\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008841055096127093\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008571345242671669\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007775260019116104\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012272815220057964\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007523761596530676\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012265591649338603\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008968075853772461\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009053309913724661\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009834811789914966\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006456855335272849\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006830638740211725\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006921484018675983\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001006638747639954\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014578000409528613\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008164448081515729\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008491205517202616\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008052723715081811\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014284064527601004\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001263363054022193\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009952359832823277\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007542161038145423\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007505232933908701\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006052886601537466\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008421624079346657\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008671024115756154\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013611442409455776\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010197418741881847\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008094691438600421\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006954895216040313\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009865720057860017\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011535576777532697\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010423596249893308\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000704432197380811\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001301079522818327\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007853832212276757\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009923549368977547\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008601971785537899\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011404049582779408\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008238226291723549\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3709238398587331\n",
      "\n",
      "[ Train epoch: 237 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011213553370907903\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007532657473348081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007841348415240645\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007637435919605196\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007326109334826469\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013003244530409575\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008046378497965634\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008599552093073726\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006348944152705371\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012352835619822145\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008211048552766442\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009623333462513983\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011562785366550088\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000937513483222574\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008068333845585585\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007313987007364631\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008494938956573606\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010154697811231017\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010320702567696571\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010985193075612187\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009975258726626635\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011003349209204316\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010545164113864303\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010081076761707664\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007582447724416852\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014279457973316312\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008641094900667667\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009414823143742979\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007640046533197165\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006341282278299332\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012125886278226972\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008124444866552949\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001010245643556118\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001065807999111712\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008575367392040789\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012464870233088732\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001421252265572548\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015245137037709355\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016839717281982303\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008398879435844719\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3767668390646577\n",
      "\n",
      "[ Train epoch: 238 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010794192785397172\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000866218819282949\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010896763997152448\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010940971551463008\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005736788734793663\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007002365309745073\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001062971306964755\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009209542185999453\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010095358593389392\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007188442396000028\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010612166952341795\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015951846726238728\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010795483831316233\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007410490652546287\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006853505037724972\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007274533854797482\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008153423550538719\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001012115040794015\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007284439634531736\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016047903336584568\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006173551082611084\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011652852408587933\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009993730345740914\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000681996694765985\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006927266367711127\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011665032943710685\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008878750959411263\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001381967682391405\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008451250032521784\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008382474188692868\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008870823658071458\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008652536198496819\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008218737202696502\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010858780005946755\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000895583420060575\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011576111428439617\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007466555689461529\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008020529639907181\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011741947382688522\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016987476265057921\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3779814455192536\n",
      "\n",
      "[ Train epoch: 239 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008479697280563414\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000744677847251296\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009847794426605105\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013664918951690197\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011926264269277453\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014692479744553566\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011553190415725112\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007320810691453516\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008431868627667427\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009244200773537159\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008947698515839875\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008349267300218344\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007533179596066475\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011435732012614608\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008472921908833086\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011527842143550515\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010400352766737342\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008229315862990916\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010360917076468468\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008725299267098308\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001049293321557343\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007869068067520857\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009369690087623894\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008407314890064299\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009611211717128754\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008731712587177753\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008874949999153614\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007310500950552523\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008409859728999436\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000670974375680089\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009695870103314519\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006738079828210175\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007329384097829461\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010562567040324211\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007154353661462665\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011228055227547884\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005664437776431441\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001163695240393281\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008583732414990664\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013456966262310743\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37128414429025725\n",
      "\n",
      "[ Train epoch: 240 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000550662400200963\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006914379191584885\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000943124177865684\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007712835213169456\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006005847244523466\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011783172376453876\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007377765141427517\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00118491449393332\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000951498223003\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008668240043334663\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011205048067495227\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008005287381820381\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010667606256902218\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001161248772405088\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012643126538023353\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001301642507314682\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011136471293866634\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000841423636302352\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010148995788767934\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011082994751632214\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002303410554304719\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012082635657861829\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009379688417539\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010572306346148252\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011086419690400362\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009630662971176207\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007804245688021183\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011373365996405482\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008324312511831522\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013277719262987375\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016035998705774546\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014092402998358011\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007907877443358302\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014078662497922778\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000636065611615777\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009568880777806044\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008695573196746409\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000906337343621999\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009058807627297938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013111222069710493\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3794548384612426\n",
      "\n",
      "[ Train epoch: 241 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008228464284911752\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009307353757321835\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014310223050415516\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008569558849558234\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008518164395354688\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007630920154042542\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010412882547825575\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008029031450860202\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008838565554469824\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009553387062624097\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001020701602101326\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000835239770822227\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014907135628163815\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007038922631181777\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008288845419883728\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012898368295282125\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010088268900290132\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009116094443015754\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001578705501742661\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008508279570378363\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008192369132302701\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008131152717396617\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000828731746878475\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008662996697239578\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008873827173374593\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007504172390326858\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000772319792304188\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011294586583971977\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007749018259346485\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012668948620557785\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007864420767873526\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009015242103487253\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009288462460972369\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008940892294049263\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000871329044457525\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007493093144148588\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010118079371750355\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009630274726077914\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009592853602953255\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000872399949003011\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3712673903792165\n",
      "\n",
      "[ Train epoch: 242 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009122369228862226\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008720032055862248\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009894372196868062\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010136016644537449\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007401524344459176\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008502666605636477\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009098353330045938\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001066493452526629\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000546037859749049\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009095060522668064\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001255293725989759\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010712406365200877\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000686191488057375\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011583969462662935\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00200256472453475\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007537879864685237\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009157308959402144\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008863343973644078\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011272665578871965\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010312056401744485\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009484980837441981\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008527345489710569\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012473978567868471\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007767977076582611\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009313105838373303\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010510266292840242\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010059131309390068\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000642037543002516\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009605148225091398\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009244530228897929\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009221464861184359\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011164398165419698\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012248334242030978\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012635770253837109\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009150361292995512\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012424734886735678\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007423479692079127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011932639172300696\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000974764465354383\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026286740321666002\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3716406458988786\n",
      "\n",
      "[ Train epoch: 243 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007526781992055476\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006321474211290479\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008378023048862815\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007171271136030555\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000845474423840642\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008672726107761264\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007757435087114573\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010405669454485178\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007531435112468898\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012352126650512218\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005512300995178521\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000782842340413481\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001044822740368545\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007770385127514601\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011230556992813945\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008981490973383188\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000944661209359765\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008741766796447337\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008741345372982323\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009444165625609457\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010039469925686717\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009595860610716045\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007062272052280605\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008531043422408402\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008328619878739119\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013784239999949932\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010377992875874043\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008064014255069196\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008678604499436915\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014452586183324456\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000731323438230902\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008223231416195631\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008642812026664615\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010752043453976512\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009512488031759858\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007057926268316805\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000915242824703455\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010915440507233143\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00123459508176893\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013905619271099567\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3746936647221446\n",
      "\n",
      "[ Train epoch: 244 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008647398208267987\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007487941766157746\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007430128171108663\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007782926550135016\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011160437716171145\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011927183950319886\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009415686945430934\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012939674779772758\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008505168370902538\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000651738082524389\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008509663166478276\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007788303773850203\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000927877495996654\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011816658079624176\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006392010836862028\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010649376781657338\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009345494909211993\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00128528056666255\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009030444198288023\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007372722029685974\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006817486137151718\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009961003670468926\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009120085160247982\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005912967026233673\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000819417298771441\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018037693807855248\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006324467249214649\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007381231407634914\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008702523191459477\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010597814107313752\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009532477124594152\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010118820937350392\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008019995293579996\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012229400454089046\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001407752395607531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009128483943641186\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011788621777668595\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008414281764999032\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009929739171639085\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009471207740716636\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37722211866639555\n",
      "\n",
      "[ Train epoch: 245 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012428286718204618\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009036945994012058\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008201063028536737\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011330611305311322\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014128910843282938\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008942450513131917\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009041944285854697\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007480650092475116\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011385580291971564\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010096578625962138\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009093572734855115\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001330705126747489\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008544971351511776\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013958995696157217\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012837479589506984\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008165823528543115\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006830663769505918\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000680012337397784\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010047070682048798\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008392739109694958\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009342649136669934\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011809304123744369\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008320645429193974\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094225561246276\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011303843930363655\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011349074775353074\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001107106334529817\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006485979538410902\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010033914586529136\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008710718248039484\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001098070410080254\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000937915057875216\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008739308686926961\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013031137641519308\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000716266455128789\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007490649586543441\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012878462439402938\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002351311733946204\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009987934026867151\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017192319501191378\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.38068470422877\n",
      "\n",
      "[ Train epoch: 246 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015025908360257745\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009391247294843197\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011697631562128663\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012091152602806687\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013045151717960835\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001200419501401484\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009666298283264041\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013399661984294653\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006091221002861857\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012099789455533028\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000820880348328501\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010616877116262913\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000780776608735323\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009208604460582137\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008525155135430396\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010820450261235237\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010397956939414144\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009675227338448167\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001092957565560937\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014422741951420903\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008569250348955393\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010204107966274023\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007051641005091369\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001125961309298873\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000782219460234046\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010206287261098623\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008819186477921903\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006957907462492585\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008763257064856589\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001190011273138225\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014797660987824202\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000751038605812937\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008225197088904679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009405405726283789\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007601951947435737\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008660773746669292\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008114253869280219\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011968674371019006\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001038223272189498\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010572387836873531\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3757233933429234\n",
      "\n",
      "[ Train epoch: 247 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009403894073329866\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008544139564037323\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009776211809366941\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010418646270409226\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007095336331985891\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006400761776603758\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018498639110475779\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001014729612506926\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007230954943224788\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018883878365159035\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001396919135004282\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011029822053387761\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009856700198724866\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009811322670429945\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007781813037581742\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008721288177184761\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009160691406577826\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009896262781694531\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008495259680785239\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009789904579520226\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010981445666402578\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008550921338610351\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000604625849518925\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007671215571463108\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008065870497375727\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007131544407457113\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009380876435898244\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001027362304739654\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007075464818626642\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008395391050726175\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010864033829420805\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014312664279714227\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011731202248483896\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008615187834948301\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009991376427933574\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010671262862160802\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007312299567274749\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018061378505080938\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010213559726253152\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001140241278335452\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37897903606062755\n",
      "\n",
      "[ Train epoch: 248 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009434266830794513\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010702722938731313\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018506549531593919\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010274361120536923\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008857363136485219\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008493203204125166\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000812605838291347\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007530160946771502\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012912137899547815\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011558657279238105\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006511646206490695\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001023289980366826\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009154744329862297\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014747930690646172\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010591255268082023\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001092760358005762\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000983722973614931\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000973450078163296\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007875036098994315\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009048936190083623\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001245474093593657\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009416000684723258\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009216264588758349\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010937141487374902\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009606255916878581\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013793520629405975\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007437203312292695\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007280113641172647\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007487662369385362\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007688379264436662\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006280205561779439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008525184821337461\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014871410094201565\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006412140792235732\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001107176416553557\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007976788328960538\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007717880071140826\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012079619336873293\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010118786012753844\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016643155831843615\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.3780691434512846\n",
      "\n",
      "[ Train epoch: 249 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000840003602206707\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011737708700820804\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008661688771098852\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008426433196291327\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009864456951618195\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006742263212800026\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006842451984994113\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008824125397950411\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014523360878229141\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010146452113986015\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010803566547110677\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007433397695422173\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010284008458256721\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007236951496452093\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008212009561248124\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008749988046474755\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007685741875320673\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008152102236635983\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007311689550988376\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007785925990901887\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000659769750200212\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007872959831729531\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010914939921349287\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014149411581456661\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000815521867480129\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007878709584474564\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007505023968406022\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009022018639370799\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017721677431836724\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008176890551112592\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001035668421536684\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010699741542339325\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007986999116837978\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009234733297489583\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000950755609665066\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009238414349965751\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009272199822589755\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010794152040034533\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009910876397043467\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016359509900212288\n",
      "\n",
      "Total benign train accuarcy: 100.0\n",
      "Total benign train loss: 0.37982678948901594\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0002)\n",
    "for epoch in range(200, 250):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6c0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Test epoch: 249 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.700284481048584\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 3.8037827014923096\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 1.0594165325164795\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 3.878237724304199\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.945330023765564\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 4.397638320922852\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6879650950431824\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 3.5778591632843018\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.48312637209892273\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 3.535510540008545\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6030026078224182\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 3.5213959217071533\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8744757771492004\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 4.215766429901123\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.7506944537162781\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 3.9364798069000244\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.5168800950050354\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 3.5556087493896484\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.5792269706726074\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 3.672255277633667\n",
      "\n",
      "Total benign test accuarcy: 78.34\n",
      "Total adversarial test Accuarcy: 34.87\n",
      "Total benign test loss: 82.59672445058823\n",
      "Total adversarial test loss: 390.54036474227905\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b071ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
