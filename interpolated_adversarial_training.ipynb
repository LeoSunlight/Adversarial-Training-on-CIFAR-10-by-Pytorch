{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ca900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from models import  LinfPGDAttack, ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91657526",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epsilon = 0.0314\n",
    "k = 7\n",
    "alpha = 0.00784\n",
    "file_name = 'interpolated_adversarial_training'\n",
    "mixup_alpha = 1.0\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bdb470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1f3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y):\n",
    "    lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "adversary = LinfPGDAttack(net,epsilon,alpha,k)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61576d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    benign_loss = 0\n",
    "    adv_loss = 0\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_inputs, benign_targets_a, benign_targets_b, benign_lam = mixup_data(inputs, targets)\n",
    "        benign_outputs = net(benign_inputs)\n",
    "        loss1 = mixup_criterion(criterion, benign_outputs, benign_targets_a, benign_targets_b, benign_lam)\n",
    "        benign_loss += loss1.item()\n",
    "\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "        benign_correct += (benign_lam * predicted.eq(benign_targets_a).sum().float() + (1 - benign_lam) * predicted.eq(benign_targets_b).sum().float())\n",
    "        if batch_idx % 10 == 0:\n",
    "                print('\\nCurrent batch:', str(batch_idx))\n",
    "                print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "                print('Current benign train loss:', loss1.item())\n",
    "\n",
    "        adv = adversary.perturb(inputs, targets)\n",
    "        adv_inputs, adv_targets_a, adv_targets_b, adv_lam = mixup_data(adv, targets)\n",
    "        adv_outputs = net(adv_inputs)\n",
    "        loss2 = mixup_criterion(criterion, adv_outputs, adv_targets_a, adv_targets_b, adv_lam)\n",
    "        adv_loss += loss2.item()\n",
    "\n",
    "        _, predicted = adv_outputs.max(1)\n",
    "        adv_correct += (adv_lam * predicted.eq(adv_targets_a).sum().float() + (1 - adv_lam) * predicted.eq(adv_targets_b).sum().float())\n",
    "        if batch_idx % 10 == 0:\n",
    "                print('Current adversarial train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "                print('Current adversarial train loss:', loss2.item())\n",
    "\n",
    "        loss = (loss1 + loss2) / 2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * benign_correct / total)\n",
    "    print('Total adversarial train accuarcy:', 100. * adv_correct / total)\n",
    "    print('Total benign train loss:', benign_loss)\n",
    "    print('Total adversarial train loss:', adv_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b206ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    benign_loss = 0\n",
    "    adv_loss = 0\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            total += targets.size(0)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            benign_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            benign_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('\\nCurrent batch:', str(batch_idx))\n",
    "                print('Current benign test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "                print('Current benign test loss:', loss.item())\n",
    "\n",
    "            adv = adversary.perturb(inputs, targets)\n",
    "            adv_outputs = net(adv)\n",
    "            loss = criterion(adv_outputs, targets)\n",
    "            adv_loss += loss.item()\n",
    "\n",
    "            _, predicted = adv_outputs.max(1)\n",
    "            adv_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Current adversarial test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "                print('Current adversarial test loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign test accuarcy:', 100. * benign_correct / total)\n",
    "    print('Total adversarial test Accuarcy:', 100. * adv_correct / total)\n",
    "    print('Total benign test loss:', benign_loss)\n",
    "    print('Total adversarial test loss:', adv_loss)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3511eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 2.4463391304016113\n",
      "Current adversarial train accuracy: 0.0\n",
      "Current adversarial train loss: 4.894921779632568\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 3.1045103073120117\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 3.8991918563842773\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 2.3740270137786865\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.553011417388916\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 2.3121681213378906\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.4135799407958984\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 2.2573416233062744\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.3336985111236572\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 2.2239906787872314\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.3657889366149902\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 2.2404634952545166\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.3230957984924316\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 2.199002742767334\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.2126266956329346\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 2.214688301086426\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.290497064590454\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 2.2712223529815674\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.3192567825317383\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 2.2486159801483154\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.2769768238067627\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 2.2271974086761475\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 2.283614158630371\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.2734375\n",
      "Current benign train loss: 2.1198601722717285\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.2892398834228516\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 2.0590267181396484\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.322571039199829\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 2.221343755722046\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.3055362701416016\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 2.195244789123535\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.3038530349731445\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 2.131819009780884\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.315286874771118\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 2.1558337211608887\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.318600654602051\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 2.11336088180542\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.2453982830047607\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.9892795085906982\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.185530424118042\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 2.1433403491973877\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.1845884323120117\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 2.225663661956787\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.3087775707244873\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 2.048504590988159\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.2809319496154785\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 2.0844521522521973\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.2202632427215576\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 2.0477778911590576\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.2178831100463867\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 2.1283390522003174\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.2470831871032715\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 2.028637409210205\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.1986441612243652\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.9906184673309326\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.1746578216552734\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 2.0928826332092285\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.217522621154785\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 2.1694512367248535\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.3288826942443848\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 2.0289883613586426\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.246255397796631\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.853652834892273\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.1376571655273438\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 2.0383331775665283\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.0997581481933594\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 2.1058108806610107\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1763837337493896\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.984734296798706\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.234840154647827\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 2.0090789794921875\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.1624419689178467\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.9083703756332397\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 2.1748013496398926\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 2.0277833938598633\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.1519577503204346\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 2.037517786026001\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.235609531402588\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.35\n",
      "Current benign train loss: 2.0410847663879395\n",
      "Current adversarial train accuracy: 0.0875\n",
      "Current adversarial train loss: 2.208005905151367\n",
      "\n",
      "Total benign train accuarcy: tensor(22.2426, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(16.0951, device='cuda:0')\n",
      "Total benign train loss: 842.7990480661392\n",
      "Total adversarial train loss: 906.3990569114685\n",
      "\n",
      "[ Test epoch: 0 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.41\n",
      "Current benign test loss: 1.7651551961898804\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 2.1043882369995117\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.45\n",
      "Current benign test loss: 1.6949230432510376\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 2.0473289489746094\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.34\n",
      "Current benign test loss: 1.7303242683410645\n",
      "Current adversarial test accuracy: 0.16\n",
      "Current adversarial test loss: 2.0663161277770996\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.38\n",
      "Current benign test loss: 1.6998156309127808\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 2.078190803527832\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.28\n",
      "Current benign test loss: 1.8438541889190674\n",
      "Current adversarial test accuracy: 0.13\n",
      "Current adversarial test loss: 2.257385492324829\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.35\n",
      "Current benign test loss: 1.8024908304214478\n",
      "Current adversarial test accuracy: 0.16\n",
      "Current adversarial test loss: 2.198897361755371\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.29\n",
      "Current benign test loss: 1.8129409551620483\n",
      "Current adversarial test accuracy: 0.15\n",
      "Current adversarial test loss: 2.147568702697754\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.33\n",
      "Current benign test loss: 1.8983806371688843\n",
      "Current adversarial test accuracy: 0.17\n",
      "Current adversarial test loss: 2.314631223678589\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.4\n",
      "Current benign test loss: 1.7667754888534546\n",
      "Current adversarial test accuracy: 0.23\n",
      "Current adversarial test loss: 2.1413931846618652\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.23\n",
      "Current benign test loss: 1.8427892923355103\n",
      "Current adversarial test accuracy: 0.19\n",
      "Current adversarial test loss: 2.2082595825195312\n",
      "\n",
      "Total benign test accuarcy: 33.9\n",
      "Total adversarial test Accuarcy: 20.13\n",
      "Total benign test loss: 178.18654835224152\n",
      "Total adversarial test loss: 215.17391848564148\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.9407360553741455\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.1417911052703857\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.9604673385620117\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.1876020431518555\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.8774627447128296\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.1526997089385986\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 2.0312628746032715\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.171123504638672\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 2.090930223464966\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.1266403198242188\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 2.101591110229492\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 2.1706440448760986\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.9937974214553833\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.266479253768921\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.9074634313583374\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.1578330993652344\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 2.123826742172241\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.151120662689209\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.9362196922302246\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.2204761505126953\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.932153582572937\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.1963932514190674\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.6924989223480225\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.1679553985595703\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.939893126487732\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.1362807750701904\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 2.062757968902588\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.1674652099609375\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.8741343021392822\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.0219974517822266\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.3359375\n",
      "Current benign train loss: 1.800907015800476\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.2171287536621094\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.8519359827041626\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.187326431274414\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.8002381324768066\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.999205470085144\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 2.0106024742126465\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.055077314376831\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.9070892333984375\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.1753249168395996\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 2.005695343017578\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.208008289337158\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 2.0193886756896973\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.1691503524780273\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.8164061307907104\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.1397223472595215\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.9926029443740845\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.1233959197998047\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.7628448009490967\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.10390567779541\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.7236640453338623\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.1080856323242188\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.882692575454712\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.277393102645874\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.711573839187622\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.165369987487793\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.7528865337371826\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.163007974624634\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.780470848083496\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.0989675521850586\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.9405158758163452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.2137439250946045\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 2.0405778884887695\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.217130184173584\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.8771402835845947\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.1055209636688232\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.573771595954895\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.1158599853515625\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.7752903699874878\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.108214855194092\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.942278504371643\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.197469711303711\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 1.795314073562622\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.277709722518921\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 2.016677141189575\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.0940098762512207\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 2.051833152770996\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 2.234351634979248\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1125\n",
      "Current benign train loss: 1.897162675857544\n",
      "Current adversarial train accuracy: 0.15\n",
      "Current adversarial train loss: 2.2804384231567383\n",
      "\n",
      "Total benign train accuarcy: tensor(31.0874, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(19.6932, device='cuda:0')\n",
      "Total benign train loss: 753.1956994533539\n",
      "Total adversarial train loss: 845.2543958425522\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.5\n",
      "Current benign test loss: 1.6474277973175049\n",
      "Current adversarial test accuracy: 0.27\n",
      "Current adversarial test loss: 1.9775546789169312\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.5\n",
      "Current benign test loss: 1.6816455125808716\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 2.0415868759155273\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.44\n",
      "Current benign test loss: 1.6438872814178467\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.9808236360549927\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.46\n",
      "Current benign test loss: 1.603016972541809\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.943638801574707\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.39\n",
      "Current benign test loss: 1.7562947273254395\n",
      "Current adversarial test accuracy: 0.19\n",
      "Current adversarial test loss: 2.1511876583099365\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.44\n",
      "Current benign test loss: 1.6820217370986938\n",
      "Current adversarial test accuracy: 0.27\n",
      "Current adversarial test loss: 2.04390287399292\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.44\n",
      "Current benign test loss: 1.647336483001709\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.9789938926696777\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.42\n",
      "Current benign test loss: 1.6849323511123657\n",
      "Current adversarial test accuracy: 0.24\n",
      "Current adversarial test loss: 2.0705971717834473\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.51\n",
      "Current benign test loss: 1.628022313117981\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.9943110942840576\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.39\n",
      "Current benign test loss: 1.6456037759780884\n",
      "Current adversarial test accuracy: 0.18\n",
      "Current adversarial test loss: 1.9811991453170776\n",
      "\n",
      "Total benign test accuarcy: 44.18\n",
      "Total adversarial test Accuarcy: 23.51\n",
      "Total benign test loss: 167.68789422512054\n",
      "Total adversarial test loss: 202.5060112476349\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.917832374572754\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.1820783615112305\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 2.0452632904052734\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.05904483795166\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.8300223350524902\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.1693174839019775\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.8685015439987183\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.2294492721557617\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.9185376167297363\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.071058988571167\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.6688151359558105\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.170027494430542\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.9877777099609375\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.2121970653533936\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.7924853563308716\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.0396909713745117\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.9343230724334717\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1103529930114746\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.6639187335968018\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 2.1266355514526367\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.9708240032196045\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1383004188537598\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.9669108390808105\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1604323387145996\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 2.0171313285827637\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.163331985473633\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.7908382415771484\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.96872878074646\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.9192688465118408\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 2.189891815185547\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.878190279006958\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.010364055633545\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.7301549911499023\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.1769258975982666\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.7768115997314453\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0567359924316406\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.6419481039047241\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.1433539390563965\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.789696216583252\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.177170753479004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.947199821472168\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.156554698944092\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.7686123847961426\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.184544563293457\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.8597347736358643\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.1436679363250732\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.717422366142273\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.127408266067505\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.7712411880493164\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.1747817993164062\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 2.0013949871063232\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.185617208480835\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.8661994934082031\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.1905345916748047\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.7407903671264648\n",
      "Current adversarial train accuracy: 0.0390625\n",
      "Current adversarial train loss: 2.001415491104126\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.7837553024291992\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.9845945835113525\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.763031005859375\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.9645909070968628\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.8638694286346436\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0235092639923096\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 2.0671334266662598\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 2.039590358734131\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.5774863958358765\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.0858278274536133\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 2.0071496963500977\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.1024303436279297\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.0390625\n",
      "Current benign train loss: 1.6153273582458496\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.1926801204681396\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.8060475587844849\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 2.1711244583129883\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.900736689567566\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.1003732681274414\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3786683082580566\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.1259498596191406\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.981997013092041\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.152860164642334\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.709005355834961\n",
      "Current adversarial train accuracy: 0.0875\n",
      "Current adversarial train loss: 2.170315742492676\n",
      "\n",
      "Total benign train accuarcy: tensor(36.0045, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(21.8149, device='cuda:0')\n",
      "Total benign train loss: 718.4221550226212\n",
      "Total adversarial train loss: 826.5021543502808\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.59\n",
      "Current benign test loss: 1.3582360744476318\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.9138236045837402\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.55\n",
      "Current benign test loss: 1.3642539978027344\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.934830665588379\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.5\n",
      "Current benign test loss: 1.3482459783554077\n",
      "Current adversarial test accuracy: 0.23\n",
      "Current adversarial test loss: 1.843098759651184\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.62\n",
      "Current benign test loss: 1.2487738132476807\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7631890773773193\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.41\n",
      "Current benign test loss: 1.4587854146957397\n",
      "Current adversarial test accuracy: 0.2\n",
      "Current adversarial test loss: 2.0837807655334473\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.5\n",
      "Current benign test loss: 1.44834566116333\n",
      "Current adversarial test accuracy: 0.21\n",
      "Current adversarial test loss: 2.0243005752563477\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.47\n",
      "Current benign test loss: 1.420143485069275\n",
      "Current adversarial test accuracy: 0.18\n",
      "Current adversarial test loss: 1.9561398029327393\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.54\n",
      "Current benign test loss: 1.3742729425430298\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.9838718175888062\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.52\n",
      "Current benign test loss: 1.3725568056106567\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.9169032573699951\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.41\n",
      "Current benign test loss: 1.4353477954864502\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.9708749055862427\n",
      "\n",
      "Total benign test accuarcy: 50.82\n",
      "Total adversarial test Accuarcy: 25.15\n",
      "Total benign test loss: 139.6410493850708\n",
      "Total adversarial test loss: 195.0703821182251\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 2.002286672592163\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 2.232635021209717\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.830414056777954\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.1139626502990723\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.9397807121276855\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 2.0953867435455322\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.6643271446228027\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9149589538574219\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.5724406242370605\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.12218976020813\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.6306886672973633\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.180675745010376\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.8862518072128296\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.0343546867370605\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.5641167163848877\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.0064916610717773\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.8545689582824707\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.077970027923584\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.9396076202392578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.220060348510742\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.643937587738037\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 2.023308277130127\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.85677170753479\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1371102333068848\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 2.0467772483825684\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.0311074256896973\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 2.0564563274383545\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.299757957458496\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.5393505096435547\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.0948333740234375\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.8781640529632568\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0991899967193604\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.4856871366500854\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.075073003768921\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.8125677108764648\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1247997283935547\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.5817697048187256\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.052161693572998\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.9398236274719238\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.0277857780456543\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4470763206481934\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.2531349658966064\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.5791852474212646\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.009378433227539\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.3504019975662231\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.088693618774414\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.597003698348999\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.1507973670959473\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.380271315574646\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.1437184810638428\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.658242106437683\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.1963469982147217\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.8701424598693848\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.008772134780884\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.6517233848571777\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.158724784851074\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.453778624534607\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 2.013758659362793\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.522716760635376\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.2180683612823486\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.5160987377166748\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.2124881744384766\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.7912870645523071\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.1262545585632324\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.8293628692626953\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.18585205078125\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.9646894931793213\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.1618101596832275\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.648956298828125\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 2.0925300121307373\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.9816019535064697\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.160818576812744\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.7066147327423096\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.1293928623199463\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.5786535739898682\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.135986566543579\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.842195987701416\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9189927577972412\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.575\n",
      "Current benign train loss: 1.490067481994629\n",
      "Current adversarial train accuracy: 0.1\n",
      "Current adversarial train loss: 2.1605377197265625\n",
      "\n",
      "Total benign train accuarcy: tensor(40.0110, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(22.7289, device='cuda:0')\n",
      "Total benign train loss: 690.0369048118591\n",
      "Total adversarial train loss: 819.8887372016907\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.59\n",
      "Current benign test loss: 1.2642478942871094\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.8709121942520142\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.6\n",
      "Current benign test loss: 1.2575596570968628\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.8995275497436523\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.53\n",
      "Current benign test loss: 1.2665475606918335\n",
      "Current adversarial test accuracy: 0.24\n",
      "Current adversarial test loss: 1.8418889045715332\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.61\n",
      "Current benign test loss: 1.1867938041687012\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7391947507858276\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.55\n",
      "Current benign test loss: 1.3170932531356812\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.9772547483444214\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.55\n",
      "Current benign test loss: 1.3221068382263184\n",
      "Current adversarial test accuracy: 0.23\n",
      "Current adversarial test loss: 1.9726811647415161\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.44\n",
      "Current benign test loss: 1.404772162437439\n",
      "Current adversarial test accuracy: 0.18\n",
      "Current adversarial test loss: 2.0091917514801025\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.59\n",
      "Current benign test loss: 1.2946966886520386\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.9482613801956177\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.57\n",
      "Current benign test loss: 1.301744818687439\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.8853743076324463\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.56\n",
      "Current benign test loss: 1.2450580596923828\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.8321843147277832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 56.42\n",
      "Total adversarial test Accuarcy: 27.3\n",
      "Total benign test loss: 129.33093190193176\n",
      "Total adversarial test loss: 189.9045979976654\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.8666555881500244\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.0735135078430176\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.5160746574401855\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.031752347946167\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.5249958038330078\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.272740364074707\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.9602270126342773\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.9501234292984009\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.8663232326507568\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.9789354801177979\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.7647299766540527\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.132563591003418\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.4591635465621948\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.110668182373047\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.8781639337539673\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.0337159633636475\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.5773744583129883\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.0992791652679443\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.5066781044006348\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8911000490188599\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.7583603858947754\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.1614413261413574\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.4634205102920532\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.00016450881958\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.4342411756515503\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.1552023887634277\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.5336673259735107\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.208270311355591\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.6163097620010376\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.0666613578796387\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.9620904922485352\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.0925040245056152\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.6910470724105835\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.110605239868164\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.6962895393371582\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.109349489212036\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 2.023704767227173\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.9677138328552246\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.839625597000122\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.148674488067627\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.4634991884231567\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.9071683883666992\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.8735358715057373\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.091707706451416\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.6662827730178833\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.9274005889892578\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.432917833328247\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.087449550628662\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.9074339866638184\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.1171345710754395\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.4298839569091797\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.165409564971924\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.8668122291564941\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.0565474033355713\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6532156467437744\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.037698745727539\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.469691514968872\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.910492181777954\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.492830514907837\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9597654342651367\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.8101023435592651\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.1503214836120605\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.6577537059783936\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.1309666633605957\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.682068109512329\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.119898557662964\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.8387830257415771\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.1459755897521973\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.8082268238067627\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.147242784500122\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.547435998916626\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.0828537940979004\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.6189554929733276\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9636963605880737\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3692882061004639\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.0765326023101807\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.343551754951477\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.139172077178955\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.3625\n",
      "Current benign train loss: 1.852161169052124\n",
      "Current adversarial train accuracy: 0.3\n",
      "Current adversarial train loss: 2.0392911434173584\n",
      "\n",
      "Total benign train accuarcy: tensor(41.9606, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(24.5096, device='cuda:0')\n",
      "Total benign train loss: 674.582291841507\n",
      "Total adversarial train loss: 804.4220980405807\n",
      "\n",
      "[ Test epoch: 4 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.68\n",
      "Current benign test loss: 1.1676850318908691\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.823707103729248\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.59\n",
      "Current benign test loss: 1.2435969114303589\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.9212590456008911\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.65\n",
      "Current benign test loss: 1.1544361114501953\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.7330747842788696\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.62\n",
      "Current benign test loss: 1.227362871170044\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.892765998840332\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.63\n",
      "Current benign test loss: 1.2450799942016602\n",
      "Current adversarial test accuracy: 0.21\n",
      "Current adversarial test loss: 1.960679054260254\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.61\n",
      "Current benign test loss: 1.2316029071807861\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.9235481023788452\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.56\n",
      "Current benign test loss: 1.2868472337722778\n",
      "Current adversarial test accuracy: 0.2\n",
      "Current adversarial test loss: 1.9371119737625122\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.62\n",
      "Current benign test loss: 1.2011741399765015\n",
      "Current adversarial test accuracy: 0.27\n",
      "Current adversarial test loss: 1.9039313793182373\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.58\n",
      "Current benign test loss: 1.2744325399398804\n",
      "Current adversarial test accuracy: 0.23\n",
      "Current adversarial test loss: 1.9094951152801514\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.49\n",
      "Current benign test loss: 1.2639849185943604\n",
      "Current adversarial test accuracy: 0.17\n",
      "Current adversarial test loss: 1.9700698852539062\n",
      "\n",
      "Total benign test accuarcy: 58.77\n",
      "Total adversarial test Accuarcy: 26.79\n",
      "Total benign test loss: 126.417285323143\n",
      "Total adversarial test loss: 192.96354031562805\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.2734375\n",
      "Current benign train loss: 1.891991376876831\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.0173826217651367\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.3951435089111328\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.036792516708374\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.856041431427002\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0461413860321045\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.4993667602539062\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.095824956893921\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.6761224269866943\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9888865947723389\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3405286073684692\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.021200656890869\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.559139370918274\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.203517198562622\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.41326105594635\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.109992027282715\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.3856914043426514\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.962581753730774\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.4544010162353516\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 2.0954718589782715\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.6757924556732178\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9102532863616943\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.9274725914001465\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.1043732166290283\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.325762152671814\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.9176051616668701\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.761176347732544\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.062957763671875\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.889369249343872\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.1394805908203125\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.888113260269165\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9593017101287842\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.4488170146942139\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.1359591484069824\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.8591904640197754\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.9377179145812988\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.7728557586669922\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.182745933532715\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.9023315906524658\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.1483187675476074\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.4389166831970215\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9610427618026733\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.7538496255874634\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.1356430053710938\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.4761780500411987\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.91184401512146\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.8597720861434937\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 2.102031707763672\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.4094970226287842\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.8765243291854858\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.4415363073349\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.9390580654144287\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.7981157302856445\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.1695609092712402\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.4608567953109741\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.963919758796692\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.652692198753357\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9669322967529297\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.771395206451416\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.9070378541946411\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.23219895362854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.9798170328140259\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.7591522932052612\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8429853916168213\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.650559663772583\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.980482816696167\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.419973611831665\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.894885540008545\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.7748160362243652\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.035344123840332\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.5308879613876343\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9900301694869995\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.7613425254821777\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.1069774627685547\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.8783237934112549\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9929537773132324\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.5066554546356201\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 2.1434731483459473\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.525\n",
      "Current benign train loss: 1.6977635622024536\n",
      "Current adversarial train accuracy: 0.225\n",
      "Current adversarial train loss: 2.066275119781494\n",
      "\n",
      "Total benign train accuarcy: tensor(45.5003, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(25.5234, device='cuda:0')\n",
      "Total benign train loss: 648.4445335865021\n",
      "Total adversarial train loss: 795.7800410985947\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.65\n",
      "Current benign test loss: 1.206812858581543\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.872012972831726\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.66\n",
      "Current benign test loss: 1.1813198328018188\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.8669506311416626\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.61\n",
      "Current benign test loss: 1.1573861837387085\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.7595306634902954\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.68\n",
      "Current benign test loss: 1.1651531457901\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.8057070970535278\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.61\n",
      "Current benign test loss: 1.2716387510299683\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 2.022047519683838\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.58\n",
      "Current benign test loss: 1.247611403465271\n",
      "Current adversarial test accuracy: 0.21\n",
      "Current adversarial test loss: 1.9955470561981201\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.55\n",
      "Current benign test loss: 1.2759430408477783\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.9617537260055542\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.57\n",
      "Current benign test loss: 1.2045260667800903\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.9219964742660522\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.57\n",
      "Current benign test loss: 1.2177720069885254\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.8641542196273804\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.63\n",
      "Current benign test loss: 1.161261796951294\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.8289762735366821\n",
      "\n",
      "Total benign test accuarcy: 60.76\n",
      "Total adversarial test Accuarcy: 27.86\n",
      "Total benign test loss: 121.84009659290314\n",
      "Total adversarial test loss: 189.5974622964859\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.7882620096206665\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.108098030090332\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.2977709770202637\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.0764100551605225\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.4313650131225586\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9729578495025635\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.7045807838439941\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.1282548904418945\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.402468204498291\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8708611726760864\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.7066106796264648\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9785469770431519\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.6771736145019531\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.964272141456604\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.4516009092330933\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.062887668609619\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.7477138042449951\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0931220054626465\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.8702439069747925\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.055509328842163\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.8048503398895264\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.102074146270752\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.4155733585357666\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.1078999042510986\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.7830709218978882\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.104276657104492\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.3652088642120361\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9231195449829102\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.618159532546997\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9505189657211304\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.3670291900634766\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.0812675952911377\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.6972014904022217\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8363449573516846\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.6316859722137451\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.042513608932495\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.7868255376815796\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.0497798919677734\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.8283283710479736\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.065431594848633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.8117082118988037\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.10469388961792\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.3475110530853271\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9825226068496704\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.7190312147140503\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.046914577484131\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.4694347381591797\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.093430757522583\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.9384247064590454\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.170846462249756\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.470687985420227\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.0583548545837402\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.5871827602386475\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.0873303413391113\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.803487777709961\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.722969651222229\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.5992980003356934\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0868518352508545\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.29732084274292\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.025338649749756\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.7369508743286133\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.7498019933700562\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.6603916883468628\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.030738592147827\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.5608935356140137\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.128502130508423\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.9075490236282349\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.0704102516174316\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.5469021797180176\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.12042236328125\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.9489896297454834\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.1657321453094482\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.533718466758728\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.0474860668182373\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.4740097522735596\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.904974102973938\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.8735034465789795\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.860602617263794\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.6\n",
      "Current benign train loss: 1.6012046337127686\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.0213050842285156\n",
      "\n",
      "Total benign train accuarcy: tensor(47.7354, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(26.4830, device='cuda:0')\n",
      "Total benign train loss: 630.1109869480133\n",
      "Total adversarial train loss: 786.2920974493027\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.67\n",
      "Current benign test loss: 1.10985267162323\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7999118566513062\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.65\n",
      "Current benign test loss: 1.170457363128662\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.8561209440231323\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.62\n",
      "Current benign test loss: 1.0877269506454468\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.6918437480926514\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.69\n",
      "Current benign test loss: 1.118353247642517\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7881466150283813\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.62\n",
      "Current benign test loss: 1.1185091733932495\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.863466739654541\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.1428604125976562\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.8265011310577393\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.61\n",
      "Current benign test loss: 1.191922903060913\n",
      "Current adversarial test accuracy: 0.24\n",
      "Current adversarial test loss: 1.8442234992980957\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.63\n",
      "Current benign test loss: 1.1652412414550781\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.8686394691467285\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.64\n",
      "Current benign test loss: 1.1648180484771729\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.835137963294983\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.63\n",
      "Current benign test loss: 1.1667596101760864\n",
      "Current adversarial test accuracy: 0.2\n",
      "Current adversarial test loss: 1.8814016580581665\n",
      "\n",
      "Total benign test accuarcy: 63.83\n",
      "Total adversarial test Accuarcy: 28.98\n",
      "Total benign test loss: 116.53975701332092\n",
      "Total adversarial test loss: 184.566486120224\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.8221840858459473\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0476818084716797\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.1210181713104248\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.0201492309570312\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.3546074628829956\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9841406345367432\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.9155842065811157\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.205899238586426\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.350311279296875\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.185518264770508\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.6337738037109375\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.1194345951080322\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1202359199523926\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8917967081069946\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.5712088346481323\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.9849488735198975\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.8531317710876465\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.133899211883545\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.7914758920669556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8329623937606812\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.4621269702911377\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.861619472503662\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.4879138469696045\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.9509923458099365\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.6671676635742188\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.1035120487213135\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.7734496593475342\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0666720867156982\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.0717371702194214\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.875895619392395\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.962052345275879\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.0257785320281982\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3357441425323486\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.2301483154296875\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.804027795791626\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8891241550445557\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.2942192554473877\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.162468194961548\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.6323199272155762\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.9070656299591064\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.7539461851119995\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.0010507106781006\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.140709638595581\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.021458148956299\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.840794563293457\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.122170925140381\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.9006037712097168\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.107839822769165\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.8462936878204346\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.115060567855835\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.7862834930419922\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9955185651779175\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.6891109943389893\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9543044567108154\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.7436882257461548\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9223532676696777\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.483690857887268\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7798051834106445\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.328974962234497\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.039567232131958\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.7987052202224731\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.044729471206665\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.6669291257858276\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.0201828479766846\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.157280445098877\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9317835569381714\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.8510699272155762\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.0424346923828125\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1345539093017578\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9351202249526978\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.4640886783599854\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.063178062438965\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.7957992553710938\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.1030421257019043\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.4194920063018799\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0837459564208984\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.757863163948059\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.051513195037842\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.15\n",
      "Current benign train loss: 1.2824792861938477\n",
      "Current adversarial train accuracy: 0.1\n",
      "Current adversarial train loss: 1.857138991355896\n",
      "\n",
      "Total benign train accuarcy: tensor(50.3550, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(27.0001, device='cuda:0')\n",
      "Total benign train loss: 608.5470894575119\n",
      "Total adversarial train loss: 784.3228155374527\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 1.0804073810577393\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.7181189060211182\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0632630586624146\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.7021796703338623\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.65\n",
      "Current benign test loss: 1.0898370742797852\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.721138596534729\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 1.0579373836517334\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6590555906295776\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.69\n",
      "Current benign test loss: 1.10319983959198\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7792941331863403\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.68\n",
      "Current benign test loss: 1.130213975906372\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.8165861368179321\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.69\n",
      "Current benign test loss: 1.184009075164795\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.8422706127166748\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.65\n",
      "Current benign test loss: 1.0777535438537598\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7567754983901978\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0991520881652832\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7441225051879883\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.67\n",
      "Current benign test loss: 1.07450270652771\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7440086603164673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 68.63\n",
      "Total adversarial test Accuarcy: 33.49\n",
      "Total benign test loss: 111.27131450176239\n",
      "Total adversarial test loss: 176.86426711082458\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.541998028755188\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7842953205108643\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.8539502620697021\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.0840647220611572\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.0708866119384766\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.173123359680176\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.2045978307724\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.911524772644043\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.7418417930603027\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.8823914527893066\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.403144359588623\n",
      "Current adversarial train accuracy: 0.0390625\n",
      "Current adversarial train loss: 1.9440048933029175\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6508413553237915\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.0988717079162598\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.8638851642608643\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.888319969177246\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.0243804454803467\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7950764894485474\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.8565452098846436\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.1233465671539307\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.0782667398452759\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.9441710710525513\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.8261480331420898\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0741372108459473\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.3642792701721191\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.1353936195373535\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.7088241577148438\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9965306520462036\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.8519811630249023\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.088007688522339\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.8844190835952759\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.8619238138198853\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3012442588806152\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 2.013880729675293\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.90006685256958\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.0853214263916016\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6347182989120483\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.928183674812317\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.8521182537078857\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.1763172149658203\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.4066754579544067\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9815938472747803\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.5991449356079102\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.0837345123291016\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.570634365081787\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.09682559967041\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.802653431892395\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9422396421432495\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.1101404428482056\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9517699480056763\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.4064407348632812\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.105104923248291\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.5056655406951904\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.7941333055496216\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.7391951084136963\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9569365978240967\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.2234302759170532\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9435460567474365\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.8002631664276123\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0099682807922363\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.338512897491455\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 2.0650992393493652\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.2751768827438354\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9439325332641602\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1456395387649536\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9304935932159424\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.7621331214904785\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9325025081634521\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.3359375\n",
      "Current benign train loss: 1.806328296661377\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.0113368034362793\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.841148853302002\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.087616443634033\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.5959300994873047\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9565314054489136\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.6241366863250732\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.061328411102295\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.8895299434661865\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.8714081048965454\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.2375\n",
      "Current benign train loss: 1.7015293836593628\n",
      "Current adversarial train accuracy: 0.4625\n",
      "Current adversarial train loss: 1.8197572231292725\n",
      "\n",
      "Total benign train accuarcy: tensor(51.0681, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(28.0116, device='cuda:0')\n",
      "Total benign train loss: 604.2766715884209\n",
      "Total adversarial train loss: 774.5009138584137\n",
      "\n",
      "[ Test epoch: 8 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 1.0279693603515625\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.7535934448242188\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 1.0400617122650146\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7955937385559082\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 1.0373185873031616\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.7245571613311768\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.7\n",
      "Current benign test loss: 1.069496989250183\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7386720180511475\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0508439540863037\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.7974201440811157\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 1.0466378927230835\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.788681149482727\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.62\n",
      "Current benign test loss: 1.13718843460083\n",
      "Current adversarial test accuracy: 0.26\n",
      "Current adversarial test loss: 1.882423758506775\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.66\n",
      "Current benign test loss: 1.0528874397277832\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7853801250457764\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0235172510147095\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7500592470169067\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.7\n",
      "Current benign test loss: 1.0557979345321655\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.7979137897491455\n",
      "\n",
      "Total benign test accuarcy: 70.04\n",
      "Total adversarial test Accuarcy: 32.69\n",
      "Total benign test loss: 105.5143404006958\n",
      "Total adversarial test loss: 178.4159677028656\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.3395501375198364\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.0428080558776855\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.8642566204071045\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.9164506196975708\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.4918776750564575\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7437021732330322\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.243430495262146\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 2.0881857872009277\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1754918098449707\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.041003942489624\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.8926851749420166\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.1022167205810547\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.2219165563583374\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.0814995765686035\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.0873987674713135\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.907358169555664\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.425816297531128\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.0316972732543945\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.1050573587417603\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.9048964977264404\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.0491328239440918\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.111680030822754\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.2633724212646484\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.6453111171722412\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.4229700565338135\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.0075736045837402\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.298302412033081\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.148580551147461\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.672589898109436\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.0659852027893066\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.2242109775543213\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0876331329345703\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.0578713417053223\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.0647482872009277\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.1593610048294067\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8486571311950684\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.8300151824951172\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 2.034047842025757\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.5803457498550415\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9279990196228027\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.582758903503418\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 2.1102170944213867\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.6469777822494507\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.1152989864349365\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.4008561372756958\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.8517651557922363\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.6232585906982422\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8212207555770874\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.509291648864746\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8506088256835938\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 1.3500206470489502\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 2.0371267795562744\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.6915438175201416\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.091242551803589\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.5997200012207031\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.8332693576812744\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.208992600440979\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9374289512634277\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.8080081939697266\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 2.0173251628875732\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.523705244064331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9322035312652588\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.8072535991668701\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.0127782821655273\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.8679604530334473\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.0088460445404053\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.8151676654815674\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.0390639305114746\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.7777220010757446\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.925965666770935\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.4448118209838867\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9137297868728638\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.8857333660125732\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.7875230312347412\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.7534319162368774\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.100001096725464\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.7871981859207153\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9098159074783325\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.725\n",
      "Current benign train loss: 1.1099284887313843\n",
      "Current adversarial train accuracy: 0.0875\n",
      "Current adversarial train loss: 1.8006359338760376\n",
      "\n",
      "Total benign train accuarcy: tensor(52.7394, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(29.2088, device='cuda:0')\n",
      "Total benign train loss: 590.1759549379349\n",
      "Total adversarial train loss: 764.5779975652695\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 1.0565601587295532\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7436416149139404\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 1.0184202194213867\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.729538083076477\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.67\n",
      "Current benign test loss: 1.0437233448028564\n",
      "Current adversarial test accuracy: 0.27\n",
      "Current adversarial test loss: 1.6949865818023682\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.057611346244812\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6855932474136353\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0549589395523071\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7741682529449463\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 1.0458475351333618\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7547956705093384\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.66\n",
      "Current benign test loss: 1.0530272722244263\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.730812430381775\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.66\n",
      "Current benign test loss: 1.045859932899475\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7578742504119873\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 1.0536913871765137\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7597540616989136\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.67\n",
      "Current benign test loss: 1.0331847667694092\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7272132635116577\n",
      "\n",
      "Total benign test accuarcy: 69.13\n",
      "Total adversarial test Accuarcy: 33.29\n",
      "Total benign test loss: 106.03392601013184\n",
      "Total adversarial test loss: 175.75269269943237\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.7806882858276367\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8756572008132935\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.6571364402770996\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.8228119611740112\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.8315861225128174\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.1098172664642334\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.9946712851524353\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.7642805576324463\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.7612454891204834\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9862401485443115\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.052520751953125\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.8042656183242798\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.5006749629974365\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.7780998945236206\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2142114639282227\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.037997245788574\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.7714955806732178\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.9234193563461304\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.6426887512207031\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.1737594604492188\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.6858184337615967\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.1793630123138428\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.8596192598342896\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.9588711261749268\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2818094491958618\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9785655736923218\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.1116526126861572\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.9172990322113037\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.5107306241989136\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.0344858169555664\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4127871990203857\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.986645221710205\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.0353893041610718\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0042991638183594\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.734434962272644\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9357593059539795\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.2878615856170654\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.9741734266281128\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.7521600723266602\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0909736156463623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 1.1357672214508057\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.986842393875122\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.1822693347930908\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 2.063070774078369\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.621798038482666\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.1898984909057617\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.7536988258361816\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.1374387741088867\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.7263948917388916\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.0714478492736816\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.151126503944397\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8892813920974731\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.654737949371338\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7085115909576416\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.362575888633728\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9542617797851562\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.830732822418213\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.030540943145752\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.7087469100952148\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.7380670309066772\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.2574228048324585\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.107874631881714\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.2791190147399902\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.1364126205444336\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.5236403942108154\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.0179896354675293\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 1.1220178604125977\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8281164169311523\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0948238372802734\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.0058369636535645\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4399833679199219\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8644013404846191\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.5308103561401367\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.992802381515503\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.627760648727417\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.068235158920288\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.4793779850006104\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.142834424972534\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7375\n",
      "Current benign train loss: 0.8845335841178894\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.950305461883545\n",
      "\n",
      "Total benign train accuarcy: tensor(54.8372, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(29.4300, device='cuda:0')\n",
      "Total benign train loss: 570.1269746422768\n",
      "Total adversarial train loss: 767.9473292827606\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 0.9979206919670105\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7443715333938599\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9658052921295166\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7324899435043335\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.9234741926193237\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.6436396837234497\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9737047553062439\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6757868528366089\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 1.006567358970642\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.772109031677246\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 1.0233018398284912\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.8307386636734009\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 1.0139460563659668\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7456637620925903\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.68\n",
      "Current benign test loss: 1.005449652671814\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.8013780117034912\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.004489779472351\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7658723592758179\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9855890870094299\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.75667142868042\n",
      "\n",
      "Total benign test accuarcy: 71.6\n",
      "Total adversarial test Accuarcy: 33.68\n",
      "Total benign test loss: 100.29318070411682\n",
      "Total adversarial test loss: 176.39013040065765\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.6207607984542847\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8922536373138428\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3346285820007324\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.7622137069702148\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.1049365997314453\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.8896892070770264\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.735978603363037\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.929291844367981\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.6625585556030273\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.7930643558502197\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4107835292816162\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9597468376159668\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.0839881896972656\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8824408054351807\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.7161345481872559\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9478309154510498\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.6780552864074707\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.9568710327148438\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.9806010723114014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9641995429992676\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.475752592086792\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.5883575677871704\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.7620906829833984\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.717972755432129\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.0652525424957275\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7865135669708252\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.0904390811920166\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7612361907958984\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.6703846454620361\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9017081260681152\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6364761590957642\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.025925636291504\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.1355992555618286\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.0269014835357666\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.2647510766983032\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9290534257888794\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.71003258228302\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8721777200698853\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.6120907068252563\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8826210498809814\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.7413017749786377\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9605032205581665\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.7559027671813965\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.913333535194397\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2246692180633545\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.0372157096862793\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.0409536361694336\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8985803127288818\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.1861015558242798\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8793275356292725\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.095853567123413\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.101911783218384\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.2595415115356445\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.737842321395874\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.8543338775634766\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.060520887374878\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.8267028331756592\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.963922142982483\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.2203640937805176\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.815565824508667\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.2038990259170532\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9129393100738525\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.9828311204910278\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.0551185607910156\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.5342648029327393\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.8437466621398926\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.5489561557769775\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.029991626739502\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.8522238731384277\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.034611225128174\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.5618575811386108\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9584746360778809\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.4319310188293457\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8727946281433105\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.9484313726425171\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.088362216949463\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.7408573627471924\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.0783863067626953\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.7606258392333984\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.088665246963501\n",
      "\n",
      "Total benign train accuarcy: tensor(55.0278, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(30.4949, device='cuda:0')\n",
      "Total benign train loss: 567.5222891569138\n",
      "Total adversarial train loss: 755.0844042301178\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 0.9588109850883484\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.821424961090088\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.9436519742012024\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.8411662578582764\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.9523876905441284\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.8046380281448364\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.9795262813568115\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.804600477218628\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 0.9581363201141357\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.9092086553573608\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.9778060913085938\n",
      "Current adversarial test accuracy: 0.25\n",
      "Current adversarial test loss: 1.9222890138626099\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9768520593643188\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.8659707307815552\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.69\n",
      "Current benign test loss: 1.018767237663269\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.9449023008346558\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.940406858921051\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.850295901298523\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9253566861152649\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.8217183351516724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 73.36\n",
      "Total adversarial test Accuarcy: 31.95\n",
      "Total benign test loss: 96.09734052419662\n",
      "Total adversarial test loss: 184.2901133298874\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4456350803375244\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.7669583559036255\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.8214183449745178\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.802172064781189\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.7168552875518799\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0231165885925293\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.13241708278656\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.067659378051758\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.7968332767486572\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.8719538450241089\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.3985967636108398\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7727563381195068\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.7365410327911377\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.04864501953125\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.4286532402038574\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9525701999664307\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.5489368438720703\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.1017074584960938\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.8323814868927002\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0469307899475098\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.44492769241333\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.9473016262054443\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.5333225727081299\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.7560818195343018\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.5441484451293945\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.037734031677246\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.4939472675323486\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9821925163269043\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.563537359237671\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8390861749649048\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.3456172943115234\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9491534233093262\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.8132648468017578\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.796093225479126\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.1416255235671997\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9797084331512451\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.62664794921875\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9360079765319824\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.7880712151527405\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7547664642333984\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.3036565780639648\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.7996010780334473\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.4548381567001343\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.093871831893921\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.248764157295227\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8494032621383667\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.1935518980026245\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8994399309158325\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0799487829208374\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8960156440734863\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.8246381282806396\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8626381158828735\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.6810625791549683\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.5721124410629272\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.3539292812347412\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.142639636993408\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.691190242767334\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 2.0304746627807617\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.6730496883392334\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9831739664077759\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.883064866065979\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 2.0447754859924316\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.1778719425201416\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.0315463542938232\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.6427385807037354\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9857304096221924\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.1834489107131958\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.043776512145996\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3281171321868896\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.8857873678207397\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.9905399084091187\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.912494421005249\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.4256612062454224\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7369171380996704\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.6571354866027832\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.04386305809021\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.4141496419906616\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.181741952896118\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.0543030500411987\n",
      "Current adversarial train accuracy: 0.1125\n",
      "Current adversarial train loss: 1.8055802583694458\n",
      "\n",
      "Total benign train accuarcy: tensor(55.9771, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(30.8360, device='cuda:0')\n",
      "Total benign train loss: 563.6201749444008\n",
      "Total adversarial train loss: 749.6698812246323\n",
      "\n",
      "[ Test epoch: 12 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.854179859161377\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6932235956192017\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8646286725997925\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7514549493789673\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8552945852279663\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.6544699668884277\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9417495727539062\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7233220338821411\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.8923506736755371\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.8007385730743408\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8636971116065979\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7788751125335693\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.8853956460952759\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.729649305343628\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.65\n",
      "Current benign test loss: 0.9632391929626465\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.8176567554473877\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.8917948007583618\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6929872035980225\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.8439870476722717\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6551861763000488\n",
      "\n",
      "Total benign test accuarcy: 74.15\n",
      "Total adversarial test Accuarcy: 35.16\n",
      "Total benign test loss: 88.99464851617813\n",
      "Total adversarial test loss: 172.69314765930176\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.8517773151397705\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.0144095420837402\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.3956491947174072\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.0244297981262207\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2983324527740479\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9586570262908936\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.8684910535812378\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.740369439125061\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.1618372201919556\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7748056650161743\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.7956855297088623\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9388558864593506\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.4472694396972656\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9397666454315186\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.3359375\n",
      "Current benign train loss: 1.6872823238372803\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.8447988033294678\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.326214075088501\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6511512994766235\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.733352780342102\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.7862930297851562\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.5370793342590332\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.979187250137329\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.7560001611709595\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9767329692840576\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.458287000656128\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.024502992630005\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.2642014026641846\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 2.017439365386963\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.814357042312622\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8999524116516113\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.7079259157180786\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.143230438232422\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.7815431356430054\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.999330997467041\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.3276947736740112\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 2.03479266166687\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.91439288854599\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.010634660720825\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.0178108215332031\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9147908687591553\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7611290216445923\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.990602970123291\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.4875428676605225\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9429391622543335\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.417000651359558\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.667984962463379\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.9444494247436523\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.605851411819458\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.7538139820098877\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.922459602355957\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.5214595794677734\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.75391685962677\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.122899055480957\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.739618182182312\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.5403599739074707\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.8503122329711914\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.4344987869262695\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8231773376464844\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.2498725652694702\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.012955904006958\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.5799286365509033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 2.0208654403686523\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.6873929500579834\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.0154812335968018\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.6033419370651245\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9954280853271484\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4286882877349854\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9145724773406982\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3770911693572998\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.6493911743164062\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.9141941070556641\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.926285982131958\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.9266732335090637\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.6891745328903198\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.2891860008239746\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8403879404067993\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.378490924835205\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.7234251499176025\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.725\n",
      "Current benign train loss: 1.2476497888565063\n",
      "Current adversarial train accuracy: 0.3625\n",
      "Current adversarial train loss: 2.0460119247436523\n",
      "\n",
      "Total benign train accuarcy: tensor(57.1158, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(31.5054, device='cuda:0')\n",
      "Total benign train loss: 552.1506544947624\n",
      "Total adversarial train loss: 746.3505656719208\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.881503164768219\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7498342990875244\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.809907853603363\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.6959960460662842\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.8841835856437683\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.728172779083252\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9073593020439148\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6949273347854614\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9198957085609436\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.8401076793670654\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.8590347170829773\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.7949873208999634\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.9471789598464966\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.8588879108428955\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.7\n",
      "Current benign test loss: 0.9154064655303955\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7866259813308716\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.8632652759552002\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7515357732772827\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8531853556632996\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.6926254034042358\n",
      "\n",
      "Total benign test accuarcy: 75.1\n",
      "Total adversarial test Accuarcy: 35.32\n",
      "Total benign test loss: 88.05969732999802\n",
      "Total adversarial test loss: 173.71640729904175\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.683272361755371\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 2.0397586822509766\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.700778603553772\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.978286862373352\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.7487244606018066\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.148550271987915\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.0858070850372314\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8965425491333008\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.7902357578277588\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.036846399307251\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2487928867340088\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.7908803224563599\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.2162212133407593\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9493799209594727\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.4894894361495972\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.6009607315063477\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 1.3386507034301758\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.961499571800232\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.6153249740600586\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7259095907211304\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6493642330169678\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7720547914505005\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3062212467193604\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7297701835632324\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.012726068496704\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9423463344573975\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.8416937589645386\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.0326709747314453\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.6842408180236816\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.836371898651123\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.0864919424057007\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9519330263137817\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.4084351062774658\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.6071616411209106\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.7627719640731812\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.777811050415039\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.6820428371429443\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9912946224212646\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.1717817783355713\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.918219804763794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.2442457675933838\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7171862125396729\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.4665701389312744\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.6863009929656982\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.2715551853179932\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.7532575130462646\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.8249025344848633\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.858891487121582\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.948154866695404\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.763745665550232\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.711020827293396\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.0724968910217285\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.7754995822906494\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.856743574142456\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.5541824102401733\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.8955531120300293\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.475914478302002\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.976508617401123\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.6051054000854492\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7566919326782227\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.2306058406829834\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8900259733200073\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.6870102882385254\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.952428936958313\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.3650932312011719\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.809370994567871\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.2827565670013428\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 2.0525312423706055\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.6130776405334473\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.724170207977295\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.4617127180099487\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.0396993160247803\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.5124084949493408\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9032237529754639\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.38124680519104\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.0814361572265625\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2736570835113525\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.008514642715454\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.6625\n",
      "Current benign train loss: 1.6139819622039795\n",
      "Current adversarial train accuracy: 0.425\n",
      "Current adversarial train loss: 1.7502858638763428\n",
      "\n",
      "Total benign train accuarcy: tensor(56.9592, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(32.0631, device='cuda:0')\n",
      "Total benign train loss: 551.9371428489685\n",
      "Total adversarial train loss: 743.7003701925278\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9918123483657837\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6744084358215332\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9734987616539001\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.6852647066116333\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0209101438522339\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.680652141571045\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9982893466949463\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6166408061981201\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9737613201141357\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6869442462921143\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 1.011062502861023\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7383511066436768\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 1.0308116674423218\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7016348838806152\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.975533664226532\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6738439798355103\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.9638984799385071\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6909959316253662\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9836786389350891\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.677269458770752\n",
      "\n",
      "Total benign test accuarcy: 76.6\n",
      "Total adversarial test Accuarcy: 37.23\n",
      "Total benign test loss: 99.54001611471176\n",
      "Total adversarial test loss: 168.60378897190094\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.572427749633789\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9505401849746704\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.465644121170044\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 2.0025246143341064\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.720008373260498\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.878842830657959\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.194434404373169\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.7001659870147705\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 0.9510898590087891\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 2.0229134559631348\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.2407915592193604\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7423211336135864\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.1379761695861816\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9210264682769775\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6871348023414612\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8436455726623535\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.4673819541931152\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9574509859085083\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4180934429168701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.832434892654419\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.7762523889541626\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.677531123161316\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.9625736474990845\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.715602159500122\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.9574370980262756\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.918610692024231\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.694185495376587\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7422789335250854\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.5847535133361816\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 2.0443146228790283\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1544445753097534\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.95646071434021\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.5991904735565186\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.7144850492477417\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.7327358722686768\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.8412973880767822\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.7182281017303467\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 2.023277759552002\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4181103706359863\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.730929970741272\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.7857942581176758\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9898173809051514\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.7099719047546387\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.880413293838501\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.2291467189788818\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.6697607040405273\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.4515429735183716\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9474842548370361\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7873504757881165\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.0037708282470703\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.6625645160675049\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9046173095703125\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.7880537509918213\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.92391037940979\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.648439884185791\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.928178071975708\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.257371425628662\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7313207387924194\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.369920253753662\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.8256064653396606\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.7810020446777344\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 2.013800621032715\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.8368639945983887\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 2.0431933403015137\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.2590835094451904\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 2.032543182373047\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.7950611114501953\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9706473350524902\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.5085034370422363\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.983003854751587\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.2818048000335693\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9693520069122314\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.656480073928833\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.633813738822937\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.754432201385498\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8131530284881592\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.4379830360412598\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8235418796539307\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.0052742958068848\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.969132423400879\n",
      "\n",
      "Total benign train accuarcy: tensor(57.6464, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(32.4762, device='cuda:0')\n",
      "Total benign train loss: 543.8706827163696\n",
      "Total adversarial train loss: 738.5284514427185\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9394803047180176\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7143690586090088\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.8807766437530518\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6729336977005005\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9245842695236206\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.634688377380371\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.94881272315979\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6785086393356323\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9293937683105469\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7647209167480469\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.9031179547309875\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.7342888116836548\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.7\n",
      "Current benign test loss: 0.9987832903862\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7694305181503296\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.9309095740318298\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.7213435173034668\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.8718615174293518\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.640401005744934\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8902390003204346\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.6660797595977783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 77.2\n",
      "Total adversarial test Accuarcy: 36.15\n",
      "Total benign test loss: 91.40840423107147\n",
      "Total adversarial test loss: 168.44035637378693\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.6503489017486572\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.9865148067474365\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.7284414768218994\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.7544606924057007\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4769277572631836\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 2.0221846103668213\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.0508356094360352\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9508652687072754\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.3145962953567505\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9127594232559204\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.4245288372039795\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 2.1266369819641113\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.2232872247695923\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.1366982460021973\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.5464096069335938\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.1286263465881348\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.7086544036865234\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.699302315711975\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.779689908027649\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.0986239910125732\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.7146461009979248\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8307403326034546\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.6696889400482178\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.0403738021850586\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8467234969139099\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9102859497070312\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.1641075611114502\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.930915355682373\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.2969849109649658\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.689087152481079\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.5951125621795654\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9708125591278076\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.6028685569763184\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9374375343322754\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.1673336029052734\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7873919010162354\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.7930110096931458\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.6981619596481323\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.7545389533042908\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8489054441452026\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0734219551086426\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 2.016495943069458\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.725365161895752\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8302749395370483\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.0696167945861816\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.700250506401062\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2136529684066772\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.979137897491455\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.7166805863380432\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.7546666860580444\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.7909846305847168\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7424561977386475\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.6205898523330688\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9735640287399292\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.9724562168121338\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8281855583190918\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.3564876317977905\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0671329498291016\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.6815572381019592\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9342447519302368\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.3486741781234741\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9035272598266602\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6160008907318115\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.052255630493164\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8158355951309204\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9870705604553223\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.4016121625900269\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9729303121566772\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.7555341720581055\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9571857452392578\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.7672741413116455\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7531533241271973\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.6603655815124512\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.641402244567871\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.558337926864624\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6735219955444336\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.9359368085861206\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.0057404041290283\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7875\n",
      "Current benign train loss: 1.3704862594604492\n",
      "Current adversarial train accuracy: 0.1625\n",
      "Current adversarial train loss: 1.904202938079834\n",
      "\n",
      "Total benign train accuarcy: tensor(58.8237, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(32.0943, device='cuda:0')\n",
      "Total benign train loss: 531.3462265133858\n",
      "Total adversarial train loss: 740.7118180990219\n",
      "\n",
      "[ Test epoch: 16 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.8313016295433044\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6973475217819214\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.7859398722648621\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6682308912277222\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8259738683700562\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6649529933929443\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.863065779209137\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6821541786193848\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8169716000556946\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7376501560211182\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.8538224101066589\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.8044511079788208\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.8703930377960205\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7694627046585083\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.8512808084487915\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7315365076065063\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8087506294250488\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7431527376174927\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.7739665508270264\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6452913284301758\n",
      "\n",
      "Total benign test accuarcy: 77.35\n",
      "Total adversarial test Accuarcy: 35.74\n",
      "Total benign test loss: 82.3680909872055\n",
      "Total adversarial test loss: 170.87137353420258\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.235846996307373\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.1625781059265137\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.1677322387695312\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9930065870285034\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.7251088619232178\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.967099666595459\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4690617322921753\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.9990620613098145\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.6017382144927979\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.0375936031341553\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.9550209045410156\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7726359367370605\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.8554906845092773\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9006521701812744\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.4879846572875977\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.1062636375427246\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6218713521957397\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.6893941164016724\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.9154555201530457\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9798171520233154\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.6579750180244446\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9353563785552979\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.5867681503295898\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.952121376991272\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.5144565105438232\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.90761399269104\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.5989830493927002\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8596584796905518\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.6125402450561523\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8589857816696167\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.5932363271713257\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6827292442321777\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7753655314445496\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8055353164672852\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.6178395748138428\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9788365364074707\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.9852625727653503\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 1.9384582042694092\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.9133312702178955\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.6804816722869873\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.6562559604644775\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.8842904567718506\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.6738612651824951\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9609124660491943\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2112360000610352\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6934549808502197\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.7386273741722107\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.9856822490692139\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.6814507246017456\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0564403533935547\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.7394729852676392\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 2.018380641937256\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.4028955698013306\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9164609909057617\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.7289594411849976\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.699742078781128\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.9287083148956299\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9804046154022217\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.629650354385376\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.9130792617797852\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.7175642251968384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 2.001488447189331\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.2705384492874146\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7899155616760254\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.616438627243042\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.6852977275848389\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.5690619945526123\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8947584629058838\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.747682809829712\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.906141757965088\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.705075204372406\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.91206693649292\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.7907066345214844\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.7473948001861572\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.6008853912353516\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.1270575523376465\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6855944991111755\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.039045810699463\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.15\n",
      "Current benign train loss: 0.9833196401596069\n",
      "Current adversarial train accuracy: 0.525\n",
      "Current adversarial train loss: 1.4843034744262695\n",
      "\n",
      "Total benign train accuarcy: tensor(61.8928, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(33.1724, device='cuda:0')\n",
      "Total benign train loss: 501.3788754940033\n",
      "Total adversarial train loss: 732.4828507900238\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9882243871688843\n",
      "Current adversarial test accuracy: 0.46\n",
      "Current adversarial test loss: 1.662216305732727\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 1.0081719160079956\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.7265907526016235\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 1.0025582313537598\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6078511476516724\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9640055298805237\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.5938514471054077\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.974711000919342\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6484450101852417\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.9920200109481812\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6757142543792725\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 1.0408740043640137\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.698860764503479\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9448909163475037\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.6029939651489258\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9809134602546692\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.6931360960006714\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.934750497341156\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6173347234725952\n",
      "\n",
      "Total benign test accuarcy: 75.53\n",
      "Total adversarial test Accuarcy: 38.39\n",
      "Total benign test loss: 98.22985416650772\n",
      "Total adversarial test loss: 164.33359968662262\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2295348644256592\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 2.0320842266082764\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.6388213634490967\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8283488750457764\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.620013952255249\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7846183776855469\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.2946829795837402\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9312634468078613\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.7263935804367065\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.90407395362854\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.6774064302444458\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9910932779312134\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0405902862548828\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9563329219818115\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.9419375061988831\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.7593355178833008\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.6244704723358154\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9262794256210327\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.7318255305290222\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.7970119714736938\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.675269603729248\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.9170517921447754\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.7033917903900146\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9686185121536255\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.8881990909576416\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8861676454544067\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.8147544860839844\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 2.059809684753418\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.651740312576294\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.9147112369537354\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.4651985168457031\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9619783163070679\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3947267532348633\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9206284284591675\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.6599636673927307\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.8471996784210205\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.2606356143951416\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8405048847198486\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.8358463644981384\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.976052165031433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.671676516532898\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8091416358947754\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.4573075771331787\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.007000684738159\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.7138276100158691\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.9413940906524658\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.5798543095588684\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.7206530570983887\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.1288833618164062\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.9312736988067627\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.366502046585083\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9464303255081177\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0275511741638184\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9754314422607422\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.7275547981262207\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.6864854097366333\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.6549677848815918\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.5481902360916138\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.7847386002540588\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9936740398406982\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.7293184995651245\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.9354451894760132\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.8218159675598145\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 2.038814067840576\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.6828033924102783\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8713269233703613\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6897196769714355\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.7934215068817139\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.8753107190132141\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.7511484622955322\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.1992387771606445\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7994338274002075\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.4190764427185059\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.695478081703186\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.6635653972625732\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.898561954498291\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6820515394210815\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.8995988368988037\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.525\n",
      "Current benign train loss: 1.724149227142334\n",
      "Current adversarial train accuracy: 0.3375\n",
      "Current adversarial train loss: 1.776476263999939\n",
      "\n",
      "Total benign train accuarcy: tensor(60.2888, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(33.5856, device='cuda:0')\n",
      "Total benign train loss: 518.042051255703\n",
      "Total adversarial train loss: 727.9161268472672\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.9056270122528076\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.5767892599105835\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.9188780784606934\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.672690749168396\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.9208788275718689\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.580519199371338\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.970431923866272\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.666398525238037\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9289114475250244\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.662502408027649\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.941342830657959\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.7374639511108398\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9981606006622314\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7022039890289307\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9333441853523254\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6561654806137085\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.9004685282707214\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.637601375579834\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9145603179931641\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.680946707725525\n",
      "\n",
      "Total benign test accuarcy: 77.42\n",
      "Total adversarial test Accuarcy: 37.97\n",
      "Total benign test loss: 93.43984246253967\n",
      "Total adversarial test loss: 165.54511547088623\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.3359375\n",
      "Current benign train loss: 1.5902440547943115\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.5175683498382568\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.5713095664978027\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9307821989059448\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.5963118076324463\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9234718084335327\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.6856913566589355\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.854424238204956\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.6630613803863525\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.8883190155029297\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.5315983295440674\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.016505718231201\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.5184049606323242\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9102604389190674\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.4475198984146118\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0335185527801514\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.6073325872421265\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 2.0034122467041016\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.7543792724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.6293847560882568\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4958739280700684\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7174896001815796\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.6907286643981934\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.5727988481521606\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.9287568926811218\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 2.0516884326934814\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.0230261087417603\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.9700844287872314\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.7360806465148926\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.9176101684570312\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.636375069618225\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.045098304748535\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.54118013381958\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.8957465887069702\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.4028253555297852\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.7861759662628174\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.8704065084457397\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.875985860824585\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.5088510513305664\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9588584899902344\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2280027866363525\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.9093208312988281\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.5648905038833618\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8312971591949463\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.1055164337158203\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7757965326309204\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.3632961511611938\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9459295272827148\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.4622596502304077\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.95686936378479\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.2861026525497437\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.0730414390563965\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.0745370388031006\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.770538330078125\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.360823154449463\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9634066820144653\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.6990718841552734\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6960797309875488\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.9123797416687012\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.764052391052246\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.722408652305603\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8818817138671875\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.7176482677459717\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.014564037322998\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.7381200790405273\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7569749355316162\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.8284115791320801\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.9774339199066162\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.6574345231056213\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 2.0344789028167725\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.7157559394836426\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9613890647888184\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.2074904441833496\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.736445665359497\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.416090488433838\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6798702478408813\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.8006528615951538\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.976953148841858\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.4789457321166992\n",
      "Current adversarial train accuracy: 0.425\n",
      "Current adversarial train loss: 1.870002269744873\n",
      "\n",
      "Total benign train accuarcy: tensor(61.7451, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(34.0189, device='cuda:0')\n",
      "Total benign train loss: 500.85659939050674\n",
      "Total adversarial train loss: 722.2641575336456\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9423176050186157\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6739059686660767\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9292730093002319\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6834911108016968\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.69\n",
      "Current benign test loss: 0.9657554626464844\n",
      "Current adversarial test accuracy: 0.24\n",
      "Current adversarial test loss: 1.66050386428833\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9778929948806763\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.677794337272644\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.9519181251525879\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.7232975959777832\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.9323503971099854\n",
      "Current adversarial test accuracy: 0.27\n",
      "Current adversarial test loss: 1.7444274425506592\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 1.005173683166504\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.692905068397522\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9255913496017456\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.6999622583389282\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9056971073150635\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6534184217453003\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9277495741844177\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6472026109695435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 76.7\n",
      "Total adversarial test Accuarcy: 36.4\n",
      "Total benign test loss: 93.83100891113281\n",
      "Total adversarial test loss: 167.4109991788864\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.9442209601402283\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6182277202606201\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.7758219242095947\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.756263256072998\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.217488408088684\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9424629211425781\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.8146356344223022\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.833167314529419\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.5746568441390991\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9654184579849243\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.5644466876983643\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8175756931304932\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.2872065305709839\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.5674954652786255\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.5866687297821045\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.571555256843567\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.5464677810668945\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9274213314056396\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.6525605916976929\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9029881954193115\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2045162916183472\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.964860200881958\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.5063488483428955\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8627474308013916\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.4608917236328125\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.9401278495788574\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.5034818649291992\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7993407249450684\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4309158325195312\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9850677251815796\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.6078453660011292\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.6149195432662964\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.3429889678955078\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9437341690063477\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.4843779802322388\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.8829967975616455\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.0437259674072266\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.9388906955718994\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3333213329315186\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7118674516677856\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.8548845052719116\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.6484860181808472\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.7382442951202393\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7503886222839355\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.7109043598175049\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.7841620445251465\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.490087628364563\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8767621517181396\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.6157257556915283\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9786064624786377\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.669201135635376\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9717650413513184\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.1416091918945312\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.7921172380447388\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.7772486209869385\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9961997270584106\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5930390954017639\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9842809438705444\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.7406467199325562\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.768141269683838\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.7064850330352783\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.6133359670639038\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.483412265777588\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8385579586029053\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.3123455047607422\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.920302152633667\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.979214072227478\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.6792616844177246\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.1460299491882324\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6839743852615356\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.076175332069397\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9203273057937622\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.596091628074646\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.851651906967163\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.5492808818817139\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7839187383651733\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.054975152015686\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.971850872039795\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1125\n",
      "Current benign train loss: 1.448716163635254\n",
      "Current adversarial train accuracy: 0.3875\n",
      "Current adversarial train loss: 1.780013918876648\n",
      "\n",
      "Total benign train accuarcy: tensor(62.6951, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total adversarial train accuarcy: tensor(34.2702, device='cuda:0')\n",
      "Total benign train loss: 489.0942787826061\n",
      "Total adversarial train loss: 720.6810793876648\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9694511294364929\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.7205488681793213\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9313499927520752\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.762474536895752\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9338573217391968\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.6594401597976685\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.939664900302887\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6581432819366455\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.9306960105895996\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7186895608901978\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9277588129043579\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.7344038486480713\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.010434865951538\n",
      "Current adversarial test accuracy: 0.24\n",
      "Current adversarial test loss: 1.7933173179626465\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9484035968780518\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7625981569290161\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9460834264755249\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.8018614053726196\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8961753249168396\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6569273471832275\n",
      "\n",
      "Total benign test accuarcy: 77.48\n",
      "Total adversarial test Accuarcy: 33.99\n",
      "Total benign test loss: 94.04422253370285\n",
      "Total adversarial test loss: 173.07429468631744\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.6705756187438965\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7586777210235596\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.385956048965454\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.832571029663086\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.6772353649139404\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8710191249847412\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.3737943172454834\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8713667392730713\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.6910825967788696\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7310090065002441\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.2309682369232178\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.5944409370422363\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.6732674837112427\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7912431955337524\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.6704510450363159\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.006957769393921\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.108453631401062\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9444259405136108\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.6953356266021729\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.020036220550537\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9656314849853516\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8801934719085693\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.6339757442474365\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.7143746614456177\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.612946629524231\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.7056087255477905\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.829219102859497\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8975588083267212\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.8784996271133423\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.023076295852661\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.9493781328201294\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7806435823440552\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.0243219137191772\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9568438529968262\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.9206317067146301\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.806900143623352\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.6980312466621399\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.9171370267868042\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.6571487188339233\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9497308731079102\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.6183553338050842\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.7468593120574951\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.8329439759254456\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.723897933959961\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.49804213643074036\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.8424263000488281\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8114362359046936\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.7194342613220215\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.5402119159698486\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.9101892709732056\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.4287915229797363\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8126320838928223\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.5984309911727905\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9404017925262451\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.1822752952575684\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.002875328063965\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.710160493850708\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8847408294677734\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.3515233993530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.821014404296875\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.551437497138977\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9369412660598755\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.2337968349456787\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.972186803817749\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.3395917415618896\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8203462362289429\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2595551013946533\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.755595326423645\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.678312063217163\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9678400754928589\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.2387844324111938\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.0113306045532227\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.0031713247299194\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8094892501831055\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.406444787979126\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7551813125610352\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.0361868143081665\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0500411987304688\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7875\n",
      "Current benign train loss: 0.8802218437194824\n",
      "Current adversarial train accuracy: 0.4125\n",
      "Current adversarial train loss: 1.914459466934204\n",
      "\n",
      "Total benign train accuarcy: tensor(61.9559, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(33.3871, device='cuda:0')\n",
      "Total benign train loss: 498.89579114317894\n",
      "Total adversarial train loss: 728.4553776979446\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8941720724105835\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.706426978111267\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.8623062372207642\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.7250993251800537\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.8832280039787292\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.6497220993041992\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8710548281669617\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6151639223098755\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8670490980148315\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7284820079803467\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.8648768067359924\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7714483737945557\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9337632656097412\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.7211620807647705\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9016048908233643\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.763322353363037\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.862337052822113\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7171794176101685\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8184462785720825\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.650146484375\n",
      "\n",
      "Total benign test accuarcy: 78.14\n",
      "Total adversarial test Accuarcy: 34.33\n",
      "Total benign test loss: 88.98682415485382\n",
      "Total adversarial test loss: 170.61809372901917\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.8310196399688721\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.0428755283355713\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.5671672821044922\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.7823082208633423\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.5421204566955566\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9604160785675049\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.6399226188659668\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6821911334991455\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.2358927726745605\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9224295616149902\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.438032627105713\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.871138095855713\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.2215689420700073\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.048203945159912\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.015425682067871\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.5025639533996582\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2525138854980469\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.6614515781402588\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.759203314781189\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7266314029693604\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.7183586359024048\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.852802038192749\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.6151175498962402\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8656175136566162\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.7699899673461914\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8023676872253418\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.6921094059944153\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9212114810943604\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2216299772262573\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8372552394866943\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.4064579010009766\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.513863205909729\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.8418327569961548\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9238498210906982\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3259485960006714\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.6848936080932617\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.7563101053237915\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.654398798942566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.1573954820632935\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9200751781463623\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.6753716468811035\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9227036237716675\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.0245143175125122\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.07121205329895\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.5447252988815308\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8361668586730957\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.7427116632461548\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.6338942050933838\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.4280586242675781\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9105761051177979\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.202317714691162\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9532628059387207\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.5446200370788574\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.8955436944961548\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.0086345672607422\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.7919492721557617\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.892039954662323\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.9079546928405762\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7585779428482056\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.8028126955032349\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.3548262119293213\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7278878688812256\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.729149341583252\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.915102481842041\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.7050742506980896\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.976348876953125\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.7326045036315918\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.973170280456543\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.8310438394546509\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 2.085416555404663\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.4453132152557373\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.956594705581665\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.166154384613037\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.930443525314331\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.0125682353973389\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.024474859237671\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6480350494384766\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.7259483337402344\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4726206660270691\n",
      "Current adversarial train accuracy: 0.275\n",
      "Current adversarial train loss: 1.9243392944335938\n",
      "\n",
      "Total benign train accuarcy: tensor(63.9138, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(34.1937, device='cuda:0')\n",
      "Total benign train loss: 478.14556190371513\n",
      "Total adversarial train loss: 720.7590841054916\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.976652979850769\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.6536005735397339\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9190161824226379\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.642708420753479\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9270997643470764\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.5872454643249512\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9908050298690796\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6839584112167358\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9698295593261719\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.695439100265503\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9512253403663635\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.6632312536239624\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.7\n",
      "Current benign test loss: 1.0202438831329346\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7330113649368286\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9623386859893799\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.693932056427002\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9488853216171265\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7027064561843872\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8792497515678406\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5776194334030151\n",
      "\n",
      "Total benign test accuarcy: 77.14\n",
      "Total adversarial test Accuarcy: 37.59\n",
      "Total benign test loss: 94.04819893836975\n",
      "Total adversarial test loss: 164.35414350032806\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.618615984916687\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.640564203262329\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.694368839263916\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.881730079650879\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.5210192203521729\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0077457427978516\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2109838724136353\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9935522079467773\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.6607658267021179\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8419241905212402\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.169238567352295\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7652404308319092\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.7829921245574951\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.7121853828430176\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.4152053594589233\n",
      "Current adversarial train accuracy: 0.046875\n",
      "Current adversarial train loss: 1.7680776119232178\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.5422011613845825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.595727801322937\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.7176249027252197\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.973583459854126\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.6470664739608765\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.6775178909301758\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.6640098690986633\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8884650468826294\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.6574627161026001\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7829595804214478\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.6384934186935425\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.5856295824050903\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.035502314567566\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.551405668258667\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.369042158126831\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.905411958694458\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.6246576309204102\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.955148458480835\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.359375\n",
      "Current benign train loss: 1.6010953187942505\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7904959917068481\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.4536406993865967\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.6549135446548462\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.603171467781067\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.6411349773406982\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.5778638124465942\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.8658252954483032\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7514004111289978\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7722597122192383\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.1490366458892822\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9661731719970703\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2754859924316406\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8711364269256592\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.503383457660675\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.7693798542022705\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.2661848068237305\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9707621335983276\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.6926422119140625\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.0002102851867676\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.5873236060142517\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9145673513412476\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.5068933963775635\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9298505783081055\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.474142074584961\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8537662029266357\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.63258695602417\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9533684253692627\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.867016077041626\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6674878597259521\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.5927459001541138\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9495611190795898\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.1014657020568848\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8963830471038818\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2177692651748657\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.7293870449066162\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.7588300704956055\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.738602876663208\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.0105717182159424\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.6660078763961792\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.4538235664367676\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.8995819091796875\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4812085628509521\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9593713283538818\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8375\n",
      "Current benign train loss: 1.373188853263855\n",
      "Current adversarial train accuracy: 0.4625\n",
      "Current adversarial train loss: 1.95265793800354\n",
      "\n",
      "Total benign train accuarcy: tensor(62.9664, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(34.7693, device='cuda:0')\n",
      "Total benign train loss: 488.25849255919456\n",
      "Total adversarial train loss: 715.7450883388519\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.8826167583465576\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.604720115661621\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8541781902313232\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.629696011543274\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.8993573784828186\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.5835177898406982\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9248183369636536\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6272680759429932\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9117828607559204\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6780447959899902\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8905171155929565\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6883468627929688\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.9733500480651855\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6771975755691528\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.8738112449645996\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6099646091461182\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8944093585014343\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7266753911972046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.8134141564369202\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.5771353244781494\n",
      "\n",
      "Total benign test accuarcy: 77.01\n",
      "Total adversarial test Accuarcy: 37.32\n",
      "Total benign test loss: 88.92265665531158\n",
      "Total adversarial test loss: 163.5071985721588\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.5513367652893066\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.699408769607544\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.36528480052948\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.6996142864227295\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.8234837055206299\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.968400239944458\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.6055035591125488\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8220274448394775\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.2634403705596924\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.5981494188308716\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.2925087213516235\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.8000205755233765\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.4781825542449951\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8090310096740723\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.5688146352767944\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8720123767852783\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.610656499862671\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.9098563194274902\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4301854968070984\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.5372898578643799\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3050504922866821\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.6596142053604126\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.6857240200042725\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9212353229522705\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.5063010454177856\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9033820629119873\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.3858487606048584\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8784410953521729\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2168011665344238\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.7932584285736084\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.9774938821792603\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.841256022453308\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.1625564098358154\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7384626865386963\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.161327838897705\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.9207991361618042\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.5397987365722656\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.5374733209609985\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.6984187364578247\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.9297031164169312\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.4166969060897827\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.6212893724441528\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.3458294868469238\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9689664840698242\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.5262863636016846\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7566704750061035\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.8795401453971863\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8770594596862793\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.266424298286438\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.5144164562225342\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.413697749376297\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.901710033416748\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.5524661540985107\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8603063821792603\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.0023479461669922\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8116530179977417\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.6285573244094849\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9113085269927979\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.7641986012458801\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6122287511825562\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2874796390533447\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8833547830581665\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.6298781633377075\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.8868412971496582\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.6596015691757202\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6835484504699707\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.5658859014511108\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.757140874862671\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3794894218444824\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8772575855255127\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.5607737302780151\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.932863712310791\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.5945696830749512\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9046688079833984\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.509709119796753\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 2.000250816345215\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.660631775856018\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.9784035682678223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.775\n",
      "Current benign train loss: 1.4667177200317383\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.0250091552734375\n",
      "\n",
      "Total benign train accuarcy: tensor(63.6489, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.0050, device='cuda:0')\n",
      "Total benign train loss: 474.1870445013046\n",
      "Total adversarial train loss: 710.8759369850159\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.8985908031463623\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.6072040796279907\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8963634371757507\n",
      "Current adversarial test accuracy: 0.46\n",
      "Current adversarial test loss: 1.661910891532898\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9215308427810669\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.6123346090316772\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.891804575920105\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.559982419013977\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9115889072418213\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6618057489395142\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.9426018595695496\n",
      "Current adversarial test accuracy: 0.27\n",
      "Current adversarial test loss: 1.7491592168807983\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9600810408592224\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.6440259218215942\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.9095256924629211\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6902014017105103\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.8596935272216797\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.6211718320846558\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.8595995306968689\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.618231177330017\n",
      "\n",
      "Total benign test accuarcy: 77.45\n",
      "Total adversarial test Accuarcy: 37.3\n",
      "Total benign test loss: 90.6890276670456\n",
      "Total adversarial test loss: 164.11298751831055\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.384059190750122\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9117131233215332\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.5624843835830688\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8780144453048706\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.669837236404419\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9080135822296143\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.7397977709770203\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.691156029701233\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.1550875902175903\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.8891074657440186\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.895348846912384\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8031054735183716\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.496779441833496\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.9582407474517822\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.3378385305404663\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.8413755893707275\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.1857248544692993\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.61115300655365\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.6638308763504028\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.920896053314209\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.034501552581787\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.904712438583374\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.0340633392333984\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.8991680145263672\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.6526784896850586\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.7874350547790527\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0077370405197144\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8878918886184692\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.164763331413269\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8896085023880005\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.090200424194336\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7709392309188843\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.9894281625747681\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.916617751121521\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.3406486511230469\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.978651523590088\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.306670069694519\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8179889917373657\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.2823599576950073\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8420464992523193\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.578784465789795\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8682212829589844\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2617703676223755\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8871417045593262\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.1092246770858765\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7957336902618408\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.4310365915298462\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9861767292022705\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.1782305240631104\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.8884916305541992\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.9063114523887634\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8797523975372314\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.7793971300125122\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.6377679109573364\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.6055330038070679\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.6864171028137207\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2803173065185547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.0149645805358887\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.8433288931846619\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9450621604919434\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.4084808826446533\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.805394172668457\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.3418548107147217\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.821366310119629\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.5900585651397705\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.887357473373413\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.5225410461425781\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9411027431488037\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.571995496749878\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8599798679351807\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.4817558526992798\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.9467213153839111\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.4032230377197266\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.499380350112915\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.6779955625534058\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.9262807369232178\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.609427809715271\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.837094783782959\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1125\n",
      "Current benign train loss: 1.124428629875183\n",
      "Current adversarial train accuracy: 0.2375\n",
      "Current adversarial train loss: 2.1063899993896484\n",
      "\n",
      "Total benign train accuarcy: tensor(65.7763, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(34.7417, device='cuda:0')\n",
      "Total benign train loss: 458.3412880599499\n",
      "Total adversarial train loss: 714.798751950264\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.9488688111305237\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.6263611316680908\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9294605851173401\n",
      "Current adversarial test accuracy: 0.48\n",
      "Current adversarial test loss: 1.6591476202011108\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9409722685813904\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.6079891920089722\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9350995421409607\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.5921227931976318\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9591091275215149\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6745631694793701\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.985068678855896\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7271958589553833\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9875307679176331\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6615469455718994\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9269747138023376\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6354413032531738\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.9308364987373352\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6925512552261353\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.871793806552887\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.569400429725647\n",
      "\n",
      "Total benign test accuarcy: 78.68\n",
      "Total adversarial test Accuarcy: 38.46\n",
      "Total benign test loss: 94.05220210552216\n",
      "Total adversarial test loss: 164.76382660865784\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.4295981228351593\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8052178621292114\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.6869872808456421\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.906904935836792\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.7763601541519165\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.734596848487854\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.115767240524292\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.6887023448944092\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.5205328464508057\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.9344795942306519\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4759256839752197\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.799006462097168\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.5000853538513184\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9871940612792969\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.8361086845397949\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8035893440246582\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.250281572341919\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8875048160552979\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.0679551362991333\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8780895471572876\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0496829748153687\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9007490873336792\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.9432913064956665\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9458844661712646\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.5688185691833496\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8988971710205078\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.6097140312194824\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.026472568511963\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.248354434967041\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.8788830041885376\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.8642723560333252\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.7902965545654297\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.6273465156555176\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.7710778713226318\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.4340778589248657\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.7177064418792725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.4571726322174072\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.929502248764038\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.724989414215088\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.945862054824829\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.6855451464653015\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.849124550819397\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.0981673002243042\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.761141061782837\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.0424104928970337\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8594379425048828\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3345454931259155\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.6908092498779297\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.5850908756256104\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 1.9898037910461426\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.206595540046692\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.616605281829834\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.686065435409546\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.736227035522461\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.51725435256958\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9748685359954834\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.4683692455291748\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.890634298324585\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.2831275463104248\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.705571174621582\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.9760562181472778\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.7644270658493042\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.6533209085464478\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.9408434629440308\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7858231663703918\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.8282607793807983\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.4568626880645752\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.742967128753662\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.9540034532546997\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9066805839538574\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.5941779613494873\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.856720209121704\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.43153977394104\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8448967933654785\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.44356298446655273\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.901158332824707\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.5645771026611328\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8954839706420898\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.175\n",
      "Current benign train loss: 1.575716257095337\n",
      "Current adversarial train accuracy: 0.1125\n",
      "Current adversarial train loss: 1.9596083164215088\n",
      "\n",
      "Total benign train accuarcy: tensor(64.5901, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(33.9843, device='cuda:0')\n",
      "Total benign train loss: 473.71439519524574\n",
      "Total adversarial train loss: 721.6487725973129\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8913791179656982\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6367363929748535\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8777614831924438\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6916210651397705\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9135822057723999\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6057558059692383\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.8841323852539062\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6025912761688232\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8795743584632874\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6448416709899902\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.8883789777755737\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6889963150024414\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9741244316101074\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7338365316390991\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.883592963218689\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6400434970855713\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.8615809082984924\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.6546281576156616\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.8147395253181458\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.5731562376022339\n",
      "\n",
      "Total benign test accuarcy: 78.58\n",
      "Total adversarial test Accuarcy: 37.73\n",
      "Total benign test loss: 88.7502207159996\n",
      "Total adversarial test loss: 164.55798768997192\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.6297590732574463\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7187764644622803\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.0771290063858032\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.686471700668335\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.469384789466858\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.6935020685195923\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.1669292449951172\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9266259670257568\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.681104063987732\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.7613866329193115\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.411778211593628\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.9620859622955322\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.5833392143249512\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.485526204109192\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2843811511993408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9288746118545532\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.5365815162658691\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.5854859352111816\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.1069703102111816\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 2.0403048992156982\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.6192630529403687\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.7852272987365723\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.603102684020996\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.645430564880371\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.7508660554885864\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7154333591461182\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.657233476638794\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.991174578666687\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.3413208723068237\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.8322982788085938\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.0748168230056763\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.928877353668213\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.1412606239318848\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8218729496002197\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.4936246871948242\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.9797146320343018\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.9309447407722473\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9428576231002808\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.6050137281417847\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.6909228563308716\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.7009892463684082\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.9597296714782715\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.6579121351242065\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.931280493736267\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4676237404346466\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.824289083480835\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.9909955263137817\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 2.0463197231292725\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.37266206741333\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9270169734954834\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.4026069641113281\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9236489534378052\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.6485477685928345\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.8951416015625\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.4842878580093384\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.853564977645874\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.5953859090805054\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.917059302330017\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.1901607513427734\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.7970987558364868\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.3689854145050049\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9835302829742432\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.6510138511657715\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8887401819229126\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0637019872665405\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.915898084640503\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.5806269645690918\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.884670376777649\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.6685264110565186\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6310373544692993\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.8875030279159546\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.5160375833511353\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.5200661420822144\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.929168462753296\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.793476939201355\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9989795684814453\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.916931688785553\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8042837381362915\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1125\n",
      "Current benign train loss: 0.9491496682167053\n",
      "Current adversarial train accuracy: 0.1125\n",
      "Current adversarial train loss: 1.8170266151428223\n",
      "\n",
      "Total benign train accuarcy: tensor(64.4385, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.1654, device='cuda:0')\n",
      "Total benign train loss: 470.84211334586143\n",
      "Total adversarial train loss: 713.078181385994\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.9884387850761414\n",
      "Current adversarial test accuracy: 0.46\n",
      "Current adversarial test loss: 1.6122592687606812\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9621598720550537\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.6185487508773804\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.63\n",
      "Current benign test loss: 1.0506728887557983\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.66141939163208\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 1.0004962682724\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6183502674102783\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0026144981384277\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.6436262130737305\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 1.0170619487762451\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.7209266424179077\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.69\n",
      "Current benign test loss: 1.0765790939331055\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.675438642501831\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.7\n",
      "Current benign test loss: 0.9812145233154297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6570556163787842\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9481613636016846\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.603521466255188\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.9315121173858643\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5628554821014404\n",
      "\n",
      "Total benign test accuarcy: 74.48\n",
      "Total adversarial test Accuarcy: 38.91\n",
      "Total benign test loss: 98.78194618225098\n",
      "Total adversarial test loss: 162.7564321756363\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.6385383605957031\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8932876586914062\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.897972047328949\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9328789710998535\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.48788776993751526\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9170799255371094\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.1919033527374268\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.8615309000015259\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.283856749534607\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.850506067276001\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2222546339035034\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9029762744903564\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.6308629512786865\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 2.0450525283813477\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.2898989915847778\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6266063451766968\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.9599473476409912\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8783143758773804\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.7145246863365173\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9173338413238525\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7797033786773682\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.6885273456573486\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 1.0652347803115845\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.908134937286377\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.312082052230835\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.524808645248413\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.3610663414001465\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.6807174682617188\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2344441413879395\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.7818762063980103\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.7002339363098145\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8752692937850952\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.5033385753631592\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 2.007878303527832\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.5230522155761719\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.7110806703567505\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.4731982946395874\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.803609013557434\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.6023973226547241\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.5398385524749756\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.434807300567627\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8165459632873535\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.3432974815368652\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.6022062301635742\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.3844435214996338\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.861269235610962\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.5290750861167908\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.97965669631958\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.5977176427841187\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9400455951690674\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.6088310480117798\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.0247504711151123\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.7224717140197754\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.963649034500122\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.1849724054336548\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.9374456405639648\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.61915922164917\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.858131766319275\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.15194833278656\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7451691627502441\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.7241746783256531\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.9452195167541504\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.179249882698059\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9045764207839966\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.5438661575317383\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.925991415977478\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.6857848167419434\n",
      "Current adversarial train accuracy: 0.0234375\n",
      "Current adversarial train loss: 1.9594612121582031\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0965662002563477\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6339120864868164\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.9527832269668579\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.751737117767334\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.0160859823226929\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7997950315475464\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.0033702850341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.874804973602295\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.7955945134162903\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.8999485969543457\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 1.0575122833251953\n",
      "Current adversarial train accuracy: 0.0875\n",
      "Current adversarial train loss: 1.9186651706695557\n",
      "\n",
      "Total benign train accuarcy: tensor(66.4391, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.1313, device='cuda:0')\n",
      "Total benign train loss: 451.2126596570015\n",
      "Total adversarial train loss: 713.0957450866699\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.9386014342308044\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5936248302459717\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 0.939558207988739\n",
      "Current adversarial test accuracy: 0.47\n",
      "Current adversarial test loss: 1.6206926107406616\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.9141977429389954\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.4873855113983154\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.9308540225028992\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.5456863641738892\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.932984471321106\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.5857080221176147\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.9070260524749756\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6199586391448975\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.72\n",
      "Current benign test loss: 1.0041472911834717\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6273460388183594\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.67\n",
      "Current benign test loss: 0.9112628698348999\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5639437437057495\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.9261071085929871\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6131612062454224\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8760402202606201\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.5462510585784912\n",
      "\n",
      "Total benign test accuarcy: 75.55\n",
      "Total adversarial test Accuarcy: 40.95\n",
      "Total benign test loss: 92.5843066573143\n",
      "Total adversarial test loss: 158.39801383018494\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.3940523862838745\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9298453330993652\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.5078983306884766\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9252238273620605\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.5469032526016235\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8112938404083252\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.318790078163147\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.6841249465942383\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.3787057399749756\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.9920594692230225\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.2774845361709595\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7708516120910645\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0304346084594727\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.925255537033081\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.1739847660064697\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9338672161102295\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.4896858930587769\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8218705654144287\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.2614665031433105\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.4849481582641602\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.3392990827560425\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.5737282037734985\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.9671487808227539\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.87176513671875\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.62575364112854\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.62186598777771\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.0099514722824097\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 2.001495361328125\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.9023751020431519\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.556062936782837\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.5273053646087646\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6895833015441895\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.4861888289451599\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.5533944368362427\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.4837968349456787\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9362282752990723\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.0060834884643555\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8865296840667725\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.7974618673324585\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9298090934753418\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.7150239944458008\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.8600252866744995\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.5818732976913452\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.759725570678711\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.5454039573669434\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.7094666957855225\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.3308508396148682\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.5975573062896729\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.863085150718689\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.8921833038330078\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.4649113118648529\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9937607049942017\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.6850671768188477\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.950317621231079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.5560212135314941\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.7758417129516602\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.7348078489303589\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.6147656440734863\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 0.5204430818557739\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.765499234199524\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.6014994382858276\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8532488346099854\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.537612795829773\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.8959729671478271\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.6089255213737488\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.6083616018295288\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.8286654949188232\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.8567216396331787\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.4796068668365479\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.8457046747207642\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.5183423757553101\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.7871019840240479\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.240909218788147\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.9816722869873047\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.1343499422073364\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.547696590423584\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4014159440994263\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9310760498046875\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.85\n",
      "Current benign train loss: 1.4996100664138794\n",
      "Current adversarial train accuracy: 0.425\n",
      "Current adversarial train loss: 1.721105694770813\n",
      "\n",
      "Total benign train accuarcy: tensor(64.9691, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.7638, device='cuda:0')\n",
      "Total benign train loss: 464.77956357598305\n",
      "Total adversarial train loss: 706.0681391954422\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8558954000473022\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.611344814300537\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8246971368789673\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.6003761291503906\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.71\n",
      "Current benign test loss: 0.8797123432159424\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.5811063051223755\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.8745781779289246\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.586542010307312\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.8540890216827393\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.6402397155761719\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.8802350759506226\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.7056889533996582\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.8981481194496155\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.6487160921096802\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8228667974472046\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.622276782989502\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.8212059140205383\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5871467590332031\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7698527574539185\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5074599981307983\n",
      "\n",
      "Total benign test accuarcy: 78.65\n",
      "Total adversarial test Accuarcy: 37.98\n",
      "Total benign test loss: 84.67668145895004\n",
      "Total adversarial test loss: 161.5599683523178\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0372470617294312\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.8948194980621338\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.2734375\n",
      "Current benign train loss: 1.5970826148986816\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7351559400558472\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.5226690769195557\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8762779235839844\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0176966190338135\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8566763401031494\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.4259682893753052\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.772945761680603\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.9010821580886841\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6371785402297974\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.20424222946167\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.893624186515808\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7785767316818237\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8510161638259888\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.40761834383010864\n",
      "Current adversarial train accuracy: 0.5390625\n",
      "Current adversarial train loss: 1.6872742176055908\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.6269152164459229\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8423573970794678\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6416397094726562\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9510524272918701\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.4327964782714844\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9813873767852783\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.5971049070358276\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.5920753479003906\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.39666932821273804\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6204081773757935\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4750034809112549\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.8547122478485107\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.341060757637024\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.7173709869384766\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.565496802330017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.889127492904663\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.5817434787750244\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.009396553039551\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.777151346206665\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.9470837116241455\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.3706469535827637\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9720230102539062\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.4426672458648682\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 2.0206103324890137\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.48293936252594\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7228432893753052\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.523728847503662\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.8292790651321411\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.6277774572372437\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8937671184539795\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.9992752075195312\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9933229684829712\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.4080345630645752\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.772291898727417\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 0.5787702798843384\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8600990772247314\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.378697395324707\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.6529467105865479\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.5953711271286011\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.75201416015625\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.0203149318695068\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.5889520645141602\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.1250041723251343\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8246248960494995\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.6188701391220093\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.910377025604248\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.8810962438583374\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8320101499557495\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.607189416885376\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.982001781463623\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.2772767543792725\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7819128036499023\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.609739065170288\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.5531222820281982\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7940757274627686\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8493502140045166\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.6248209476470947\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9381963014602661\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.7565900087356567\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.563883662223816\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.175\n",
      "Current benign train loss: 0.9446696043014526\n",
      "Current adversarial train accuracy: 0.525\n",
      "Current adversarial train loss: 1.7503187656402588\n",
      "\n",
      "Total benign train accuarcy: tensor(64.8443, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.7714, device='cuda:0')\n",
      "Total benign train loss: 464.8758072257042\n",
      "Total adversarial train loss: 705.296583533287\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.8910001516342163\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6203597784042358\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.882744312286377\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.674055576324463\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8879667520523071\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5472512245178223\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.8819266557693481\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.546095371246338\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.8596896529197693\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.6550105810165405\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.87482088804245\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.6515891551971436\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.9463463425636292\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.6598280668258667\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.871477484703064\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.6173689365386963\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.9026938080787659\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.671412706375122\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8367729783058167\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.578940987586975\n",
      "\n",
      "Total benign test accuarcy: 78.22\n",
      "Total adversarial test Accuarcy: 38.79\n",
      "Total benign test loss: 87.45154112577438\n",
      "Total adversarial test loss: 161.63505065441132\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.9120442867279053\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8051525354385376\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.6173630952835083\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.6410311460494995\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.8777320384979248\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.8620810508728027\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.6831796169281006\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9348199367523193\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.252354621887207\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 2.1310014724731445\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.5863399505615234\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8958275318145752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.703705072402954\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9373313188552856\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.581223487854004\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8749923706054688\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.8340181112289429\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9707129001617432\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.9164071679115295\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.648327112197876\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.1790709495544434\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.5770364999771118\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.9614802598953247\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.9156010150909424\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.9181088805198669\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.913294792175293\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.4857861995697021\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9733312129974365\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.8667094707489014\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.907114863395691\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.6944698095321655\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9054605960845947\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.6566433906555176\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7539204359054565\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.3094911575317383\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.4710825681686401\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.7082310914993286\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8865935802459717\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.0868014097213745\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8481507301330566\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.0661394596099854\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.5881023406982422\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.2882373332977295\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7065744400024414\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1438671350479126\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8850066661834717\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.7190956473350525\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.9888336658477783\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.958606481552124\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7711669206619263\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.4361227750778198\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9675159454345703\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.9393323659896851\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.819277048110962\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.7454358339309692\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5355666875839233\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.6485497951507568\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9721124172210693\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.6023629903793335\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8397773504257202\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.6439725160598755\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.665127158164978\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.8474287390708923\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.7259821891784668\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.3736027479171753\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.6112042665481567\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.7766726016998291\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.8927607536315918\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.5353904962539673\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.717465877532959\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.4190404415130615\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.681523323059082\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3462138175964355\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.8969603776931763\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.6751737594604492\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9432873725891113\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.3209164142608643\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.6036633253097534\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.225\n",
      "Current benign train loss: 1.6479156017303467\n",
      "Current adversarial train accuracy: 0.425\n",
      "Current adversarial train loss: 1.8153769969940186\n",
      "\n",
      "Total benign train accuarcy: tensor(63.8639, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.0512, device='cuda:0')\n",
      "Total benign train loss: 493.02542212605476\n",
      "Total adversarial train loss: 711.9930598735809\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.7319322228431702\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.6881674528121948\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.6920647621154785\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7144943475723267\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.7276573181152344\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6729544401168823\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7329043745994568\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.5962660312652588\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.7037904262542725\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7092896699905396\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.7224521040916443\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.7878680229187012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.8259527087211609\n",
      "Current adversarial test accuracy: 0.29\n",
      "Current adversarial test loss: 1.8472248315811157\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.7368714213371277\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.676955223083496\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.7289431691169739\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7921922206878662\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6176316738128662\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.5413163900375366\n",
      "\n",
      "Total benign test accuarcy: 82.08\n",
      "Total adversarial test Accuarcy: 36.63\n",
      "Total benign test loss: 71.54980605840683\n",
      "Total adversarial test loss: 169.04640209674835\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.4195849895477295\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8621578216552734\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.022204875946045\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.870105504989624\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.1673948764801025\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9232823848724365\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.3734562397003174\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.861936092376709\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.0792129039764404\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9945629835128784\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.6884995698928833\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6239416599273682\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.1113595962524414\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.8382518291473389\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.6333327293395996\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9354748725891113\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.6510050296783447\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8268325328826904\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.8844238519668579\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9565508365631104\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.560116171836853\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.4602879285812378\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.0412189960479736\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.8214110136032104\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.6343032121658325\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.709571361541748\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.270338773727417\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9478278160095215\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.6380482316017151\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.819153070449829\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.222205638885498\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9749164581298828\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9842789769172668\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.7600494623184204\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.704937219619751\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8402678966522217\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.2124747037887573\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 2.066270351409912\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.652162790298462\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.922858715057373\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.3540985584259033\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8270400762557983\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.6167545318603516\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7871595621109009\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2580599784851074\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.922245979309082\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.8271684646606445\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9838252067565918\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0411765575408936\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.823880672454834\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.6831679344177246\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9065059423446655\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.256636381149292\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.936311960220337\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.486825704574585\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.7733296155929565\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.0152558088302612\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.6233868598937988\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.5615758895874023\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8106555938720703\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.6130675077438354\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.972245216369629\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.178492546081543\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9309556484222412\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7721090316772461\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.851995587348938\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.6280493140220642\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.8982374668121338\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.824201226234436\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7048035860061646\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.4717130661010742\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7174558639526367\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.5260974168777466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.6712334156036377\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.4647088050842285\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.841280221939087\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.4145313501358032\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.754082202911377\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2450370788574219\n",
      "Current adversarial train accuracy: 0.3875\n",
      "Current adversarial train loss: 1.8632334470748901\n",
      "\n",
      "Total benign train accuarcy: tensor(63.1324, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.1306, device='cuda:0')\n",
      "Total benign train loss: 498.6147957444191\n",
      "Total adversarial train loss: 713.0536803007126\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6993669271469116\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.566422939300537\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6680095195770264\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5543206930160522\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.7633294463157654\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.663019061088562\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.7615847587585449\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.625501275062561\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.7000030279159546\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.5833556652069092\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.9\n",
      "Current benign test loss: 0.6945475935935974\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.6964824199676514\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.7733856439590454\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6859265565872192\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.6800698637962341\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.5887885093688965\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6625635027885437\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.5819801092147827\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6447953581809998\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6114345788955688\n",
      "\n",
      "Total benign test accuarcy: 82.62\n",
      "Total adversarial test Accuarcy: 40.16\n",
      "Total benign test loss: 70.12552547454834\n",
      "Total adversarial test loss: 161.05277907848358\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.6576523184776306\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8660086393356323\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.2771399021148682\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.6997038125991821\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.63374662399292\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9168787002563477\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.690925121307373\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.699196696281433\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.6043879985809326\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.8490588665008545\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.7535202503204346\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.868894100189209\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.6008076667785645\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.8895548582077026\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.346822738647461\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.0434799194335938\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.450960636138916\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8165265321731567\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.5503549575805664\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8476476669311523\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.4719507694244385\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8788448572158813\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.7480878829956055\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.998838186264038\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.6902315616607666\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8290070295333862\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0844480991363525\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.827825665473938\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.4432541131973267\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.806027889251709\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9060612320899963\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8935575485229492\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.646432638168335\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9052526950836182\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.2426605224609375\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9153575897216797\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.5003397464752197\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5096681118011475\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.3892474174499512\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9166172742843628\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.6255344748497009\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8800973892211914\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.8946573138237\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9876205921173096\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.8476434350013733\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8797636032104492\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.3303732872009277\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 1.952378273010254\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.7367031574249268\n",
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.8945317268371582\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.5577627420425415\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8116344213485718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.5808498859405518\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8528201580047607\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4056472778320312\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.6046241521835327\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.69828462600708\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7671892642974854\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 1.4976223707199097\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7433180809020996\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.9224443435668945\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.6760077476501465\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.2712442874908447\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.7636387348175049\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.8786056041717529\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9444305896759033\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.8880105018615723\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.9233925342559814\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7545789480209351\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6160858869552612\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2738966941833496\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.728990077972412\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.5700538158416748\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.8299384117126465\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.329890489578247\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.8945741653442383\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.5152029991149902\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9668419361114502\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.6375\n",
      "Current benign train loss: 1.7141872644424438\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.0067036151885986\n",
      "\n",
      "Total benign train accuarcy: tensor(63.5552, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(35.8627, device='cuda:0')\n",
      "Total benign train loss: 491.83974185585976\n",
      "Total adversarial train loss: 706.6222113370895\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.7521852254867554\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6901293992996216\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.753170907497406\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.7126957178115845\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.8016155958175659\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.6574881076812744\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.8103363513946533\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.713699460029602\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.7784347534179688\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.704383373260498\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.7577117681503296\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.814109206199646\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.841939389705658\n",
      "Current adversarial test accuracy: 0.28\n",
      "Current adversarial test loss: 1.8851027488708496\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.7862538695335388\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.740646481513977\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.7419857978820801\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7299318313598633\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.727327287197113\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.6953997611999512\n",
      "\n",
      "Total benign test accuarcy: 82.93\n",
      "Total adversarial test Accuarcy: 36.26\n",
      "Total benign test loss: 77.0210742354393\n",
      "Total adversarial test loss: 172.81582307815552\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.9484808444976807\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.8006131649017334\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.5769410133361816\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.8640185594558716\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.7172058820724487\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9668699502944946\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.1647356748580933\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9372467994689941\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.7152199745178223\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8212776184082031\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.179998755455017\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.5496900081634521\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.0724390745162964\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7904610633850098\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.3799622058868408\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.651376724243164\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.155184268951416\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9820767641067505\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.7727518081665039\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.5109896659851074\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.661842703819275\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8186264038085938\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.208561897277832\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.8290265798568726\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.221345067024231\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9260902404785156\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 0.9635375738143921\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6005040407180786\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.4555048942565918\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8787866830825806\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.259227991104126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7075715065002441\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.590742826461792\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5933685302734375\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.6868535280227661\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9584705829620361\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.2210416793823242\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.5705517530441284\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.6045050621032715\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9065426588058472\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.8280782699584961\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.5846277475357056\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.7743996381759644\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.655336856842041\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.6506564617156982\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.8394722938537598\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.681065320968628\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9442631006240845\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.090502381324768\n",
      "Current adversarial train accuracy: 0.5546875\n",
      "Current adversarial train loss: 1.6624159812927246\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4777361154556274\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.5723401308059692\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.625481367111206\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9522020816802979\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.4277629852294922\n",
      "Current adversarial train accuracy: 0.5234375\n",
      "Current adversarial train loss: 1.6594181060791016\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.7204346656799316\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.8568875789642334\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.6305975914001465\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8393696546554565\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2517046928405762\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8015012741088867\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.665542721748352\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7174108028411865\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.3268153667449951\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.4609304666519165\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 1.1162869930267334\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.9568268060684204\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.568014144897461\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6430816650390625\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.8882946968078613\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.884979486465454\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.7402905225753784\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.69558846950531\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.3157131671905518\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9229196310043335\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0777034759521484\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.4020473957061768\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1375\n",
      "Current benign train loss: 0.7743897438049316\n",
      "Current adversarial train accuracy: 0.1125\n",
      "Current adversarial train loss: 1.682034969329834\n",
      "\n",
      "Total benign train accuarcy: tensor(64.1798, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(36.1718, device='cuda:0')\n",
      "Total benign train loss: 489.7306852340698\n",
      "Total adversarial train loss: 701.8934288024902\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7496421933174133\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6479883193969727\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6662573218345642\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5694845914840698\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6876776814460754\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.5276315212249756\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.738008439540863\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.5516629219055176\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6673808097839355\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5593252182006836\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6571958661079407\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6605916023254395\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.7739303112030029\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7671664953231812\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6733617186546326\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5874725580215454\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.6242156028747559\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.542073369026184\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6739991903305054\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.5506625175476074\n",
      "\n",
      "Total benign test accuarcy: 83.19\n",
      "Total adversarial test Accuarcy: 40.09\n",
      "Total benign test loss: 68.09681129455566\n",
      "Total adversarial test loss: 158.44314920902252\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.9803339242935181\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.8349204063415527\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.6430528163909912\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9493958950042725\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.6385043859481812\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8347485065460205\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.0168139934539795\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.9349900484085083\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.8364499807357788\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.808122158050537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 0.8361823558807373\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.7605178356170654\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.5819429159164429\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.8752063512802124\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.6820836067199707\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7787790298461914\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.7345044612884521\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7771252393722534\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.3010168075561523\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.6719629764556885\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.7768267393112183\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.927680253982544\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2808506488800049\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7258504629135132\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.7107038497924805\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8381690979003906\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.8173298835754395\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7947375774383545\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.5009548664093018\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8624252080917358\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.3215177059173584\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.8294909000396729\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.1067477464675903\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9050984382629395\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.2510523796081543\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.8002898693084717\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.922387957572937\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9109606742858887\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.4726099967956543\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.8097554445266724\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.999643087387085\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.0072567462921143\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.1095242500305176\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9827276468276978\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.5300642251968384\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.8685004711151123\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 0.6710717082023621\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.6087141036987305\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.9089353084564209\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.8898537158966064\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.4873385429382324\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8289762735366821\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.5750542879104614\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9429221153259277\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.6533665657043457\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.7113333940505981\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.5907573699951172\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.970562219619751\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.9807504415512085\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.5753287076950073\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.9788103103637695\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.84027898311615\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.651711106300354\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.914785623550415\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.666517972946167\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8241477012634277\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.5695347785949707\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.850844144821167\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.662043571472168\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.895362377166748\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.603166937828064\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7690181732177734\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.359375\n",
      "Current benign train loss: 1.7642183303833008\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8077969551086426\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.581348717212677\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8000158071517944\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.03125\n",
      "Current benign train loss: 0.9583279490470886\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 2.00925350189209\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1625\n",
      "Current benign train loss: 1.5553900003433228\n",
      "Current adversarial train accuracy: 0.075\n",
      "Current adversarial train loss: 1.828721284866333\n",
      "\n",
      "Total benign train accuarcy: tensor(65.9943, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(36.1159, device='cuda:0')\n",
      "Total benign train loss: 471.1394718885422\n",
      "Total adversarial train loss: 706.589456319809\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6700530052185059\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6695878505706787\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6194710731506348\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6328843832015991\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7373553514480591\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6109751462936401\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7327532768249512\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.719058871269226\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6878874897956848\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6624209880828857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6606793999671936\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6879676580429077\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.8000087141990662\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.760685682296753\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.6484189033508301\n",
      "Current adversarial test accuracy: 0.46\n",
      "Current adversarial test loss: 1.6166797876358032\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.6091172695159912\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6418095827102661\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6385831236839294\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.574895977973938\n",
      "\n",
      "Total benign test accuarcy: 83.96\n",
      "Total adversarial test Accuarcy: 38.07\n",
      "Total benign test loss: 67.14235132932663\n",
      "Total adversarial test loss: 165.02928185462952\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.785900890827179\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.80557119846344\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.0502203702926636\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6110765933990479\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.1426584720611572\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8958687782287598\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.6239101886749268\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.847339153289795\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.6039025783538818\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.8531814813613892\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0312848091125488\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.938402533531189\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7953895330429077\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8030177354812622\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.6986019611358643\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7276782989501953\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.6538705825805664\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8061355352401733\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.2980962991714478\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7280452251434326\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.6477307081222534\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7008072137832642\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7566320300102234\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.713792324066162\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.311065673828125\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.6315345764160156\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 1.5103518962860107\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.5634849071502686\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.2341558933258057\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.6542598009109497\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.7505985498428345\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 2.033686876296997\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.0239804983139038\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 2.0189597606658936\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.697718620300293\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.8195407390594482\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.9809038639068604\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.5410524606704712\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.476441740989685\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.9349169731140137\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.641256332397461\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.6874874830245972\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.690068244934082\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.9602254629135132\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.161561131477356\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8989503383636475\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.668860912322998\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.8513309955596924\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.7774249315261841\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.6231483221054077\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.575056791305542\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7801482677459717\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.620805025100708\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.754465937614441\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.3459608554840088\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9374630451202393\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.7525177597999573\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.9130160808563232\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.322460651397705\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.734711766242981\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.9591503739356995\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.6513056755065918\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.688249111175537\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.8219311237335205\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.701052188873291\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8947012424468994\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.7461355328559875\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.9458372592926025\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.6812834739685059\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.864058494567871\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.6063847541809082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.5785123109817505\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.1280282735824585\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.54371976852417\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3344541788101196\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.747485637664795\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.473389744758606\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8611676692962646\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7875\n",
      "Current benign train loss: 0.9239598512649536\n",
      "Current adversarial train accuracy: 0.0875\n",
      "Current adversarial train loss: 2.0340209007263184\n",
      "\n",
      "Total benign train accuarcy: tensor(63.7752, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(36.6972, device='cuda:0')\n",
      "Total benign train loss: 488.6578668951988\n",
      "Total adversarial train loss: 699.1660877466202\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.6082814931869507\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6793726682662964\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5628026127815247\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6058601140975952\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6806229948997498\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6696805953979492\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6701002717018127\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.7855569124221802\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.5848761796951294\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6705235242843628\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.89\n",
      "Current benign test loss: 0.5865917205810547\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.7412843704223633\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6630311012268066\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.7821890115737915\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6266292929649353\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.7029637098312378\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5828489065170288\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6630672216415405\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.9\n",
      "Current benign test loss: 0.5165657997131348\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.564794898033142\n",
      "\n",
      "Total benign test accuarcy: 84.94\n",
      "Total adversarial test Accuarcy: 38.2\n",
      "Total benign test loss: 60.49431151151657\n",
      "Total adversarial test loss: 168.383509516716\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2364412546157837\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.383803367614746\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4457374811172485\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.8941913843154907\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.9639893770217896\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.03476881980896\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.1953125\n",
      "Current benign train loss: 1.5807883739471436\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7025433778762817\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2475459575653076\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.4841077327728271\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.6817861795425415\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.6015992164611816\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.7011808156967163\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 2.0760817527770996\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.359375\n",
      "Current benign train loss: 1.7635293006896973\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8435547351837158\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.4615464210510254\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8415642976760864\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.4493812322616577\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.9033864736557007\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.7173068523406982\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9073251485824585\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.7174859046936035\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.614768385887146\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8462467193603516\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.7563762664794922\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.630465030670166\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.856350302696228\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.6542727947235107\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9783520698547363\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.7025625705718994\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.7916004657745361\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 1.6543866395950317\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.4268035888671875\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2533607482910156\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8109500408172607\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.6318342685699463\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.647961974143982\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3788232803344727\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8432281017303467\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.7428380846977234\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.907909631729126\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.507915735244751\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9851224422454834\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.9275187849998474\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.7505767345428467\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.62057626247406\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8307721614837646\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.6097593307495117\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9022579193115234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.3674800395965576\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9683066606521606\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.3279780149459839\n",
      "Current adversarial train accuracy: 0.53125\n",
      "Current adversarial train loss: 1.6037160158157349\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.6853134632110596\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.9544553756713867\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.2090132236480713\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.693497657775879\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.8806673288345337\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8058202266693115\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.9227586984634399\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.9854940176010132\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.8333572149276733\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.917696237564087\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.3246006965637207\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.5821268558502197\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.4996689558029175\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8954330682754517\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4406657218933105\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8619619607925415\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.6491453647613525\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.9241408109664917\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.6449881792068481\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.6836879253387451\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.6530640125274658\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8056174516677856\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.6052303314208984\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8857669830322266\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1\n",
      "Current benign train loss: 1.0255273580551147\n",
      "Current adversarial train accuracy: 0.3625\n",
      "Current adversarial train loss: 1.889031171798706\n",
      "\n",
      "Total benign train accuarcy: tensor(64.4806, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.1060, device='cuda:0')\n",
      "Total benign train loss: 485.2433084845543\n",
      "Total adversarial train loss: 694.2639706134796\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7133721113204956\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.6474136114120483\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.6022322177886963\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5319066047668457\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6975628733634949\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.522657036781311\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.725803554058075\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.5880070924758911\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.6521731615066528\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5652047395706177\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.91\n",
      "Current benign test loss: 0.6535837650299072\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.6889969110488892\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.7385531067848206\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.664927363395691\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.6433828473091125\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6089938879013062\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5949780941009521\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.5156028270721436\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5671766400337219\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.4693406820297241\n",
      "\n",
      "Total benign test accuarcy: 84.26\n",
      "Total adversarial test Accuarcy: 40.53\n",
      "Total benign test loss: 64.34069555997849\n",
      "Total adversarial test loss: 155.38576483726501\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.2036746740341187\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.5951186418533325\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.0908832550048828\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8316962718963623\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.7616862058639526\n",
      "Current adversarial train accuracy: 0.578125\n",
      "Current adversarial train loss: 1.654822826385498\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 0.7370375394821167\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7399156093597412\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.0143020153045654\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.6448285579681396\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.624003529548645\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5669149160385132\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.616727590560913\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.843798041343689\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.666822910308838\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7739341259002686\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.5655272006988525\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.7895535230636597\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.7394145727157593\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8629701137542725\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.7682015895843506\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8556816577911377\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 1.6848498582839966\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9874128103256226\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.134896993637085\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.5579206943511963\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.6587589979171753\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.926236867904663\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.6724615097045898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8613336086273193\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.5313602685928345\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.3562875986099243\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.7474397420883179\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.4480904340744019\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.3916316032409668\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8325111865997314\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.6528551578521729\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.8272643089294434\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.511785626411438\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.7980436086654663\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.6124403476715088\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.833735466003418\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.6434406042099\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.834320306777954\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.5925822257995605\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.6923880577087402\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.1492780447006226\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.7431068420410156\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 1.3618155717849731\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.860602855682373\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.8299359679222107\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.8681297302246094\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 0.5687595009803772\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8544321060180664\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.3000110387802124\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.980468988418579\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.201676845550537\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8927873373031616\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.6099231243133545\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8880589008331299\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.5893399715423584\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.8233063220977783\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.6409785747528076\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.8828065395355225\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.629713773727417\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.9016878604888916\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.72347491979599\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.918524146080017\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 1.6968193054199219\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7812886238098145\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.180727243423462\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9267544746398926\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.5861949920654297\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.8312885761260986\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.2462443113327026\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8909246921539307\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.7679522037506104\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.6033916473388672\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.7125\n",
      "Current benign train loss: 1.5611498355865479\n",
      "Current adversarial train accuracy: 0.475\n",
      "Current adversarial train loss: 1.9263546466827393\n",
      "\n",
      "Total benign train accuarcy: tensor(64.1914, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(36.9060, device='cuda:0')\n",
      "Total benign train loss: 483.95290583372116\n",
      "Total adversarial train loss: 698.6094853878021\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6381536722183228\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.8777172565460205\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.6730866432189941\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.8478888273239136\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.5817700028419495\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7109397649765015\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6620744466781616\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.8424062728881836\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6465332508087158\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.950993299484253\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.5954107046127319\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.8749068975448608\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6637557148933411\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.9377424716949463\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6302285194396973\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.8249118328094482\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.5347947478294373\n",
      "Current adversarial test accuracy: 0.31\n",
      "Current adversarial test loss: 1.7761341333389282\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.49369102716445923\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6099579334259033\n",
      "\n",
      "Total benign test accuarcy: 83.55\n",
      "Total adversarial test Accuarcy: 36.21\n",
      "Total benign test loss: 58.736846178770065\n",
      "Total adversarial test loss: 178.95827221870422\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.8035036325454712\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.9488019943237305\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6227506399154663\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8726375102996826\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.8873263001441956\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.7994956970214844\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.533474326133728\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7322173118591309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.9714913964271545\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.83504056930542\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.0400824546813965\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.0497353076934814\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.9802334308624268\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.8789598941802979\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.9096423387527466\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7051618099212646\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.675577163696289\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.6977378129959106\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.0712839365005493\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.9171829223632812\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.6969571113586426\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.6553411483764648\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 0.684537410736084\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.4632748365402222\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.5980170965194702\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8485934734344482\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.2397890090942383\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.5043538808822632\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.6605720520019531\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.9697849750518799\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.3125783205032349\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 2.0064432621002197\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.5434725284576416\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8316175937652588\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.6121220588684082\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9023795127868652\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.2074596881866455\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.4042255878448486\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.8947488069534302\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.5287901163101196\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.6832884550094604\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.5529402494430542\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.09994637966156\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.9514415264129639\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.5706758499145508\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.734034538269043\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.9215587377548218\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.5869512557983398\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 1.51959228515625\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 2.0122246742248535\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.1135456562042236\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.5866366624832153\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.3118896484375\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7790125608444214\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.6518954038619995\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.8123396635055542\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.8421791791915894\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.9435229301452637\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.5310723781585693\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8294391632080078\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.1720629930496216\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7913284301757812\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.0716359615325928\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.855022668838501\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.6023643016815186\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.980170488357544\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.9729547500610352\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8152291774749756\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.7504315376281738\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.7574951648712158\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.5206598043441772\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.81996750831604\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.8972601890563965\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9832191467285156\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.2093031406402588\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.6150397062301636\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.627288818359375\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.6602661609649658\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1375\n",
      "Current benign train loss: 1.3959217071533203\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7200398445129395\n",
      "\n",
      "Total benign train accuarcy: tensor(63.0145, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.3483, device='cuda:0')\n",
      "Total benign train loss: 498.98938339948654\n",
      "Total adversarial train loss: 693.571266412735\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.7177186608314514\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.5734803676605225\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6635806560516357\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.5337817668914795\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6977443695068359\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.473335862159729\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.7153661847114563\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5664945840835571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6819466352462769\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5665016174316406\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.7162299156188965\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7019734382629395\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.7750445008277893\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7070679664611816\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.7156593203544617\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.6104347705841064\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.7255300879478455\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.688286542892456\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.650766909122467\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.530858039855957\n",
      "\n",
      "Total benign test accuarcy: 83.3\n",
      "Total adversarial test Accuarcy: 40.13\n",
      "Total benign test loss: 69.17968481779099\n",
      "Total adversarial test loss: 158.7100007534027\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.659306526184082\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.891401767730713\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.0724831819534302\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.6090155839920044\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.4533047676086426\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.934880018234253\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.5740024447441101\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8895816802978516\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.6352061033248901\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8090341091156006\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.8824642896652222\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.6624808311462402\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.1184470653533936\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8313707113265991\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.887025773525238\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 2.0232229232788086\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.0846283435821533\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.4486074447631836\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.1789774894714355\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.527539610862732\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.359375\n",
      "Current benign train loss: 1.5614349842071533\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.9160618782043457\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.6468223333358765\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.4401715993881226\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.5920424461364746\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.5062555074691772\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.1151654720306396\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.504700779914856\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.5375382304191589\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.859441876411438\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.21875\n",
      "Current benign train loss: 1.549760103225708\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.7389122247695923\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.49143752455711365\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.742018222808838\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.187753438949585\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8978875875473022\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.4323145151138306\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.698253870010376\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.9282684326171875\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.9745416641235352\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.6249973773956299\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.7770700454711914\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.6167935132980347\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.5958486795425415\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.9998334646224976\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7124087810516357\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2148650884628296\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.913219928741455\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.9455184936523438\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9546657800674438\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.3461389541625977\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.587051272392273\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.5735424757003784\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.4783968925476074\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.644824743270874\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9053711891174316\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.7980165481567383\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8248767852783203\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.6389365196228027\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 2.0161988735198975\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.742060899734497\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.863709568977356\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.6669141054153442\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 2.0414130687713623\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3925302028656006\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.663554310798645\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.6364948749542236\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.9415924549102783\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.1495859622955322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7906005382537842\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.6898269653320312\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.854585886001587\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.7452068328857422\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 2.012014389038086\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.9041347503662109\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.9481208324432373\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.6571018695831299\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.9901690483093262\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1\n",
      "Current benign train loss: 0.574566662311554\n",
      "Current adversarial train accuracy: 0.525\n",
      "Current adversarial train loss: 1.649747371673584\n",
      "\n",
      "Total benign train accuarcy: tensor(63.1936, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.5190, device='cuda:0')\n",
      "Total benign train loss: 492.576952368021\n",
      "Total adversarial train loss: 690.6737568378448\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6292886734008789\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.647882342338562\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.5770528316497803\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6154348850250244\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6461667418479919\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.5662792921066284\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6819153428077698\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.611116886138916\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6502521634101868\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6478586196899414\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.89\n",
      "Current benign test loss: 0.6022956967353821\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6472512483596802\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.6689003109931946\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6925714015960693\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6288832426071167\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6329796314239502\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6158204078674316\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6778775453567505\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.5534988045692444\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.4825448989868164\n",
      "\n",
      "Total benign test accuarcy: 83.91\n",
      "Total adversarial test Accuarcy: 39.24\n",
      "Total benign test loss: 63.429511189460754\n",
      "Total adversarial test loss: 163.67912936210632\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.5261858701705933\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.681065320968628\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.647900938987732\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.857450008392334\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.6728951930999756\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8790854215621948\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.7297707796096802\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8391876220703125\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.476938009262085\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7249459028244019\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.5534022450447083\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.5058966875076294\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.6590495109558105\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6716818809509277\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.9785681366920471\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.9011127948760986\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.110391616821289\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8259286880493164\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.6873323321342468\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8933525085449219\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.434321641921997\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.630544900894165\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.2941974401474\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.480269193649292\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.2937729358673096\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.6546027660369873\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2747910022735596\n",
      "Current adversarial train accuracy: 0.0390625\n",
      "Current adversarial train loss: 1.7385015487670898\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.6293191313743591\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.678754448890686\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.6833202838897705\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.84499990940094\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.634131669998169\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8662593364715576\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.4814579486846924\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.578622579574585\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 1.3342258930206299\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9950546026229858\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.9915008544921875\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 2.011528730392456\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.46389639377594\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.8613758087158203\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.261427402496338\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.739851713180542\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.6051149368286133\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8916988372802734\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.7898341417312622\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.6272608041763306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.8853821158409119\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.4541139602661133\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.0800634622573853\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.7166833877563477\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0917423963546753\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.885488510131836\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.0910193920135498\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.6612188816070557\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.7969668507575989\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.7420778274536133\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.2499113082885742\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8358690738677979\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.6301798820495605\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.8849925994873047\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.5857785940170288\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8012943267822266\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.5369007587432861\n",
      "Current adversarial train accuracy: 0.34375\n",
      "Current adversarial train loss: 1.838545799255371\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.7573001384735107\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.4603452682495117\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.516348958015442\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8853428363800049\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.42728203535079956\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9195563793182373\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.2389891147613525\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.9055157899856567\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.5380180478096008\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.8186581134796143\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.2964158058166504\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.4151177406311035\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.5375\n",
      "Current benign train loss: 1.6131412982940674\n",
      "Current adversarial train accuracy: 0.175\n",
      "Current adversarial train loss: 1.6855517625808716\n",
      "\n",
      "Total benign train accuarcy: tensor(65.0658, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.5707, device='cuda:0')\n",
      "Total benign train loss: 477.09195551276207\n",
      "Total adversarial train loss: 690.073145031929\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.6481796503067017\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6477779150009155\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6138340830802917\n",
      "Current adversarial test accuracy: 0.33\n",
      "Current adversarial test loss: 1.727901816368103\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.667104959487915\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.6778652667999268\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6794381737709045\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6612550020217896\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.6551072597503662\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6626219749450684\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.92\n",
      "Current benign test loss: 0.5706068277359009\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6558480262756348\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6942812204360962\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.7464545965194702\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6347283720970154\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.6271780729293823\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.5999459028244019\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.642462968826294\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.527698278427124\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.492270827293396\n",
      "\n",
      "Total benign test accuarcy: 84.49\n",
      "Total adversarial test Accuarcy: 38.85\n",
      "Total benign test loss: 63.15363085269928\n",
      "Total adversarial test loss: 165.2714967727661\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.3910419940948486\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7017031908035278\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.3958461284637451\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.991428017616272\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.7506113052368164\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.8767740726470947\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.5620627403259277\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.8536603450775146\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.6413421630859375\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9252433776855469\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.6798714995384216\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8689420223236084\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.3422733545303345\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.862516164779663\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.268607497215271\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.7288718223571777\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 1.2965052127838135\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.611098051071167\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.35276460647583\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.8614715337753296\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.4919703006744385\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.575484037399292\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.097380518913269\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.70152747631073\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.2734375\n",
      "Current benign train loss: 1.646348476409912\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8821648359298706\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.4047048091888428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.934828519821167\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.5602686405181885\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.4605355262756348\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.9031970500946045\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.5932971239089966\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.583761215209961\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8563146591186523\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.0893499851226807\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.836112141609192\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.191376805305481\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.8673343658447266\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.069908857345581\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.6126824617385864\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.2890625\n",
      "Current benign train loss: 1.6072945594787598\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.9415134191513062\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.584933876991272\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.9422540664672852\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2397634983062744\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.8015835285186768\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.228070616722107\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.6863256692886353\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.4776310920715332\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9348217248916626\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.3518376350402832\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 1.8331116437911987\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.15625\n",
      "Current benign train loss: 1.4758847951889038\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.947866439819336\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.001152515411377\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5591390132904053\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.0546046495437622\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.8095316886901855\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.5954334735870361\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7521473169326782\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.834770917892456\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.9308593273162842\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.7796566486358643\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.852226734161377\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2855560779571533\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.825910210609436\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.310365080833435\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.579325556755066\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.159520149230957\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.676941990852356\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.9933230876922607\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.865862250328064\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.4559922516345978\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.7498753070831299\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.5852959156036377\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.7908315658569336\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.322265625\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.844341516494751\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.225\n",
      "Current benign train loss: 1.612111210823059\n",
      "Current adversarial train accuracy: 0.2375\n",
      "Current adversarial train loss: 1.879570722579956\n",
      "\n",
      "Total benign train accuarcy: tensor(64.9218, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.5818, device='cuda:0')\n",
      "Total benign train loss: 482.075631827116\n",
      "Total adversarial train loss: 687.9964224100113\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.7075855731964111\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6614906787872314\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.6733240485191345\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5763869285583496\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.7339692115783691\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.632082462310791\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.7665250301361084\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.660886526107788\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.7095577120780945\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.7092944383621216\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6872511506080627\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7551480531692505\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.7583045363426208\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.7332565784454346\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6864234209060669\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.7128775119781494\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.68346107006073\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7458056211471558\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6176543831825256\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.648252248764038\n",
      "\n",
      "Total benign test accuarcy: 83.51\n",
      "Total adversarial test Accuarcy: 38.35\n",
      "Total benign test loss: 69.52345472574234\n",
      "Total adversarial test loss: 166.50729429721832\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.337408423423767\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.437551736831665\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.6583304405212402\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.412812352180481\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.4334042072296143\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.694708228111267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9328265190124512\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.2792891263961792\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.59051513671875\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.498732089996338\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 1.117803931236267\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.5610265731811523\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.644658088684082\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.943936824798584\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.9805859327316284\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8789408206939697\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.6606422662734985\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.657378911972046\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.8547205924987793\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.7385895252227783\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.331986665725708\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.5220204591751099\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.2899479866027832\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 1.871628999710083\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.0055255889892578\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.7183852195739746\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.6682159900665283\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.7756893634796143\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.8782343864440918\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.8191099166870117\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.6402778625488281\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7133781909942627\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.0390625\n",
      "Current benign train loss: 0.8378810882568359\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8465890884399414\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.6749935150146484\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.871895432472229\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.2658674716949463\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.7760627269744873\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.6158168315887451\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.8339605331420898\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.3078041076660156\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8699198961257935\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3475403785705566\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9075307846069336\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.3305927515029907\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.958350419998169\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.3913466930389404\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.693755865097046\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.6564522981643677\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.8130946159362793\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.5276998281478882\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.8521089553833008\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.3464405536651611\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8134160041809082\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.6318395137786865\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.9042249917984009\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.5306856632232666\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.9104857444763184\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.7861493825912476\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.7947640419006348\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 1.5491492748260498\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8451006412506104\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.5658997297286987\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 2.035266637802124\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.0531024932861328\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7643769979476929\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.281380295753479\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.727837085723877\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.4193425178527832\n",
      "Current adversarial train accuracy: 0.1796875\n",
      "Current adversarial train loss: 1.859039306640625\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.295924186706543\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.8195087909698486\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.2596250772476196\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.8461543321609497\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.9144471883773804\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.7170631885528564\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.0828224420547485\n",
      "Current adversarial train accuracy: 0.21875\n",
      "Current adversarial train loss: 1.8264338970184326\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8875\n",
      "Current benign train loss: 0.7678251266479492\n",
      "Current adversarial train accuracy: 0.4875\n",
      "Current adversarial train loss: 1.7021243572235107\n",
      "\n",
      "Total benign train accuarcy: tensor(65.2232, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.3448, device='cuda:0')\n",
      "Total benign train loss: 475.8513472676277\n",
      "Total adversarial train loss: 693.4499151706696\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6337781548500061\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5983951091766357\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6189630031585693\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5844100713729858\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7169020175933838\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6903162002563477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.7292855978012085\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6786003112792969\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6958259344100952\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.7004622220993042\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.9\n",
      "Current benign test loss: 0.6442431807518005\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6950247287750244\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.761363685131073\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.8009364604949951\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.6870784759521484\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.6699131727218628\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6187753677368164\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6533738374710083\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5713303685188293\n",
      "Current adversarial test accuracy: 0.47\n",
      "Current adversarial test loss: 1.5044437646865845\n",
      "\n",
      "Total benign test accuarcy: 83.78\n",
      "Total adversarial test Accuarcy: 39.11\n",
      "Total benign test loss: 66.17869073152542\n",
      "Total adversarial test loss: 165.12903010845184\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.492577075958252\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.5732954740524292\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.619067907333374\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8943942785263062\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.824950098991394\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.673065423965454\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.2402700185775757\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7032157182693481\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 1.1193478107452393\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8603665828704834\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.4726991653442383\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7649798393249512\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.6290205717086792\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.8013405799865723\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.7419037818908691\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8363149166107178\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.0211713314056396\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9228239059448242\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.9165198802947998\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.9368901252746582\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6823503971099854\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5512043237686157\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.673663854598999\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.9649395942687988\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.9338126182556152\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6841529607772827\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.8524021506309509\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.8330203294754028\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.0925934314727783\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.4959681034088135\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.3898212909698486\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.685986042022705\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0557998418807983\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.5927960872650146\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0700713396072388\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.504589319229126\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.954717755317688\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.7796924114227295\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.4175050258636475\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.5634424686431885\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.7233542203903198\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.7233376502990723\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.8361307382583618\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.8897781372070312\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.2082960605621338\n",
      "Current adversarial train accuracy: 0.03125\n",
      "Current adversarial train loss: 1.502126932144165\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9989674687385559\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.7804937362670898\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3068852424621582\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8399691581726074\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.7696603536605835\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7983626127243042\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.6429693698883057\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.8606337308883667\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.1804136037826538\n",
      "Current adversarial train accuracy: 0.234375\n",
      "Current adversarial train loss: 1.9178539514541626\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 1.4473319053649902\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8935389518737793\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.591380774974823\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.834141731262207\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.727406919002533\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.840385913848877\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.6989185810089111\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8737879991531372\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.6636106967926025\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.6677762269973755\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.6863410472869873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.9399453401565552\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.046875\n",
      "Current benign train loss: 0.9862556457519531\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.9173498153686523\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.1759603023529053\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.845529317855835\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.2116265296936035\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.8864071369171143\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.0357214212417603\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8565067052841187\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.5728423595428467\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.7475926876068115\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.1375\n",
      "Current benign train loss: 1.3821499347686768\n",
      "Current adversarial train accuracy: 0.0625\n",
      "Current adversarial train loss: 1.5016355514526367\n",
      "\n",
      "Total benign train accuarcy: tensor(64.1253, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.4951, device='cuda:0')\n",
      "Total benign train loss: 485.39180770516396\n",
      "Total adversarial train loss: 691.8027639389038\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.7661718726158142\n",
      "Current adversarial test accuracy: 0.47\n",
      "Current adversarial test loss: 1.4815212488174438\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.7843374609947205\n",
      "Current adversarial test accuracy: 0.46\n",
      "Current adversarial test loss: 1.5793709754943848\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.7698465585708618\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.473655343055725\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.73\n",
      "Current benign test loss: 0.8472774028778076\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.5379528999328613\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.8073768615722656\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.5838594436645508\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7920001149177551\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.643126368522644\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.74\n",
      "Current benign test loss: 0.8465045094490051\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6106960773468018\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.75\n",
      "Current benign test loss: 0.7717834711074829\n",
      "Current adversarial test accuracy: 0.47\n",
      "Current adversarial test loss: 1.5543521642684937\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.7261356115341187\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.5223585367202759\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6595075726509094\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.4264171123504639\n",
      "\n",
      "Total benign test accuarcy: 78.49\n",
      "Total adversarial test Accuarcy: 43.02\n",
      "Total benign test loss: 77.92698502540588\n",
      "Total adversarial test loss: 154.62511599063873\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.26607346534729\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.8905420303344727\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.3463131189346313\n",
      "Current adversarial train accuracy: 0.5703125\n",
      "Current adversarial train loss: 1.6741681098937988\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.589395523071289\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.8114547729492188\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 1.5213940143585205\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.8766483068466187\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.5380377769470215\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.8266648054122925\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.5493371486663818\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.8293304443359375\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.2469960451126099\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.5677744150161743\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.8769782781600952\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.8038804531097412\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 0.5839660167694092\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6799191236495972\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7965033054351807\n",
      "Current adversarial train accuracy: 0.5234375\n",
      "Current adversarial train loss: 1.6108523607254028\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 0.9240683317184448\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.8117600679397583\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.7729049324989319\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.8855751752853394\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.3338652849197388\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.510018229484558\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.212179183959961\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7915892601013184\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 1.1013952493667603\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 2.040959119796753\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.7249583005905151\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 2.0168566703796387\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.6020610332489014\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8837707042694092\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.6022488474845886\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9308075904846191\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.9096950888633728\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9296295642852783\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9508194923400879\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.7296849489212036\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.6011947393417358\n",
      "Current adversarial train accuracy: 0.53125\n",
      "Current adversarial train loss: 1.3759256601333618\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.2335875034332275\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.8646533489227295\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.4946496486663818\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.859513521194458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6618260145187378\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6804065704345703\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.5969502925872803\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.847875714302063\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.788016676902771\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9646388292312622\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 1.521159291267395\n",
      "Current adversarial train accuracy: 0.28125\n",
      "Current adversarial train loss: 1.9032676219940186\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.369363784790039\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.8149175643920898\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.9390106201171875\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.843151569366455\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.0829946994781494\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.8148996829986572\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 1.1993674039840698\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8034690618515015\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.8507993221282959\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.725069522857666\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.570235013961792\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.9673902988433838\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.6146695613861084\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8620517253875732\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.6599056720733643\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8581100702285767\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.3449900150299072\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.8726955652236938\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.5605058670043945\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.6231276988983154\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.6469082832336426\n",
      "Current adversarial train accuracy: 0.171875\n",
      "Current adversarial train loss: 1.837143898010254\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.4643723964691162\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9258304834365845\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.075\n",
      "Current benign train loss: 1.1523306369781494\n",
      "Current adversarial train accuracy: 0.325\n",
      "Current adversarial train loss: 1.8210582733154297\n",
      "\n",
      "Total benign train accuarcy: tensor(65.8418, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.3161, device='cuda:0')\n",
      "Total benign train loss: 469.3901903629303\n",
      "Total adversarial train loss: 694.7602387666702\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.6215074062347412\n",
      "Current adversarial test accuracy: 0.36\n",
      "Current adversarial test loss: 1.674326777458191\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.5783564448356628\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.5825697183609009\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.6644914746284485\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.600721001625061\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.77\n",
      "Current benign test loss: 0.7268879413604736\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7636860609054565\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6724083423614502\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.7260931730270386\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6319101452827454\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.7898435592651367\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.6887633800506592\n",
      "Current adversarial test accuracy: 0.3\n",
      "Current adversarial test loss: 1.791469693183899\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.81\n",
      "Current benign test loss: 0.6687626838684082\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.7726424932479858\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6185393333435059\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.7540481090545654\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.5736644268035889\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.5925694704055786\n",
      "\n",
      "Total benign test accuarcy: 84.59\n",
      "Total adversarial test Accuarcy: 38.76\n",
      "Total benign test loss: 61.102703750133514\n",
      "Total adversarial test loss: 165.3683168888092\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.5724968910217285\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.741039514541626\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 1.4187049865722656\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.5077462196350098\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.2096052169799805\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8707222938537598\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.6800425052642822\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.8792128562927246\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.650909423828125\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.5096412897109985\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.4760818481445312\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.7289177179336548\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.5840622186660767\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8261361122131348\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.6580300331115723\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.392427921295166\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.6604940891265869\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8632135391235352\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 1.5492181777954102\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.633742332458496\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.6265766620635986\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8096855878829956\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 1.6001155376434326\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.779984951019287\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.6254973411560059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7273650169372559\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.5706651210784912\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.5644636154174805\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.39375045895576477\n",
      "Current adversarial train accuracy: 0.53125\n",
      "Current adversarial train loss: 1.450659990310669\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.534870982170105\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.9097741842269897\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 1.537949800491333\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6173505783081055\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.5925864577293396\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7071465253829956\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.691407322883606\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.880692958831787\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.9879631996154785\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.6679151058197021\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 1.0418198108673096\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7342019081115723\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 1.188069224357605\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.817396640777588\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.2860326766967773\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.8657336235046387\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.5744500756263733\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.8995529413223267\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.4778261184692383\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.8974323272705078\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.6517341136932373\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.7344077825546265\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.2577464580535889\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.917032241821289\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7136549949645996\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8883814811706543\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.2172273397445679\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7801815271377563\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.214685082435608\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.4849450588226318\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 0.9334914684295654\n",
      "Current adversarial train accuracy: 0.421875\n",
      "Current adversarial train loss: 1.6950962543487549\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.5571873188018799\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.6631743907928467\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.48865827918052673\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8317482471466064\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.6950693130493164\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.751150131225586\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.7272137999534607\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.979074239730835\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.7954402565956116\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8658595085144043\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.76655113697052\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.5278624296188354\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0555675029754639\n",
      "Current adversarial train accuracy: 0.546875\n",
      "Current adversarial train loss: 1.3137257099151611\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.1796875\n",
      "Current benign train loss: 1.4458565711975098\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.8286335468292236\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.8625\n",
      "Current benign train loss: 0.48344695568084717\n",
      "Current adversarial train accuracy: 0.5125\n",
      "Current adversarial train loss: 1.5439002513885498\n",
      "\n",
      "Total benign train accuarcy: tensor(66.7764, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(37.7196, device='cuda:0')\n",
      "Total benign train loss: 458.6144967973232\n",
      "Total adversarial train loss: 689.8050776720047\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.6447063684463501\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6563279628753662\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5959113836288452\n",
      "Current adversarial test accuracy: 0.45\n",
      "Current adversarial test loss: 1.6069748401641846\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6728500127792358\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6078966856002808\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6875507831573486\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.710385799407959\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6617204546928406\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6877042055130005\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.89\n",
      "Current benign test loss: 0.6109750270843506\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6891592741012573\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6943874359130859\n",
      "Current adversarial test accuracy: 0.32\n",
      "Current adversarial test loss: 1.808983325958252\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.6326451897621155\n",
      "Current adversarial test accuracy: 0.48\n",
      "Current adversarial test loss: 1.6903129816055298\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.5737016201019287\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6474051475524902\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.5444124341011047\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.52553129196167\n",
      "\n",
      "Total benign test accuarcy: 85.12\n",
      "Total adversarial test Accuarcy: 39.63\n",
      "Total benign test loss: 61.85334840416908\n",
      "Total adversarial test loss: 164.0679337978363\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.265625\n",
      "Current benign train loss: 1.568583607673645\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.9016995429992676\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.9874998331069946\n",
      "Current adversarial train accuracy: 0.2421875\n",
      "Current adversarial train loss: 1.921541452407837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 0.5304269790649414\n",
      "Current adversarial train accuracy: 0.53125\n",
      "Current adversarial train loss: 1.8134487867355347\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.9243489503860474\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8199355602264404\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.5750491619110107\n",
      "Current adversarial train accuracy: 0.2734375\n",
      "Current adversarial train loss: 1.808215618133545\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.221298098564148\n",
      "Current adversarial train accuracy: 0.1640625\n",
      "Current adversarial train loss: 1.8035554885864258\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.6386284828186035\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.711218237876892\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 1.049006700515747\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.798372745513916\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 0.5697910189628601\n",
      "Current adversarial train accuracy: 0.3984375\n",
      "Current adversarial train loss: 1.8757014274597168\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.604261875152588\n",
      "Current adversarial train accuracy: 0.3203125\n",
      "Current adversarial train loss: 1.9623219966888428\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 1.3011223077774048\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.58128821849823\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.1086769104003906\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9052379131317139\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.0390625\n",
      "Current benign train loss: 1.0438618659973145\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7957075834274292\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.5324856638908386\n",
      "Current adversarial train accuracy: 0.390625\n",
      "Current adversarial train loss: 1.8690354824066162\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8806798458099365\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.779072880744934\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 0.7057248950004578\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.7003556489944458\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.53610098361969\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.7614681720733643\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.6938990354537964\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.8515435457229614\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.6318990588188171\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.699981451034546\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.3600667715072632\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.6376676559448242\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.2028613090515137\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7573890686035156\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.712927520275116\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8526246547698975\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.1948902606964111\n",
      "Current adversarial train accuracy: 0.1328125\n",
      "Current adversarial train loss: 1.7754480838775635\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.008994460105896\n",
      "Current adversarial train accuracy: 0.203125\n",
      "Current adversarial train loss: 1.9689006805419922\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 0.8929126262664795\n",
      "Current adversarial train accuracy: 0.296875\n",
      "Current adversarial train loss: 1.8670246601104736\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 1.5247106552124023\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.898538589477539\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.7325296401977539\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.7833824157714844\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.336374044418335\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.63419508934021\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8529841899871826\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.8875317573547363\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.1851474046707153\n",
      "Current adversarial train accuracy: 0.09375\n",
      "Current adversarial train loss: 1.7738416194915771\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.2843525409698486\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.330305814743042\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.5415560007095337\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8106588125228882\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.614405632019043\n",
      "Current adversarial train accuracy: 0.40625\n",
      "Current adversarial train loss: 1.9688477516174316\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.7128580808639526\n",
      "Current adversarial train accuracy: 0.25\n",
      "Current adversarial train loss: 1.9586210250854492\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.5112767815589905\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.537888526916504\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.7476630210876465\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.5605851411819458\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.5928587913513184\n",
      "Current adversarial train accuracy: 0.3828125\n",
      "Current adversarial train loss: 1.8841519355773926\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 1.265897274017334\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7776124477386475\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.7083479166030884\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.8646599054336548\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.15\n",
      "Current benign train loss: 1.537564992904663\n",
      "Current adversarial train accuracy: 0.3875\n",
      "Current adversarial train loss: 1.8446946144104004\n",
      "\n",
      "Total benign train accuarcy: tensor(65.0829, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(38.0436, device='cuda:0')\n",
      "Total benign train loss: 477.3631326556206\n",
      "Total adversarial train loss: 686.5366512537003\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.9\n",
      "Current benign test loss: 0.5999962091445923\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.6626899242401123\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.5647767782211304\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6757739782333374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.5999542474746704\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6702253818511963\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6367045640945435\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.7035871744155884\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6368045210838318\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.7218163013458252\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.5556038022041321\n",
      "Current adversarial test accuracy: 0.43\n",
      "Current adversarial test loss: 1.705235481262207\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.6443566083908081\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.8316612243652344\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.76\n",
      "Current benign test loss: 0.6309127807617188\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.7315587997436523\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.5455173254013062\n",
      "Current adversarial test accuracy: 0.4\n",
      "Current adversarial test loss: 1.7081456184387207\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.91\n",
      "Current benign test loss: 0.4917944371700287\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.5470423698425293\n",
      "\n",
      "Total benign test accuarcy: 85.35\n",
      "Total adversarial test Accuarcy: 39.66\n",
      "Total benign test loss: 58.282629668712616\n",
      "Total adversarial test loss: 169.37098824977875\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.1014249324798584\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.929152011871338\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 1.2563180923461914\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.899004340171814\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.250262975692749\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.7077975273132324\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.2518370151519775\n",
      "Current adversarial train accuracy: 0.59375\n",
      "Current adversarial train loss: 1.6564372777938843\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 0.4351361393928528\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.6748058795928955\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.0671398639678955\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.729250192642212\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.6891722679138184\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6586488485336304\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.171875\n",
      "Current benign train loss: 1.3640456199645996\n",
      "Current adversarial train accuracy: 0.5234375\n",
      "Current adversarial train loss: 1.5781285762786865\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.645836591720581\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.758669137954712\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 1.1336605548858643\n",
      "Current adversarial train accuracy: 0.2109375\n",
      "Current adversarial train loss: 1.8651423454284668\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.459705114364624\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.6428810358047485\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.4350979328155518\n",
      "Current adversarial train accuracy: 0.328125\n",
      "Current adversarial train loss: 1.9704868793487549\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.1976728439331055\n",
      "Current adversarial train accuracy: 0.0546875\n",
      "Current adversarial train loss: 1.6014208793640137\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.5715444087982178\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.7327910661697388\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 1.394734263420105\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.5053303241729736\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.5\n",
      "Current benign train loss: 1.6145018339157104\n",
      "Current adversarial train accuracy: 0.5703125\n",
      "Current adversarial train loss: 1.7118868827819824\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.583918809890747\n",
      "Current adversarial train accuracy: 0.5234375\n",
      "Current adversarial train loss: 1.5885359048843384\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 1.2695658206939697\n",
      "Current adversarial train accuracy: 0.4140625\n",
      "Current adversarial train loss: 1.8753902912139893\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.6129381656646729\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.8088597059249878\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 1.0056142807006836\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.904909610748291\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.8908427953720093\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.9214247465133667\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.1171875\n",
      "Current benign train loss: 0.7288656234741211\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7834014892578125\n",
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.0859375\n",
      "Current benign train loss: 1.3742170333862305\n",
      "Current adversarial train accuracy: 0.359375\n",
      "Current adversarial train loss: 1.9377638101577759\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 1.4100708961486816\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8943712711334229\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.1887972354888916\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8769357204437256\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.5191071033477783\n",
      "Current adversarial train accuracy: 0.46875\n",
      "Current adversarial train loss: 1.7681221961975098\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.6844935417175293\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.5966485738754272\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.5986247062683105\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.7850501537322998\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.8252004981040955\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.819624900817871\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 1.5384737253189087\n",
      "Current adversarial train accuracy: 0.3046875\n",
      "Current adversarial train loss: 1.888566493988037\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.7909234762191772\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.4923608303070068\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.7894266247749329\n",
      "Current adversarial train accuracy: 0.3515625\n",
      "Current adversarial train loss: 1.8870162963867188\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.203125\n",
      "Current benign train loss: 1.5297162532806396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current adversarial train accuracy: 0.3359375\n",
      "Current adversarial train loss: 1.9038076400756836\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.6634156703948975\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.620795488357544\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.7239537239074707\n",
      "Current adversarial train accuracy: 0.2890625\n",
      "Current adversarial train loss: 1.8345947265625\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 1.5625262260437012\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.5539697408676147\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.1875\n",
      "Current benign train loss: 1.6727385520935059\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 2.0135350227355957\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.2734375\n",
      "Current benign train loss: 1.6982258558273315\n",
      "Current adversarial train accuracy: 0.265625\n",
      "Current adversarial train loss: 1.920057773590088\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.258734107017517\n",
      "Current adversarial train accuracy: 0.078125\n",
      "Current adversarial train loss: 1.64303457736969\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.925\n",
      "Current benign train loss: 0.4679781496524811\n",
      "Current adversarial train accuracy: 0.475\n",
      "Current adversarial train loss: 1.6214032173156738\n",
      "\n",
      "Total benign train accuarcy: tensor(63.9984, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(38.2527, device='cuda:0')\n",
      "Total benign train loss: 487.21270099282265\n",
      "Total adversarial train loss: 685.4572163820267\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6324131488800049\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5841199159622192\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.87\n",
      "Current benign test loss: 0.6004028916358948\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.5762025117874146\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.79\n",
      "Current benign test loss: 0.7071760296821594\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.6179835796356201\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.63702791929245\n",
      "Current adversarial test accuracy: 0.42\n",
      "Current adversarial test loss: 1.6041712760925293\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.6449944972991943\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.650974988937378\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6071360111236572\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6566040515899658\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.6630836725234985\n",
      "Current adversarial test accuracy: 0.38\n",
      "Current adversarial test loss: 1.6174768209457397\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.85\n",
      "Current benign test loss: 0.6595320105552673\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.663962721824646\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.6193531155586243\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6646124124526978\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.529985785484314\n",
      "Current adversarial test accuracy: 0.39\n",
      "Current adversarial test loss: 1.5215661525726318\n",
      "\n",
      "Total benign test accuarcy: 85.69\n",
      "Total adversarial test Accuarcy: 40.27\n",
      "Total benign test loss: 61.086682468652725\n",
      "Total adversarial test loss: 159.001882314682\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 1.0390957593917847\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.5325019359588623\n",
      "\n",
      "Current batch: 10\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 1.1947031021118164\n",
      "Current adversarial train accuracy: 0.2578125\n",
      "Current adversarial train loss: 1.8516943454742432\n",
      "\n",
      "Current batch: 20\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.739307701587677\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.7609467506408691\n",
      "\n",
      "Current batch: 30\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 1.0628846883773804\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.8012502193450928\n",
      "\n",
      "Current batch: 40\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.6629931330680847\n",
      "Current adversarial train accuracy: 0.515625\n",
      "Current adversarial train loss: 1.6979103088378906\n",
      "\n",
      "Current batch: 50\n",
      "Current benign train accuracy: 0.1484375\n",
      "Current benign train loss: 1.494227647781372\n",
      "Current adversarial train accuracy: 0.0703125\n",
      "Current adversarial train loss: 1.720921277999878\n",
      "\n",
      "Current batch: 60\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.5888614654541016\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.8383874893188477\n",
      "\n",
      "Current batch: 70\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.8685763478279114\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.8979289531707764\n",
      "\n",
      "Current batch: 80\n",
      "Current benign train accuracy: 0.2109375\n",
      "Current benign train loss: 1.6175602674484253\n",
      "Current adversarial train accuracy: 0.109375\n",
      "Current adversarial train loss: 1.634294033050537\n",
      "\n",
      "Current batch: 90\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 1.0725003480911255\n",
      "Current adversarial train accuracy: 0.1484375\n",
      "Current adversarial train loss: 1.7890100479125977\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.125\n",
      "Current benign train loss: 0.7920268774032593\n",
      "Current adversarial train accuracy: 0.2265625\n",
      "Current adversarial train loss: 1.9098715782165527\n",
      "\n",
      "Current batch: 110\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 1.2759603261947632\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.8526151180267334\n",
      "\n",
      "Current batch: 120\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.6159273982048035\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.8636438846588135\n",
      "\n",
      "Current batch: 130\n",
      "Current benign train accuracy: 0.0546875\n",
      "Current benign train loss: 0.8113000392913818\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.8588650226593018\n",
      "\n",
      "Current batch: 140\n",
      "Current benign train accuracy: 0.1328125\n",
      "Current benign train loss: 0.7373838424682617\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.8411531448364258\n",
      "\n",
      "Current batch: 150\n",
      "Current benign train accuracy: 0.28125\n",
      "Current benign train loss: 1.592270016670227\n",
      "Current adversarial train accuracy: 0.3671875\n",
      "Current adversarial train loss: 1.930344581604004\n",
      "\n",
      "Current batch: 160\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.8159210681915283\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.7645787000656128\n",
      "\n",
      "Current batch: 170\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.6476016044616699\n",
      "Current adversarial train accuracy: 0.125\n",
      "Current adversarial train loss: 1.814363956451416\n",
      "\n",
      "Current batch: 180\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.5822319984436035\n",
      "Current adversarial train accuracy: 0.15625\n",
      "Current adversarial train loss: 1.4751081466674805\n",
      "\n",
      "Current batch: 190\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.48347553610801697\n",
      "Current adversarial train accuracy: 0.1171875\n",
      "Current adversarial train loss: 1.7248272895812988\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.6502071619033813\n",
      "Current adversarial train accuracy: 0.5078125\n",
      "Current adversarial train loss: 1.4467883110046387\n",
      "\n",
      "Current batch: 210\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 1.3837673664093018\n",
      "Current adversarial train accuracy: 0.1875\n",
      "Current adversarial train loss: 1.8701884746551514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 220\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.6566455364227295\n",
      "Current adversarial train accuracy: 0.484375\n",
      "Current adversarial train loss: 1.7587981224060059\n",
      "\n",
      "Current batch: 230\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 1.2318586111068726\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.4699468612670898\n",
      "\n",
      "Current batch: 240\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 0.5352445840835571\n",
      "Current adversarial train accuracy: 0.375\n",
      "Current adversarial train loss: 1.9759643077850342\n",
      "\n",
      "Current batch: 250\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.6955764889717102\n",
      "Current adversarial train accuracy: 0.453125\n",
      "Current adversarial train loss: 1.810520887374878\n",
      "\n",
      "Current batch: 260\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.5535094738006592\n",
      "Current adversarial train accuracy: 0.4609375\n",
      "Current adversarial train loss: 1.841164469718933\n",
      "\n",
      "Current batch: 270\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.6884993314743042\n",
      "Current adversarial train accuracy: 0.1953125\n",
      "Current adversarial train loss: 1.922504186630249\n",
      "\n",
      "Current batch: 280\n",
      "Current benign train accuracy: 0.09375\n",
      "Current benign train loss: 1.4721509218215942\n",
      "Current adversarial train accuracy: 0.4453125\n",
      "Current adversarial train loss: 1.6716396808624268\n",
      "\n",
      "Current batch: 290\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 0.3622850179672241\n",
      "Current adversarial train accuracy: 0.5546875\n",
      "Current adversarial train loss: 1.466919183731079\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.5000084042549133\n",
      "Current adversarial train accuracy: 0.4765625\n",
      "Current adversarial train loss: 1.6532014608383179\n",
      "\n",
      "Current batch: 310\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.3547312021255493\n",
      "Current adversarial train accuracy: 0.4375\n",
      "Current adversarial train loss: 1.6204622983932495\n",
      "\n",
      "Current batch: 320\n",
      "Current benign train accuracy: 0.140625\n",
      "Current benign train loss: 1.2834749221801758\n",
      "Current adversarial train accuracy: 0.1015625\n",
      "Current adversarial train loss: 1.6932387351989746\n",
      "\n",
      "Current batch: 330\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 1.3246508836746216\n",
      "Current adversarial train accuracy: 0.3125\n",
      "Current adversarial train loss: 1.9003396034240723\n",
      "\n",
      "Current batch: 340\n",
      "Current benign train accuracy: 0.078125\n",
      "Current benign train loss: 1.0310511589050293\n",
      "Current adversarial train accuracy: 0.140625\n",
      "Current adversarial train loss: 1.8760493993759155\n",
      "\n",
      "Current batch: 350\n",
      "Current benign train accuracy: 0.109375\n",
      "Current benign train loss: 1.3966917991638184\n",
      "Current adversarial train accuracy: 0.4296875\n",
      "Current adversarial train loss: 1.6502450704574585\n",
      "\n",
      "Current batch: 360\n",
      "Current benign train accuracy: 0.2265625\n",
      "Current benign train loss: 1.5252244472503662\n",
      "Current adversarial train accuracy: 0.4921875\n",
      "Current adversarial train loss: 1.3811877965927124\n",
      "\n",
      "Current batch: 370\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 1.205073595046997\n",
      "Current adversarial train accuracy: 0.0859375\n",
      "Current adversarial train loss: 1.9379770755767822\n",
      "\n",
      "Current batch: 380\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 1.3984978199005127\n",
      "Current adversarial train accuracy: 0.5\n",
      "Current adversarial train loss: 1.7898495197296143\n",
      "\n",
      "Current batch: 390\n",
      "Current benign train accuracy: 0.225\n",
      "Current benign train loss: 1.552718162536621\n",
      "Current adversarial train accuracy: 0.475\n",
      "Current adversarial train loss: 1.8754584789276123\n",
      "\n",
      "Total benign train accuarcy: tensor(65.1430, device='cuda:0')\n",
      "Total adversarial train accuarcy: tensor(38.4270, device='cuda:0')\n",
      "Total benign train loss: 474.3227089047432\n",
      "Total adversarial train loss: 682.4998461008072\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.7982614636421204\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.6071187257766724\n",
      "\n",
      "Current batch: 10\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7509354948997498\n",
      "Current adversarial test accuracy: 0.44\n",
      "Current adversarial test loss: 1.5812221765518188\n",
      "\n",
      "Current batch: 20\n",
      "Current benign test accuracy: 0.8\n",
      "Current benign test loss: 0.8225042223930359\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.5730034112930298\n",
      "\n",
      "Current batch: 30\n",
      "Current benign test accuracy: 0.82\n",
      "Current benign test loss: 0.7931768894195557\n",
      "Current adversarial test accuracy: 0.46\n",
      "Current adversarial test loss: 1.556526780128479\n",
      "\n",
      "Current batch: 40\n",
      "Current benign test accuracy: 0.83\n",
      "Current benign test loss: 0.8011795878410339\n",
      "Current adversarial test accuracy: 0.48\n",
      "Current adversarial test loss: 1.6552746295928955\n",
      "\n",
      "Current batch: 50\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.7702413201332092\n",
      "Current adversarial test accuracy: 0.37\n",
      "Current adversarial test loss: 1.6494232416152954\n",
      "\n",
      "Current batch: 60\n",
      "Current benign test accuracy: 0.78\n",
      "Current benign test loss: 0.8289173245429993\n",
      "Current adversarial test accuracy: 0.35\n",
      "Current adversarial test loss: 1.6226000785827637\n",
      "\n",
      "Current batch: 70\n",
      "Current benign test accuracy: 0.84\n",
      "Current benign test loss: 0.7826127409934998\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.6285136938095093\n",
      "\n",
      "Current batch: 80\n",
      "Current benign test accuracy: 0.86\n",
      "Current benign test loss: 0.7611320614814758\n",
      "Current adversarial test accuracy: 0.34\n",
      "Current adversarial test loss: 1.674217939376831\n",
      "\n",
      "Current batch: 90\n",
      "Current benign test accuracy: 0.88\n",
      "Current benign test loss: 0.6769305467605591\n",
      "Current adversarial test accuracy: 0.41\n",
      "Current adversarial test loss: 1.471960425376892\n",
      "\n",
      "Total benign test accuarcy: 83.72\n",
      "Total adversarial test Accuarcy: 42.17\n",
      "Total benign test loss: 76.19588726758957\n",
      "Total adversarial test loss: 157.55534100532532\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for epoch in range(0, 50):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480cf4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time is 4:38:57.181549 \n"
     ]
    }
   ],
   "source": [
    "#RTX3070 50 epochs\n",
    "import datetime\n",
    "deltatime = str(datetime.timedelta(seconds=t2-t1))\n",
    "print('Total running time is %s '% deltatime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d96fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
